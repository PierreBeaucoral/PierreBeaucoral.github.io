[
  {
    "objectID": "td2/enonce-td2.html",
    "href": "td2/enonce-td2.html",
    "title": "TD 2 — Régression logistique (R)",
    "section": "",
    "text": "1. Télécharger le fichier bankloanT.xls depuis l’ENT, puis importer les données dans R\n2. Etudier la distribution de la variable ed. Créer une variable catégorielle, puis une variable ne contenant que 4 classes.\n3. Etudier la matrice des corrélations entre les 7 variables quantitatives présentes.\n4. Recoder la variable à expliquer (default) en variable quantitative puis réaliser une première régression logistique incluant toutes les variables explicatives quantitatives.\n5. Réaliser une deuxième régression logistique incluant aussi la variable educ en classe. Enregistrer aussi les résultats de ce modèle, qui est le modèle le plus complexe que nous appliquerons à ces données.\n6. Tester l’ajustement de ce modèle complet, grâce à la commande hoslem.test, où g est le nombre de groupes de niveaux différents de fonction prédictive utilisé pour le test. Varier les valeurs de g pour vérifier la robustesse du résultat.\n7. Grâce à la commande anova, réaliser un test de rapport de vraisemblance entre les deux modèles ajustés, et conclure sur la significativité de la variable educ.\n8. Ôter la variable la moins significative du modèle retenu. Vérifier que la P-value du test de rapport de vraisemblance entre les modèles avec et sans cette variable est égale ou très proche de la P-value du test bilatéral de nullité du coefficient associé à la variable.\n9. Une variable est à nouveau très peu significative. Ajuster un nouveau modèle sans cette variable. Sauvegarder les valeurs prédites par ce modèle.\n10. Etablir le tableau de contingence des individus bien ou mal classés avec une règle de coupure à 0,5\n11. Etablir la courbe ROC pour le « meilleur » modèle, puis calculer les “probabilités prédites” et étudier leur distribution\n12. Refaire la même modélisation avec un modèle Probit et observer les différences et ressemblances avec la modélisation Logit.\n\n\nSupposant qu’un individu ne remboursant pas son emprunt coûte en moyenne 100000$, et qu’un individu payant son emprunt rapporte en moyenne 40000$, on peut calculer (…) qu’il est optimal de n’accorder un prêt qu’aux individus ayant une probabilité de rembourser estimée à 0,7 ou plus.\n13. Règle de décision (probabilité de remboursement &gt;= 0.7)\n14. Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser. Commenter ce tableau."
  },
  {
    "objectID": "td2/enonce-td2.html#pour-aller-plus-loin",
    "href": "td2/enonce-td2.html#pour-aller-plus-loin",
    "title": "TD 2 — Régression logistique (R)",
    "section": "",
    "text": "Supposant qu’un individu ne remboursant pas son emprunt coûte en moyenne 100000$, et qu’un individu payant son emprunt rapporte en moyenne 40000$, on peut calculer (…) qu’il est optimal de n’accorder un prêt qu’aux individus ayant une probabilité de rembourser estimée à 0,7 ou plus.\n13. Règle de décision (probabilité de remboursement &gt;= 0.7)\n14. Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser. Commenter ce tableau."
  },
  {
    "objectID": "td2/td2.html",
    "href": "td2/td2.html",
    "title": "TD 2 — Régression logistique (R)",
    "section": "",
    "text": "Ce TD reprend l’exemple et le dictionnaire de variables (age, ed, employ, address, income, debtinc, credebt, othdebt, default) décrits dans la ressource d’origine.\nDonnées à récupérer: bankloanT.xls (ENT).\nPackages utilisés : tidyverse, readxl, janitor, broom, ResourceSelection, pROC, gt, ggplot2."
  },
  {
    "objectID": "td2/td2.html#quand-utiliser-ces-modèles",
    "href": "td2/td2.html#quand-utiliser-ces-modèles",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.1 Quand utiliser ces modèles ?",
    "text": "1.1 Quand utiliser ces modèles ?\nLa régression logistique et la régression probit sont utilisées lorsque la variable à expliquer est binaire :\n\\(Y_i \\in {0,1}\\)\n\nExemple : défaut de paiement / pas de défaut\n\nObjectif : estimer la probabilité \\(P(Y_i = 1 \\mid X_i)\\) en fonction de caractéristiques \\(X_i\\)\n\nLes variables explicatives peuvent être quantitatives ou qualitatives."
  },
  {
    "objectID": "td2/td2.html#pourquoi-ne-pas-utiliser-une-régression-linéaire",
    "href": "td2/td2.html#pourquoi-ne-pas-utiliser-une-régression-linéaire",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.2 Pourquoi ne pas utiliser une régression linéaire ?",
    "text": "1.2 Pourquoi ne pas utiliser une régression linéaire ?\nUne régression linéaire classique :\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\)\npeut donner des valeurs prédites hors de [0, 1], ce qui est absurde pour une probabilité.\nIl faut donc introduire une fonction de lien qui transforme l’intervalle (0, 1) en \\(\\mathbb{R}\\)."
  },
  {
    "objectID": "td2/td2.html#fonction-de-lien-du-modèle-logit",
    "href": "td2/td2.html#fonction-de-lien-du-modèle-logit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.3 Fonction de lien du modèle Logit",
    "text": "1.3 Fonction de lien du modèle Logit\n\\(\\text{logit}(p) = \\ln\\left(\\frac{p}{1 - p}\\right) \\quad \\text{et} \\quad p = \\frac{e^{x}}{1 + e^{x}} = \\frac{1}{1 + e^{-x}}\\)\nLe modèle s’écrit :\n\\(\\text{logit}(P(Y_i = 1)) = \\beta_0 + \\beta1 X{i1} + \\dots + \\beta_p X{ip}\\)\nLes coefficients \\(\\beta_j\\) s’interprètent via les odds-ratios : \\(OR_j = e^{\\beta_j}\\)"
  },
  {
    "objectID": "td2/td2.html#fonction-de-lien-du-modèle-probit",
    "href": "td2/td2.html#fonction-de-lien-du-modèle-probit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.4 Fonction de lien du modèle Probit",
    "text": "1.4 Fonction de lien du modèle Probit\nLe modèle Probit suppose qu’il existe une variable latente (Y_i^*) telle que :\n\\(Y_i^* = \\beta_0 + \\beta1 X{i1} + \\dots + \\beta_p X{ip} + \\varepsilon_i \\quad \\text{avec} \\quad \\varepsilon_i \\sim \\mathcal{N}(0,1)\\)\net on observe :\n\\(Y_i = 1 \\text{ si } Y_i^* &gt; 0\\)\nd’où :\n\\(P(Y_i = 1) = \\Phi(\\beta_0 + \\beta_1 X_i)\\) où \\(\\Phi\\) est la fonction de répartition de la loi normale centrée réduite."
  },
  {
    "objectID": "td2/td2.html#comparaison-graphique-des-liens-logit-et-probit",
    "href": "td2/td2.html#comparaison-graphique-des-liens-logit-et-probit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.5 Comparaison graphique des liens Logit et Probit",
    "text": "1.5 Comparaison graphique des liens Logit et Probit\n\n\nCode\nlibrary(ggplot2)\n\nx &lt;- seq(-6, 6, length.out = 200) \n\ndf_link &lt;- data.frame( x = x, Logit = 1 / (1 + exp(-x)), Probit = pnorm(x) )\n\nggplot(df_link, aes(x = x)) + geom_line(aes(y = Logit, color = \"Logit\")) + geom_line(aes(y = Probit, color = \"Probit\"), linetype = 2) + scale_color_manual(values = c(\"Logit\" = \"steelblue\", \"Probit\" = \"firebrick\")) + labs( title = \"Comparaison des liens Logit et Probit\", x = \"Score linéaire (Xβ)\", y = \"Probabilité prédite\", color = \"Modèle\" ) + theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1: Comparaison des fonctions de lien Logit et Probit\n\n\n\n\n\nObservation :\n\nLes deux courbes sont très proches ; la principale différence réside dans la forme légèrement plus aplatie du Probit aux extrémités.\nEn pratique, les résultats logit et probit sont très similaires (seuls les coefficients changent d’échelle : \\(\\beta_{\\text{logit}} ≈ 1.6 β_{\\text{probit}}\\).\n\n\n\n1.5.1 Interprétation économique\n\nLogit : privilégié quand on interprète les coefficients en termes d’odds-ratios (très courant en santé et sciences sociales).\nProbit : privilégié en économie microéconométrique, car il se relie naturellement à un modèle de variable latente et au Tobit.\n\n\n\n\nCode\nx &lt;- seq(0, 40, length.out = 200)\nbeta0 &lt;- -2.5; beta1 &lt;- 0.12\np_hat &lt;- 1 / (1 + exp(-(beta0 + beta1 * x)))\n\ndf_ex &lt;- data.frame(debt_income = x, p_hat = p_hat)\n\nggplot(df_ex, aes(debt_income, p_hat)) +\ngeom_line(color = \"seagreen4\", linewidth = 1.2) +\nlabs(\ntitle = \"Effet du ratio dette/revenu sur la probabilité de défaut (modèle logit)\",\nx = \"Ratio dette / revenu (%)\",\ny = \"Probabilité prédite de défaut\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nFigure 2: Exemple : probabilité prédite de défaut selon le ratio dette/revenu\n\n\n\n\n\nInterprétation :\n\n→ Lorsque le ratio dette/revenu augmente, la probabilité prédite de défaut croît de manière sigmoïde : faible au départ, elle augmente rapidement autour de la zone moyenne, puis se stabilise."
  },
  {
    "objectID": "td2/td2.html#résumé-comparatif",
    "href": "td2/td2.html#résumé-comparatif",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.6 Résumé comparatif",
    "text": "1.6 Résumé comparatif\n\n\n\n\n\n\n\n\nCaractéristique\nLogit\nProbit\n\n\n\n\nFonction de lien\nlogit(p) = log(p/(1−p))\nΦ⁻¹(p)\n\n\nDistribution implicite des erreurs\nLogistique\nNormale centrée réduite\n\n\nInterprétation des coefficients\nOdds-ratios\nZ-scores latents\n\n\nUsages typiques\nSanté, sociologie\nÉconomie, finance\n\n\nRésultats empiriques\nQuasi identiques (β_logit ≈ 1.6 β_probit)\n\n\n\n\n\nÀ retenir : Logit et Probit sont deux manières voisines de modéliser une probabilité binaire. Le choix entre les deux est souvent une question de convention disciplinaire ou d’interprétabilité des coefficients."
  },
  {
    "objectID": "td2/td2.html#télécharger-le-fichier-bankloant.xls-depuis-lent-puis-importer-les-données-dans-r",
    "href": "td2/td2.html#télécharger-le-fichier-bankloant.xls-depuis-lent-puis-importer-les-données-dans-r",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.1 Télécharger le fichier bankloanT.xls depuis l’ENT, puis importer les données dans R",
    "text": "2.1 Télécharger le fichier bankloanT.xls depuis l’ENT, puis importer les données dans R\n\n\nCode\ndf0 &lt;- read_excel(\"./data/bankloanT.xls\") |&gt; clean_names()\ndf0 |&gt; glimpse()\n\n\nRows: 850\nColumns: 9\n$ age      &lt;dbl&gt; 44, 26, 47, 31, 33, 45, 45, 35, 38, 32, 36, 47, 34, 39, 27, 4…\n$ ed       &lt;chr&gt; \"College degree\", \"High school degree\", \"Some college\", \"Did …\n$ employ   &lt;dbl&gt; 18, 6, 16, 5, 10, 21, 16, 17, 7, 0, 4, 23, 16, 8, 7, 8, 9, 0,…\n$ address  &lt;dbl&gt; 23, 6, 7, 7, 2, 26, 21, 4, 4, 4, 17, 11, 9, 0, 8, 18, 6, 5, 1…\n$ income   &lt;dbl&gt; 78, 30, 266, 23, 54, 132, 80, 42, 64, 20, 25, 115, 79, 21, 30…\n$ debtinc  &lt;chr&gt; \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"4\", \"4\", \"…\n$ creddebt &lt;chr&gt; \"0.56472\", \"0.1437\", \"2.19184\", \"0.046\", \"0.11988\", \"2.55816\"…\n$ othdebt  &lt;chr&gt; \"0.21528\", \"0.1563\", \"3.12816\", \"0.414\", \"1.50012\", \"1.40184\"…\n$ default  &lt;chr&gt; NA, \"No\", NA, NA, NA, \"No\", \"No\", \"No\", \"No\", \"Yes\", NA, \"No\"…"
  },
  {
    "objectID": "td2/td2.html#etudier-la-distribution-de-la-variable-ed.-créer-une-variable-catégorielle-puis-une-variable-ne-contenant-que-4-classes.",
    "href": "td2/td2.html#etudier-la-distribution-de-la-variable-ed.-créer-une-variable-catégorielle-puis-une-variable-ne-contenant-que-4-classes.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.2 Etudier la distribution de la variable ed. Créer une variable catégorielle, puis une variable ne contenant que 4 classes.",
    "text": "2.2 Etudier la distribution de la variable ed. Créer une variable catégorielle, puis une variable ne contenant que 4 classes.\n\n\nCode\ndf0 |&gt; count(ed) |&gt; arrange(desc(n))\n\n\n# A tibble: 5 × 2\n  ed                               n\n  &lt;chr&gt;                        &lt;int&gt;\n1 Did not complete high school   460\n2 High school degree             235\n3 Some college                   101\n4 College degree                  49\n5 Post-undergraduate degree        5\n\n\nCode\ndf1 &lt;- df0 |&gt;\n  mutate(\n    ed5 = factor(ed,\n                 levels = c(\n                   \"Did not complete high school\",\n                   \"High school degree\",\n                   \"Some college\",\n                   \"College degree\",\n                  \"Post-undergraduate degree\"   \n                 ),\n                 ordered = TRUE),\n    ed4 = fct_collapse(ed5,\n                       \"College or above\" = c(\"College degree\", \"Post-undergraduate degree\"))\n  )\n\ndf1 |&gt; count(ed4)\n\n\n# A tibble: 4 × 2\n  ed4                              n\n  &lt;ord&gt;                        &lt;int&gt;\n1 Did not complete high school   460\n2 High school degree             235\n3 Some college                   101\n4 College or above                54\n\n\nCode\nggplot(df1, aes(x = ed4)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(x = \"Niveau d'éducation (4 classes)\", y = \"Effectif\",\n       title = \"Distribution de l'éducation dans l'échantillon\") +\n  theme_minimal()"
  },
  {
    "objectID": "td2/td2.html#etudier-la-matrice-des-corrélations-entre-les-7-variables-quantitatives-présentes.",
    "href": "td2/td2.html#etudier-la-matrice-des-corrélations-entre-les-7-variables-quantitatives-présentes.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.3 Etudier la matrice des corrélations entre les 7 variables quantitatives présentes.",
    "text": "2.3 Etudier la matrice des corrélations entre les 7 variables quantitatives présentes.\n\n\nCode\nnum_vars &lt;- c(\"age\",\"employ\",\"address\",\"income\",\"debtinc\",\"creddebt\",\"othdebt\")\ndf1 &lt;- df1 |&gt;\n  mutate(\n    debtinc  = as.numeric(debtinc),\n    creddebt = as.numeric(creddebt),\n    othdebt  = as.numeric(othdebt)\n  )\ncor_mat &lt;- df1 |&gt;\n  select(all_of(num_vars)) |&gt;\n  drop_na() |&gt;\n  cor()\n\nlibrary(ggcorrplot)\nggcorrplot(\n  cor_mat,\n  hc.order = TRUE,           # ordonne les variables par similarité\n  lab = TRUE,                # affiche les coefficients\n  lab_size = 3,\n  colors = c(\"tomato2\", \"white\", \"seagreen3\"),\n  title = \"Corrélogramme des variables quantitatives\",\n  ggtheme = theme_minimal()\n)"
  },
  {
    "objectID": "td2/td2.html#recoder-la-variable-à-expliquer-default-en-variable-quantitative-puis-réaliser-une-première-régression-logistique-incluant-toutes-les-variables-explicatives-quantitatives.",
    "href": "td2/td2.html#recoder-la-variable-à-expliquer-default-en-variable-quantitative-puis-réaliser-une-première-régression-logistique-incluant-toutes-les-variables-explicatives-quantitatives.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.4 Recoder la variable à expliquer (default) en variable quantitative puis réaliser une première régression logistique incluant toutes les variables explicatives quantitatives.",
    "text": "2.4 Recoder la variable à expliquer (default) en variable quantitative puis réaliser une première régression logistique incluant toutes les variables explicatives quantitatives.\n\n\nCode\ndf2 &lt;- df1 |&gt;\n  mutate(\n    default_num = case_when(\n      default == \"Yes\" ~ 1,\n      default == \"No\"  ~ 0,\n      TRUE ~ NA_real_   # conserve les NA existants\n    )\n  )\nform1 &lt;- default_num ~ age + employ + address + income + debtinc + creddebt + othdebt\nmod1 &lt;- glm(form1, data=df2, family=binomial(\"logit\"))\nsummary(mod1)\n\n\n\nCall:\nglm(formula = form1, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.377693   0.571585  -2.410   0.0159 *  \nage          0.033694   0.017341   1.943   0.0520 .  \nemploy      -0.265035   0.031996  -8.283  &lt; 2e-16 ***\naddress     -0.103964   0.023193  -4.483 7.37e-06 ***\nincome      -0.007530   0.008099  -0.930   0.3525    \ndebtinc      0.065253   0.030620   2.131   0.0331 *  \ncreddebt     0.628263   0.113738   5.524 3.32e-08 ***\nothdebt      0.070289   0.077693   0.905   0.3656    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 552.21  on 692  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 568.21\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2.html#réaliser-une-deuxième-régression-logistique-incluant-aussi-la-variable-educ-en-classe.-enregistrer-aussi-les-résultats-de-ce-modèle-qui-est-le-modèle-le-plus-complexe-que-nous-appliquerons-à-ces-données.",
    "href": "td2/td2.html#réaliser-une-deuxième-régression-logistique-incluant-aussi-la-variable-educ-en-classe.-enregistrer-aussi-les-résultats-de-ce-modèle-qui-est-le-modèle-le-plus-complexe-que-nous-appliquerons-à-ces-données.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.5 Réaliser une deuxième régression logistique incluant aussi la variable educ en classe. Enregistrer aussi les résultats de ce modèle, qui est le modèle le plus complexe que nous appliquerons à ces données.",
    "text": "2.5 Réaliser une deuxième régression logistique incluant aussi la variable educ en classe. Enregistrer aussi les résultats de ce modèle, qui est le modèle le plus complexe que nous appliquerons à ces données.\n\n\nCode\nform2 &lt;- update(form1, . ~ . + ed4)\nmod2 &lt;- glm(form2, data=df2, family=binomial(\"logit\"))\nsummary(mod2)\n\n\n\nCall:\nglm(formula = form2, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.469161   0.585721  -2.508   0.0121 *  \nage          0.036527   0.017564   2.080   0.0376 *  \nemploy      -0.259784   0.033353  -7.789 6.76e-15 ***\naddress     -0.105959   0.023331  -4.542 5.58e-06 ***\nincome      -0.007386   0.007927  -0.932   0.3515    \ndebtinc      0.071049   0.030620   2.320   0.0203 *  \ncreddebt     0.616294   0.112296   5.488 4.06e-08 ***\nothdebt      0.052860   0.078374   0.674   0.5000    \ned4.L        0.003376   0.321415   0.011   0.9916    \ned4.Q       -0.334133   0.276144  -1.210   0.2263    \ned4.C       -0.030154   0.249875  -0.121   0.9039    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 550.03  on 689  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 572.03\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2.html#tester-lajustement-de-ce-modèle-complet-grâce-à-la-commande-hoslem.test-où-g-est-le-nombre-de-groupes-de-niveaux-différents-de-fonction-prédictive-utilisé-pour-le-test.-varier-les-valeurs-de-g-pour-vérifier-la-robustesse-du-résultat.",
    "href": "td2/td2.html#tester-lajustement-de-ce-modèle-complet-grâce-à-la-commande-hoslem.test-où-g-est-le-nombre-de-groupes-de-niveaux-différents-de-fonction-prédictive-utilisé-pour-le-test.-varier-les-valeurs-de-g-pour-vérifier-la-robustesse-du-résultat.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.6 Tester l’ajustement de ce modèle complet, grâce à la commande hoslem.test, où g est le nombre de groupes de niveaux différents de fonction prédictive utilisé pour le test. Varier les valeurs de g pour vérifier la robustesse du résultat.",
    "text": "2.6 Tester l’ajustement de ce modèle complet, grâce à la commande hoslem.test, où g est le nombre de groupes de niveaux différents de fonction prédictive utilisé pour le test. Varier les valeurs de g pour vérifier la robustesse du résultat.\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=4)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 2.3796, df = 2, p-value = 0.3043\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=5)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 0.9883, df = 3, p-value = 0.8041\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=6)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.3862, df = 4, p-value = 0.2499\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=7)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 2.0796, df = 5, p-value = 0.838\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=8)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 3.9178, df = 6, p-value = 0.6878\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=9)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.5538, df = 7, p-value = 0.5927\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=10)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.9712, df = 8, p-value = 0.6505"
  },
  {
    "objectID": "td2/td2.html#grâce-à-la-commande-anova-réaliser-un-test-de-rapport-de-vraisemblance-entre-les-deux-modèles-ajustés-et-conclure-sur-la-significativité-de-la-variable-educ.",
    "href": "td2/td2.html#grâce-à-la-commande-anova-réaliser-un-test-de-rapport-de-vraisemblance-entre-les-deux-modèles-ajustés-et-conclure-sur-la-significativité-de-la-variable-educ.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.7 Grâce à la commande anova, réaliser un test de rapport de vraisemblance entre les deux modèles ajustés, et conclure sur la significativité de la variable educ.",
    "text": "2.7 Grâce à la commande anova, réaliser un test de rapport de vraisemblance entre les deux modèles ajustés, et conclure sur la significativité de la variable educ.\n\n\nCode\nanova(mod1, mod2, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt\nModel 2: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt + ed4\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       692     552.21                     \n2       689     550.03  3    2.176   0.5367\n\n\n\nLa p-value = 0.54 → on ne rejette pas \\(H_0\\)​.\nAutrement dit :\n\nl’ajout de la variable d’éducation ed4 n’améliore pas significativement la qualité du modèle."
  },
  {
    "objectID": "td2/td2.html#ôter-la-variable-la-moins-significative-du-modèle-retenu.-vérifier-que-la-p-value-du-test",
    "href": "td2/td2.html#ôter-la-variable-la-moins-significative-du-modèle-retenu.-vérifier-que-la-p-value-du-test",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.8 Ôter la variable la moins significative du modèle retenu. Vérifier que la P-value du test",
    "text": "2.8 Ôter la variable la moins significative du modèle retenu. Vérifier que la P-value du test\nde rapport de vraisemblance entre les modèles avec et sans cette variable est égale ou très proche de la P-value du test bilatéral de nullité du coefficient associé à la variable.\n\n\nCode\nform3 &lt;- update(form1, . ~ . - othdebt)\nmod3 &lt;- glm(form3, data=df2, family=binomial(\"logit\"))\nsummary(mod3)\n\n\n\nCall:\nglm(formula = form3, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.591125   0.522271  -3.047  0.00231 ** \nage          0.033618   0.017383   1.934  0.05312 .  \nemploy      -0.257986   0.030791  -8.379  &lt; 2e-16 ***\naddress     -0.103119   0.023141  -4.456 8.34e-06 ***\nincome      -0.002526   0.006320  -0.400  0.68939    \ndebtinc      0.086173   0.020071   4.293 1.76e-05 ***\ncreddebt     0.595490   0.104930   5.675 1.39e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 553.02  on 693  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 567.02\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\nanova(mod2, mod3, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt + ed4\nModel 2: default_num ~ age + employ + address + income + debtinc + creddebt\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       689     550.03                     \n2       693     553.02 -4  -2.9856   0.5602"
  },
  {
    "objectID": "td2/td2.html#une-variable-est-à-nouveau-très-peu-significative.-ajuster-un-nouveau-modèle-sans-cette-variable.-sauvegarder-les-valeurs-prédites-par-ce-modèle.",
    "href": "td2/td2.html#une-variable-est-à-nouveau-très-peu-significative.-ajuster-un-nouveau-modèle-sans-cette-variable.-sauvegarder-les-valeurs-prédites-par-ce-modèle.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.9 Une variable est à nouveau très peu significative. Ajuster un nouveau modèle sans cette variable. Sauvegarder les valeurs prédites par ce modèle.",
    "text": "2.9 Une variable est à nouveau très peu significative. Ajuster un nouveau modèle sans cette variable. Sauvegarder les valeurs prédites par ce modèle.\n\n\nCode\nform4 &lt;- update(form3, . ~ . - income)\nmod4 &lt;- glm(form4, data=df2, family=binomial(\"logit\"))\nsummary(mod4)\n\n\n\nCall:\nglm(formula = form4, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.63128    0.51268  -3.182  0.00146 ** \nage          0.03256    0.01717   1.896  0.05799 .  \nemploy      -0.26076    0.03011  -8.662  &lt; 2e-16 ***\naddress     -0.10365    0.02309  -4.490 7.13e-06 ***\ndebtinc      0.08926    0.01855   4.813 1.49e-06 ***\ncreddebt     0.57265    0.08723   6.565 5.20e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 553.18  on 694  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 565.18\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\nanova(mod3, mod4, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt\nModel 2: default_num ~ age + employ + address + debtinc + creddebt\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       693     553.02                     \n2       694     553.18 -1 -0.15877   0.6903"
  },
  {
    "objectID": "td2/td2.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-avec-une-règle-de-coupure-à-05",
    "href": "td2/td2.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-avec-une-règle-de-coupure-à-05",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.10 Etablir le tableau de contingence des individus bien ou mal classés avec une règle de coupure à 0,5",
    "text": "2.10 Etablir le tableau de contingence des individus bien ou mal classés avec une règle de coupure à 0,5\n\n\nCode\n# Probabilités prédites\ndf2_nona &lt;- df2 |&gt; drop_na(age, employ, address, income, debtinc, creddebt, othdebt, default_num, ed4)\n\np_hat &lt;- predict(mod4, newdata = df2_nona, type = \"response\")\n\ndf2_nona &lt;- df2_nona |&gt;\n  mutate(\n    p_hat = p_hat,\n    pred_class = if_else(p_hat &gt;= 0.5, 1, 0)\n  )\n\n\ntable(Predicted = df2_nona$pred_class, Observed = df2_nona$default_num)\n\n\n         Observed\nPredicted   0   1\n        0 476  89\n        1  41  94\n\n\nCode\nmean(df2_nona$pred_class == df2_nona$default_num, na.rm = TRUE)\n\n\n[1] 0.8142857"
  },
  {
    "objectID": "td2/td2.html#etablir-la-courbe-roc-pour-le-meilleur-modèle-puis-calculer-les-probabilités-prédites-et-étudier-leur-distribution",
    "href": "td2/td2.html#etablir-la-courbe-roc-pour-le-meilleur-modèle-puis-calculer-les-probabilités-prédites-et-étudier-leur-distribution",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.11 Etablir la courbe ROC pour le « meilleur » modèle, puis calculer les “probabilités prédites” et étudier leur distribution",
    "text": "2.11 Etablir la courbe ROC pour le « meilleur » modèle, puis calculer les “probabilités prédites” et étudier leur distribution\n\n\nCode\nroc_obj &lt;- roc(df2_nona$default_num, df2_nona$p_hat)\n\nplot(roc_obj, main=\"Courbe ROC — Modèle logit 2025\")\n\n\n\n\n\n\n\n\n\nCode\nauc(roc_obj)\n\n\nArea under the curve: 0.8582\n\n\nCode\nggplot(df2_nona, aes(x = p_hat, fill = factor(default_num))) +\n  geom_histogram(alpha = 0.6, position = \"identity\", bins = 30) +\n  labs(title = \"Distribution des probabilités prédites par classe réelle\",\n       x = \"p̂(default = 1)\", fill = \"Défaut observé\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.11.1 Interprétation du graphe\n\nL’axe des abscisses montre les probabilités prédites de défaut \\(\\hat{p} = P(\\text{default}=1|X)\\) .\nL’axe des ordonnées montre le nombre d’individus dans chaque intervalle de probabilité.\nLa couleur rouge (0) représente les emprunteurs qui n’ont pas fait défaut.\nLa couleur bleue (1) représente les emprunteurs qui ont fait défaut."
  },
  {
    "objectID": "td2/td2.html#refaire-la-même-modélisation-avec-un-modèle-probit-et-observer-les-différences-et-ressemblances-avec-la-modélisation-logit.",
    "href": "td2/td2.html#refaire-la-même-modélisation-avec-un-modèle-probit-et-observer-les-différences-et-ressemblances-avec-la-modélisation-logit.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.12 Refaire la même modélisation avec un modèle Probit et observer les différences et ressemblances avec la modélisation Logit.",
    "text": "2.12 Refaire la même modélisation avec un modèle Probit et observer les différences et ressemblances avec la modélisation Logit.\n\n\nCode\nmod_probit &lt;- glm(formula(mod4), data=df2, family=binomial(\"probit\"))\nsummary(mod_probit)\n\n\n\nCall:\nglm(formula = formula(mod4), family = binomial(\"probit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.963869   0.297087  -3.244  0.00118 ** \nage          0.018237   0.009972   1.829  0.06742 .  \nemploy      -0.144955   0.016217  -8.939  &lt; 2e-16 ***\naddress     -0.055609   0.012835  -4.333 1.47e-05 ***\ndebtinc      0.051049   0.010563   4.833 1.35e-06 ***\ncreddebt     0.322172   0.048056   6.704 2.03e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 554.57  on 694  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 566.57\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2.html#pour-aller-plus-loin",
    "href": "td2/td2.html#pour-aller-plus-loin",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.13 Pour aller plus loin…",
    "text": "2.13 Pour aller plus loin…\nSupposant qu’un individu ne remboursant pas son emprunt coûte en moyenne 100000$, et qu’un individu payant son emprunt rapporte en moyenne 40000$, on peut calculer (…) qu’il est optimal de n’accorder un prêt qu’aux individus ayant une probabilité de rembourser estimée à 0,7 ou plus."
  },
  {
    "objectID": "td2/td2.html#règle-de-décision-probabilité-de-remboursement-0.7",
    "href": "td2/td2.html#règle-de-décision-probabilité-de-remboursement-0.7",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.14 Règle de décision (probabilité de remboursement >= 0.7)",
    "text": "2.14 Règle de décision (probabilité de remboursement &gt;= 0.7)\n\n\nCode\ndf2_nona &lt;- df2_nona |&gt; mutate(p_repay = 1 - p_hat, grant = as.numeric(p_repay &gt;= 0.7))\nmean(df2_nona$grant, na.rm = TRUE)\n\n\n[1] 0.64"
  },
  {
    "objectID": "td2/td2.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-en-considérant-comme-défaillants-potentiels-tous-les-individus-ayant-moins-de-70-de-chances-de-rembourser.-commenter-ce-tableau.",
    "href": "td2/td2.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-en-considérant-comme-défaillants-potentiels-tous-les-individus-ayant-moins-de-70-de-chances-de-rembourser.-commenter-ce-tableau.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.15 Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser. Commenter ce tableau.",
    "text": "2.15 Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser. Commenter ce tableau.\n\n\nCode\nthr_default &lt;- 0.3\ntable(Predicted = df2_nona$p_hat &gt;= thr_default, Observed = df2_nona$default_num)\n\n\n         Observed\nPredicted   0   1\n    FALSE 405  43\n    TRUE  112 140\n\n\nCode\ntab &lt;- table(Predicted = df2_nona$p_hat &gt;= thr_default,\n             Observed = df2_nona$default_num)\naccuracy &lt;- sum(diag(tab)) / sum(tab)\naccuracy\n\n\n[1] 0.7785714\n\n\nCode\nprop.table(tab, 2)   # pourcentage par classe observée\n\n\n         Observed\nPredicted         0         1\n    FALSE 0.7833656 0.2349727\n    TRUE  0.2166344 0.7650273\n\n\n\nEn fixant le seuil à 0,3 (c’est-à-dire en considérant comme « défaillant potentiel » tout individu ayant moins de 70 % de chances de rembourser), le modèle devient plus prudent : il classe davantage d’individus comme risqués. Le nombre de vrais positifs (défaillants correctement détectés) augmente, mais au prix d’une hausse des faux positifs (bons payeurs injustement rejetés).\nAutrement dit, la règle minimise les pertes dues aux impayés, mais réduit le volume de prêts accordés. C’est un compromis classique entre risque de crédit et rentabilité :\n\nPlus le seuil est bas, plus la banque protège son portefeuille, mais plus elle refuse de bons clients."
  },
  {
    "objectID": "td3/td3.html",
    "href": "td3/td3.html",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "",
    "text": "Manipuler un modèle logit multinomial nominal (SUBTYPE).\nManipuler un modèle logit ordinal (GRADE).\nSavoir :\n\npréparer les données (codage en facteurs / variables ordinales) ;\nestimer, simplifier et interpréter un modèle ;\ntester :\n\nl’ajustement (Hosmer–Lemeshow multinomial) ;\ndes interactions via test de rapport de vraisemblance (LR).\n\n\n\nDonnées : cancer.dta (288 femmes avec cancer de l’endomètre)."
  },
  {
    "objectID": "td3/td3.html#objectifs-du-td",
    "href": "td3/td3.html#objectifs-du-td",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "",
    "text": "Manipuler un modèle logit multinomial nominal (SUBTYPE).\nManipuler un modèle logit ordinal (GRADE).\nSavoir :\n\npréparer les données (codage en facteurs / variables ordinales) ;\nestimer, simplifier et interpréter un modèle ;\ntester :\n\nl’ajustement (Hosmer–Lemeshow multinomial) ;\ndes interactions via test de rapport de vraisemblance (LR).\n\n\n\nDonnées : cancer.dta (288 femmes avec cancer de l’endomètre)."
  },
  {
    "objectID": "td3/td3.html#introduction",
    "href": "td3/td3.html#introduction",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "2 Introduction",
    "text": "2 Introduction\nUn modèle de régression multinomiale est un modèle Logit ou Probit dans lequel la variable à expliquer \\(Y\\) est une variable qualitative à \\(k &gt; 2\\) modalités. Cette variable peut être qualitative nominale ou ordinale.\n\n2.1 Cas d’une variable expliquée nominale\nDans le cas d’une variable expliquée nominale, on prend n’importe quelle modalité comme modalité de référence (modalité 0), et on estime des pseudo-côtes, c’est-à-dire :\n\n\\(\\displaystyle \\frac{\\Pr(Y = 1)}{\\Pr(Y = 0)}\\)\n\\(\\displaystyle \\frac{\\Pr(Y = 2)}{\\Pr(Y = 0)}\\)\netc.\n\nPar exemple, dans le cas \\(k = 3\\) modalités de \\(Y\\), on a :\n\\(\\Pr(Y = 0) + \\Pr(Y = 1) + \\Pr(Y = 2) = 1\\)\nMAIS \\(\\Pr(Y = 0) + \\Pr(Y = 1) &lt; 1\\) et \\(\\Pr(Y = 0) + \\Pr(Y = 2) &lt; 1\\)\nOn estime alors les paramètres \\(\\beta_g\\) tels que :\n\\[\n\\ln \\left(\\frac{\\Pr(Y = g)}{\\Pr(Y = 0)}\\right)\n= \\beta_{g0} + \\sum_{j=1}^{p} \\beta_{gj} X_j\n\\]\navec \\(g = 1, \\dots, k-1\\).\nOn estime donc :\n\n\\((k - 1)\\) paramètres pour chaque variable explicative quantitative ;\n\\((k - 1)(q - 1)\\) paramètres pour une variable explicative qualitative à \\(q\\) modalités.\n\n\n\n2.2 Cas d’une variable expliquée ordinale\nDans le cas d’une variable expliquée ordinale, \\(Y = 0\\) ou \\(1\\) ou \\(2\\), etc. représente une réponse graduée.\nLa résolution suppose l’existence d’une variable continue sous-jacente \\(Y^*\\), et de \\((k - 1)\\) bornes \\(c_j\\) telles que :\n\nsi \\(y_i^* &lt; c_1\\) alors \\(y_i = 1\\)\nsi \\(c_{j-1} &lt; y_i^* &lt; c_j\\) alors \\(y_i = j\\)\nsi \\(y_i^* &gt; c_{k-1}\\) alors \\(y_i = k\\)\n\nOn a :\n\\[\ny_i^* = X_i B + \\varepsilon_i\n\\]\net on estime conjointement :\n\nles paramètres \\(\\beta_j\\) correspondant à chaque variable explicative ;\nles seuils \\(c_g\\) (\\(g = 1, \\dots, k - 1\\)).\n\nOn prédit alors l’appartenance de chaque individu à chaque classe par les formules :\n\\[\\Pr(Y_i = 0) = \\Phi(c_1 - X_i B)\\]\n\\[\\Pr(Y_i = g) = \\Phi(c_g - X_i B) - \\Phi(c_{g-1} - X_i B)\\]\noù \\(\\Phi\\) est :\n\nla fonction de répartition d’une loi gaussienne centrée réduite dans le cas du modèle Probit multivarié ;\nl’inverse de la fonction Logit dans le cas du Logit multivarié."
  },
  {
    "objectID": "td3/td3.html#présentation-de-létude-et-des-données",
    "href": "td3/td3.html#présentation-de-létude-et-des-données",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "3 Présentation de l’étude et des données",
    "text": "3 Présentation de l’étude et des données\nLes données étudiées proviennent de Hill et al. (1995) et sont utilisées comme exemple dans l’ouvrage de Kleinbaum et Klein.\n\n288 femmes avec un cancer de l’endomètre participent à l’étude.\n\n\n3.1 Dictionnaire des variables\n\nID : identifiant individuel.\nGRADE : variable ordinale indiquant le stade de la tumeur\n\n0 : bien différenciée\n1 : modérément différenciée\n2 : peu différenciée\n\nRACE : variable indicatrice à deux modalités\n\n1 : peau noire\n0 : peau blanche\n\nESTROGEN : variable indicatrice à deux modalités\n\n1 : la femme a déjà pris des œstrogènes\n0 : sinon\n\nSUBTYPE : variable qualitative à trois modalités codant le sous-type de tissu cancéreux\n\n0 : Adénocarcinome\n1 : Adenosquamous\n2 : Autre\n\nAGE : âge recodé en deux classes\n\n0 : 50–64 ans\n1 : 65–79 ans\n\nSMK : variable binaire indiquant le statut tabagique au moment de l’étude\n\n1 : fumeuse\n0 : non-fumeuse\n\n\n\n\n3.2 Références\n\nHill, H.A., Coates, R.J., Austin, H., Correa, P., Robboy, S.J., Chen, V., Click, L.A., Barrett, R.J., Boyce, J.G., Kotz, H.L., and Harlan, L.C., Racial differences in tumor grade among women with endometrial cancer, Gynecol. Oncol. 56: 154–163, 1995.\nDavid G. Kleinbaum, Mitchel Klein, Logistic Regression – A Self‐Learning Text, Third Edition, Springer, 2010."
  },
  {
    "objectID": "td3/td3.html#packages-utilisés",
    "href": "td3/td3.html#packages-utilisés",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "4 Packages utilisés",
    "text": "4 Packages utilisés\n\n\nCode\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(haven)\nlibrary(broom)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(nnet)            # multinom (logit multinomial nominal)\nlibrary(generalhoslem)   # logitgof : test de Hosmer–Lemeshow multinomial\nlibrary(MASS)            # polr : logit ordinal\n\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "td3/td3.html#import-des-données-et-préparation",
    "href": "td3/td3.html#import-des-données-et-préparation",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "5 Import des données et préparation",
    "text": "5 Import des données et préparation\nOn suppose que le fichier cancer.dta se trouve dans le dossier ./data/.\n\n\nCode\ncancer_raw &lt;- read_dta(\"./data/cancer.dta\") |&gt;\n  clean_names()\n\nglimpse(cancer_raw)\n\n\nRows: 288\nColumns: 7\n$ id       &lt;dbl&gt; 10009, 10025, 10038, 10042, 10049, 10113, 10131, 10160, 10164…\n$ grade    &lt;dbl+lbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 2, 1, 2, 2, …\n$ race     &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ estrogen &lt;dbl+lbl&gt; 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, …\n$ subtype  &lt;dbl+lbl&gt; 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, …\n$ age      &lt;dbl+lbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, …\n$ smoking  &lt;dbl+lbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nOn dispose notamment des variables :\n\ngrade (3 modalités ordonnées),\nrace,\nestrogen,\nsubtype,\nage,\nsmoking."
  },
  {
    "objectID": "td3/td3.html#recodage-des-variables",
    "href": "td3/td3.html#recodage-des-variables",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "6 Recodage des variables",
    "text": "6 Recodage des variables\nOn crée des facteurs explicites pour la régression, en choisissant des références cohérentes avec l’énoncé :\n\n\nCode\ncancer &lt;- cancer_raw |&gt;\n  mutate(\n    # convertir les labels Stata en facteurs R\n    grade_f    = as_factor(grade),\n    subtype_f  = as_factor(subtype),\n    race_f     = as_factor(race),\n    estrogen_f = as_factor(estrogen),\n    age_f      = as_factor(age),\n    smk_f      = as_factor(smoking),\n    \n    # forcer l'ordre pour l'ordinal (adapter les noms à ce que tu vois)\n    grade_ord = fct_relevel(\n      grade_f,\n      \"bien différencié\",\n      \"moyennement différencié\",\n      \"peu différencié\"\n    )\n  )\n\ncancer |&gt;\n  dplyr::select(grade, grade_ord, subtype, subtype_f,\n         race_f, estrogen_f, age_f, smk_f) |&gt;\n  head()\n\n\n# A tibble: 6 × 8\n  grade                grade_ord subtype subtype_f race_f estrogen_f age_f smk_f\n  &lt;dbl+lbl&gt;            &lt;fct&gt;     &lt;dbl+l&gt; &lt;fct&gt;     &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;\n1 1 [moyennement diff… moyennem… 1 [ade… adenosqu… blanc… never too… 50-64 yes  \n2 0 [bien différencié] bien dif… 2 [oth… other     blanc… took oest… 50-64 no   \n3 1 [moyennement diff… moyennem… 1 [ade… adenosqu… blanc… never too… 65-79 no   \n4 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… never too… 65-79 no   \n5 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… took oest… 50-64 no   \n6 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… took oest… 65-79 no"
  },
  {
    "objectID": "td3/td3.html#modèle-multinomial-pour-expliquer-subtype",
    "href": "td3/td3.html#modèle-multinomial-pour-expliquer-subtype",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "7 Modèle multinomial pour expliquer SUBTYPE",
    "text": "7 Modèle multinomial pour expliquer SUBTYPE\nVariables explicatives : RACE, ESTROGEN, SMK, AGE.\n\n\n7.1 Estimation du premier modèle (logit multinomial nominal)\n\n\nCode\nmod_sub_full &lt;- multinom(\n  subtype_f ~ race_f + estrogen_f + smk_f + age_f,\n  data = cancer\n)\n\n\n# weights:  18 (10 variable)\ninitial  value 314.203115 \niter  10 value 247.216796\nfinal  value 246.965190 \nconverged\n\n\nCode\nres_sub_ful &lt;- tidy(mod_sub_full,\n                exponentiate = TRUE,  # passe en OR\n                conf.int = TRUE)      # ajoute IC 95%\n\nres_sub_ful\n\n\n# A tibble: 10 × 8\n   y.level       term    estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 adenosquamous (Inter…    0.169     0.447    -3.97  7.18e-5   0.0705     0.407\n 2 adenosquamous race_f…    0.806     0.413    -0.521 6.02e-1   0.359      1.81 \n 3 adenosquamous estrog…    0.483     0.378    -1.93  5.39e-2   0.230      1.01 \n 4 adenosquamous smk_fy…    2.43      0.526     1.69  9.06e-2   0.869      6.82 \n 5 adenosquamous age_f6…    2.66      0.412     2.38  1.75e-2   1.19       5.96 \n 6 other         (Inter…    0.282     0.378    -3.35  8.07e-4   0.134      0.591\n 7 other         race_f…    1.13      0.376     0.319 7.49e-1   0.539      2.36 \n 8 other         estrog…    0.943     0.343    -0.171 8.64e-1   0.482      1.85 \n 9 other         smk_fy…    0.166     1.05     -1.71  8.67e-2   0.0214     1.29 \n10 other         age_f6…    1.33      0.329     0.872 3.83e-1   0.699      2.54 \n\n\n\n\n\nCode\nsummary(mod_sub_full)\n\n\nCall:\nmultinom(formula = subtype_f ~ race_f + estrogen_f + smk_f + \n    age_f, data = cancer)\n\nCoefficients:\n              (Intercept) race_fnoire estrogen_ftook oestrogen treatment\nadenosquamous   -1.775326  -0.2151038                        -0.72813726\nother           -1.266281   0.1201888                        -0.05867755\n               smk_fyes age_f65-79\nadenosquamous  0.889793  0.9780758\nother         -1.793171  0.2865677\n\nStd. Errors:\n              (Intercept) race_fnoire estrogen_ftook oestrogen treatment\nadenosquamous   0.4471631   0.4127306                          0.3777940\nother           0.3779403   0.3762200                          0.3425219\n               smk_fyes age_f65-79\nadenosquamous 0.5257988  0.4117731\nother         1.0467384  0.3285697\n\nResidual Deviance: 493.9304 \nAIC: 513.9304 \n\n\nOn obtient, pour chaque modalité \\(g\\) \\(\\neq\\) référence, une équation :\n\\(\\log \\frac{P(\\text{SUBTYPE}=g)}{P(\\text{SUBTYPE}=\\text{adenocarcinomous})} = \\beta{g0} + \\beta{g,\\text{race}} + \\dots\\)\n\nÀ caractéristiques identiques (race, oestrogènes, âge), les fumeuses ont environ 2,4 fois plus de chances (odds) d’avoir un cancer adenosquamous plutôt que le sous-type de référence, comparées aux non fumeuses.\n\n\n\n\n7.2 Résumé et odds-ratios\n\n\nCode\nres_sub_full &lt;- tidy(mod_sub_full, exponentiate = TRUE, conf.int = TRUE)\nres_sub_full\n\n\n# A tibble: 10 × 8\n   y.level       term    estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 adenosquamous (Inter…    0.169     0.447    -3.97  7.18e-5   0.0705     0.407\n 2 adenosquamous race_f…    0.806     0.413    -0.521 6.02e-1   0.359      1.81 \n 3 adenosquamous estrog…    0.483     0.378    -1.93  5.39e-2   0.230      1.01 \n 4 adenosquamous smk_fy…    2.43      0.526     1.69  9.06e-2   0.869      6.82 \n 5 adenosquamous age_f6…    2.66      0.412     2.38  1.75e-2   1.19       5.96 \n 6 other         (Inter…    0.282     0.378    -3.35  8.07e-4   0.134      0.591\n 7 other         race_f…    1.13      0.376     0.319 7.49e-1   0.539      2.36 \n 8 other         estrog…    0.943     0.343    -0.171 8.64e-1   0.482      1.85 \n 9 other         smk_fy…    0.166     1.05     -1.71  8.67e-2   0.0214     1.29 \n10 other         age_f6…    1.33      0.329     0.872 3.83e-1   0.699      2.54 \n\n\nIci, estimate = odds-ratio, conf.low / conf.high = IC 95 %.\n\n\n\n7.3 Probabilités prédites\nOn génère les probabilités prédites pour chaque modalité de SUBTYPE :\n\n\nCode\nphat_sub &lt;- predict(mod_sub_full, type = \"probs\")\nhead(phat_sub)\n\n\n  adenocarcinomous adenosquamous      other\n1        0.6852096     0.2826449 0.03214548\n2        0.7420517     0.0607007 0.19724761\n3        0.5476498     0.2467524 0.20559787\n4        0.5476498     0.2467524 0.20559787\n5        0.7420517     0.0607007 0.19724761\n6        0.6363103     0.1384208 0.22526893\n\n\nCode\ncolMeans(phat_sub)  # moyennes des proba par modalité\n\n\nadenocarcinomous    adenosquamous            other \n       0.6433555        0.1573435        0.1993010 \n\n\n\nOn recolle ces probabilités aux données :\n\n\nCode\n# 1) Sous-échantillon sans NA sur les variables du modèle\ncancer_complete &lt;- cancer |&gt;\n  drop_na(subtype_f, race_f, estrogen_f, smk_f, age_f)\n\n\n# 2) Modèle multinomial sur cancer_complete\nmod_sub_full &lt;- multinom(\n  subtype_f ~ race_f + estrogen_f + smk_f + age_f,\n  data = cancer_complete\n)\n\n\n# weights:  18 (10 variable)\ninitial  value 314.203115 \niter  10 value 247.216796\nfinal  value 246.965190 \nconverged\n\n\n\n\n\nCode\n# 3) Probabilités prédites (286 x 3)\nphat_sub &lt;- predict(mod_sub_full, type = \"probs\")\ncolMeans(phat_sub)\n\n\nadenocarcinomous    adenosquamous            other \n       0.6433555        0.1573435        0.1993010 \n\n\n\n\nCode\n# 4) On transforme en tibble et on renomme\nphat_sub_tbl &lt;- as_tibble(phat_sub)\nnames(phat_sub_tbl) &lt;- paste0(\"p_\", levels(cancer_complete$subtype_f))\n# ex : \"p_adenocarcinomous\" \"p_adenosquamous\" \"p_other\"\n\n# 5) On colle aux données *complètes* (286 lignes)\ncancer_sub &lt;- bind_cols(cancer_complete, phat_sub_tbl)\n\ncancer_sub |&gt;\n  dplyr::select(subtype_f, starts_with(\"p_\")) |&gt;\n  slice(1:5)\n\n\n# A tibble: 5 × 4\n  subtype_f        p_adenocarcinomous p_adenosquamous p_other\n  &lt;fct&gt;                         &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n1 adenosquamous                 0.685          0.283   0.0321\n2 other                         0.742          0.0607  0.197 \n3 adenosquamous                 0.548          0.247   0.206 \n4 adenocarcinomous              0.548          0.247   0.206 \n5 adenocarcinomous              0.742          0.0607  0.197 \n\n\n\n\n\n7.4 Test d’ajustement (Hosmer–Lemeshow multinomial)\nOn utilise logitgof() du package generalhoslem.\n\nobs : modalités de SUBTYPE sous forme numérique (1, 2, 3).\nexp : matrice de probabilités prédites.\ng : nombre de groupes (à ajuster si nécessaire).\n\n\n\nCode\ny_num   &lt;- as.numeric(cancer_sub$subtype_f)\nexp_mat &lt;- as.matrix(phat_sub)\n\n# Exemple avec 10 groupes\ngof_10 &lt;- logitgof(obs = y_num, exp = exp_mat, g = 10)\ngof_10\n\n\n\n    Hosmer and Lemeshow test (multinomial model)\n\ndata:  y_num, exp_mat\nX-squared = 4.0727, df = 10, p-value = 0.944\n\n\n\nLe test de Hosmer–Lemeshow (généralisé au multinomial et implémenté par logitgof() dans generalhoslem) compare, dans des groupes de probabilités prédites similaires, les effectifs observés de chaque catégorie de la variable dépendante aux effectifs attendus selon le modèle. La statistique de test est de type χ². Une grande p-value indique que l’on ne détecte pas de mauvais ajustement global du modèle aux données ; une petite p-value suggère un manque d’adéquation (modèle mal calibré).\n\n\nSi le test ne passe pas (classes attendues trop petites), on réduit le nombre de groupes :\n\n\nCode\nlibrary(purrr)\n\nmap_df(4:10, ~{\n  out &lt;- try(logitgof(y_num, exp_mat, g = .x), silent = TRUE)\n  tibble(\n    g       = .x,\n    stat    = if (inherits(out, \"try-error\")) NA_real_ else out$statistic,\n    p_value = if (inherits(out, \"try-error\")) NA_real_ else out$p.value\n  )\n})\n\n\n# A tibble: 7 × 3\n      g  stat p_value\n  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     4  1.69  0.792 \n2     5  2.01  0.735 \n3     6 15.7   0.0474\n4     7  2.63  0.955 \n5     8  2.63  0.955 \n6     9 16.5   0.170 \n7    10  4.07  0.944 \n\n\n\nLecture :\n\np-value grande → pas d’évidence de mauvais ajustement.\np-value petite → modèle mal ajusté (au moins pour certains groupes).\n\n\nEn diminuant le nombre de groupes, le test Hosmer–Lemeshow devient applicable. Les p-values varient avec g, ce qui montre que le test est assez instable dans ce petit échantillon multinomial. Néanmoins, pour la plupart des partitions (g = 4, 5, 7, 8, 9, 10), on ne rejette pas l’hypothèse d’un bon ajustement (p-value &gt; 5 %). On peut donc conclure qu’il n’y a pas de signe clair de mauvais ajustement du modèle aux données, tout en rappelant que ce test doit être interprété avec prudence.\n\n\n\n\n7.5 Simplification du modèle (tests LR)\nOn cherche un modèle plus parcimonieux en retirant les variables non significatives.\nExemple : on teste si on peut retirer smk_f puis age_f\n\n\nCode\n# Modèle sans SMK\nmod_sub_nosmk &lt;- multinom(\n  subtype_f ~ race_f + estrogen_f + age_f,\n  data = cancer\n)\n\n\n# weights:  15 (8 variable)\ninitial  value 314.203115 \niter  10 value 251.550761\nfinal  value 251.468001 \nconverged\n\n\nCode\n# Test LR : mod_sub_nosmk vs mod_sub_full\nanova(mod_sub_nosmk, mod_sub_full)\n\n\nLikelihood ratio tests of Multinomial Models\n\nResponse: subtype_f\n                                Model Resid. df Resid. Dev   Test    Df\n1         race_f + estrogen_f + age_f       564   502.9360             \n2 race_f + estrogen_f + smk_f + age_f       562   493.9304 1 vs 2     2\n  LR stat.    Pr(Chi)\n1                    \n2 9.005622 0.01107781\n\n\nTest 1 : peut-on retirer smk_f ?\n\nModèles comparés :\n\nModèle réduit : subtype_f ~ race_f + estrogen_f + age_f\nModèle complet : subtype_f ~ race_f + estrogen_f + smk_f + age_f\n\nRésultat du test LR :\n\nÀ 5 %, on rejette H₀ “on peut enlever smk_f” : le tabagisme (smk_f) apporte une information significative pour expliquer le sous-type de cancer → on garde smk_f.\n\n\n\n\nCode\n# Modèle sans AGE (à partir du modèle sans SMK par exemple)\nmod_sub_noage &lt;- multinom(\n  subtype_f ~ race_f + estrogen_f + smk_f,\n  data = cancer\n)\n\n\n# weights:  15 (8 variable)\ninitial  value 314.203115 \niter  10 value 250.492692\nfinal  value 250.192192 \nconverged\n\n\nCode\nanova(mod_sub_noage, mod_sub_full)\n\n\nLikelihood ratio tests of Multinomial Models\n\nResponse: subtype_f\n                                Model Resid. df Resid. Dev   Test    Df\n1         race_f + estrogen_f + smk_f       564   500.3844             \n2 race_f + estrogen_f + smk_f + age_f       562   493.9304 1 vs 2     2\n  LR stat.    Pr(Chi)\n1                    \n2 6.454004 0.03967628\n\n\n\nInterprétation :\n\nSi la p-value du test LR est &gt; 5 %, on ne rejette pas \\(H_0\\) : le modèle réduit n’est pas significativement pire → on peut retirer la variable.\nOn garde donc smk_f mais pas age\n\n\nLes degrés de liberté du test de rapport de vraisemblance sont égaux au nombre de paramètres supprimés entre le modèle complet et le modèle réduit.\nDans un modèle multinomial, retirer une variable facteur à \\(L\\) modalités enlève \\((J-1)(L-1)\\) coefficients, donc \\((J-1)(L-1)\\) degrés de liberté. \\(J\\) catégories et \\(L\\) modalités.\n\n\n\n\n7.6 Test meilleur modèle\nOn teste sur les deux variables restantes\n\n\nCode\n# Modèle sans RACE (à partir du modèle sans SMK par exemple)\nmod_sub_norace &lt;- multinom(\n  subtype_f ~ age_f + estrogen_f + smk_f,\n  data = cancer\n)\n\n\n# weights:  15 (8 variable)\ninitial  value 314.203115 \niter  10 value 247.380882\nfinal  value 247.202541 \nconverged\n\n\nCode\nanova(mod_sub_norace, mod_sub_full)\n\n\nLikelihood ratio tests of Multinomial Models\n\nResponse: subtype_f\n                                Model Resid. df Resid. Dev   Test    Df\n1          age_f + estrogen_f + smk_f       564   494.4051             \n2 race_f + estrogen_f + smk_f + age_f       562   493.9304 1 vs 2     2\n   LR stat.   Pr(Chi)\n1                    \n2 0.4747033 0.7887139\n\n\n\nOn retire la variable estrogen pour expliquer SUBTYPE :\n\n\nCode\n# 1) Construire un sous-échantillon complet pour toutes les variables en jeu\ncancer_lr &lt;- cancer |&gt;\n  filter(\n    !is.na(subtype_f),\n    !is.na(age_f),\n    !is.na(race_f),\n    !is.na(smk_f),\n    !is.na(estrogen_f)   # même si tu ne l'utilises pas dans tous les modèles\n  )\n\n# 2) Re-estimer les modèles sur CE MÊME jeu de données\nmod_sub_full &lt;- multinom(\n  subtype_f ~ age_f + race_f + smk_f + estrogen_f,\n  data = cancer_lr\n)\n\n\n# weights:  18 (10 variable)\ninitial  value 314.203115 \niter  10 value 247.216796\nfinal  value 246.965190 \nconverged\n\n\nCode\nmod_sub_noestro &lt;- multinom(\n  subtype_f ~ age_f + race_f + smk_f,\n  data = cancer_lr\n)\n\n\n# weights:  15 (8 variable)\ninitial  value 314.203115 \niter  10 value 249.150731\nfinal  value 248.865000 \nconverged\n\n\nCode\n# 3) Maintenant, le test LR fonctionne\nanova(mod_sub_noestro, mod_sub_full, test = \"Chisq\")\n\n\nLikelihood ratio tests of Multinomial Models\n\nResponse: subtype_f\n                                Model Resid. df Resid. Dev   Test    Df\n1              age_f + race_f + smk_f       564   497.7300             \n2 age_f + race_f + smk_f + estrogen_f       562   493.9304 1 vs 2     2\n  LR stat.   Pr(Chi)\n1                   \n2 3.799621 0.1495969\n\n\n\nLa fonction se base uniquement sur les résultats passés (modèles déjà estimés)\net sélectionne celui qui minimise l’AIC (ou le BIC).\n\n\n\n\n7.7 Interprétation économique du modèle final\n\n\nCode\nmod_sub_final &lt;- multinom(\n  subtype_f ~ age_f + smk_f,\n  data = cancer\n)\n\n\n# weights:  12 (6 variable)\ninitial  value 316.400339 \niter  10 value 250.030104\nfinal  value 250.024195 \nconverged\n\n\nCode\nres_sub &lt;- tidy(mod_sub_final,\n                exponentiate = TRUE,  # passe en OR\n                conf.int = TRUE)      # ajoute IC 95%\n\nres_sub\n\n\n# A tibble: 6 × 8\n  y.level       term     estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;         &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 adenosquamous (Interc…    0.111     0.374    -5.88  4.16e-9   0.0535     0.231\n2 adenosquamous age_f65…    2.67      0.409     2.40  1.63e-2   1.20       5.95 \n3 adenosquamous smk_fyes    2.36      0.520     1.65  9.83e-2   0.853      6.54 \n4 other         (Interc…    0.283     0.271    -4.66  3.10e-6   0.166      0.481\n5 other         age_f65…    1.30      0.328     0.812 4.17e-1   0.686      2.48 \n6 other         smk_fyes    0.167     1.05     -1.71  8.69e-2   0.0214     1.30 \n\n\nPrincipe d’interprétation :\n\nUn odds-ratio &gt; 1 pour une modalité donnée signifie que la variable augmente les cotes d’appartenir à ce type de cancer par rapport à la référence (adenocarcinomous), toutes choses égales par ailleurs.\nUn odds-ratio &lt; 1 signifie au contraire une diminution des cotes.\n\n\n\n\n7.8 Tableau de contingence des individus bien / mal classés\n\n7.8.1 (a) Effectifs par type de tumeur observée\n\n\nCode\ncancer_sub |&gt;\n  count(subtype_f)\n\n\n# A tibble: 3 × 2\n  subtype_f            n\n  &lt;fct&gt;            &lt;int&gt;\n1 adenocarcinomous   184\n2 adenosquamous       45\n3 other               57\n\n\n\n\n\n7.8.2 (b) Classe prédite par « probabilité max » (règle du 1er choix)\nOn attribue à chaque individu la classe prédite correspondant à la probabilité la plus élevée :\n\n\nCode\nphat_sub &lt;- predict(mod_sub_final, type = \"probs\")\ncolMeans(phat_sub)\n\n\nadenocarcinomous    adenosquamous            other \n       0.6458337        0.1562522        0.1979141 \n\n\nCode\nphat_sub_tbl &lt;- as_tibble(phat_sub)\nnames(phat_sub_tbl) &lt;- paste0(\"p_\", levels(cancer_complete$subtype_f))\n# ex : \"p_adenocarcinomous\" \"p_adenosquamous\" \"p_other\"\n\ncancer &lt;- bind_cols(cancer, phat_sub_tbl)\n\n# vecteur des probas sous forme de matrice\nprobs_mat &lt;- as.matrix(\n  cancer[, c(\"p_adenocarcinomous\", \"p_adenosquamous\", \"p_other\")]\n)\n\n# indices de la proba max par individu (1, 2 ou 3)\nidx_max &lt;- max.col(probs_mat)\n\n# noms des modalités dans le bon ordre\nlev &lt;- c(\"adenocarcinomous\", \"adenosquamous\", \"other\")\n\ncancer &lt;- cancer |&gt;\n  mutate(\n    pred_subtype = factor(lev[idx_max],\n                          levels = levels(subtype_f))\n  )\n\ncancer |&gt;\n  dplyr::select(subtype_f, pred_subtype, starts_with(\"p_\")) |&gt;\n  slice(1:5)\n\n\n# A tibble: 5 × 5\n  subtype_f        pred_subtype     p_adenocarcinomous p_adenosquamous p_other\n  &lt;fct&gt;            &lt;fct&gt;                         &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n1 adenosquamous    adenocarcinomous              0.763          0.201   0.0360\n2 other            adenocarcinomous              0.717          0.0798  0.203 \n3 adenosquamous    adenocarcinomous              0.600          0.178   0.221 \n4 adenocarcinomous adenocarcinomous              0.600          0.178   0.221 \n5 adenocarcinomous adenocarcinomous              0.717          0.0798  0.203 \n\n\n\n\n\nCode\ntab_sub &lt;- table(\n  Observed  = cancer$subtype_f,\n  Predicted = cancer$pred_subtype\n)\n\ntab_sub\n\n\n                  Predicted\nObserved           adenocarcinomous adenosquamous other\n  adenocarcinomous              186             0     0\n  adenosquamous                  45             0     0\n  other                          57             0     0\n\n\nCode\nprop_ok &lt;- sum(diag(tab_sub)) / sum(tab_sub)\n1-prop_ok\n\n\n[1] 0.3541667"
  },
  {
    "objectID": "td3/td3.html#b.-modèle-ordinal-pour-expliquer-grade",
    "href": "td3/td3.html#b.-modèle-ordinal-pour-expliquer-grade",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "8 B. Modèle ordinal pour expliquer GRADE",
    "text": "8 B. Modèle ordinal pour expliquer GRADE\nOn modélise le stade de la tumeur (bien / moyennement / peu différenciée) en fonction de :\n\nRACE, ESTROGEN, SUBTYPE, AGE, SMK.\n\n\n\n8.1 Modèle de base (logit ordinal)\nOn utilise polr() (MASS) avec grade_ord comme variable ordinale.\n\n\nCode\nmod_grade_base &lt;- polr(\n  grade_ord ~ race_f + estrogen_f + subtype_f + age_f + smk_f,\n  data = cancer,\n  Hess = TRUE\n)\n\nsummary(mod_grade_base)\n\n\nCall:\npolr(formula = grade_ord ~ race_f + estrogen_f + subtype_f + \n    age_f + smk_f, data = cancer, Hess = TRUE)\n\nCoefficients:\n                                      Value Std. Error  t value\nrace_fnoire                         0.59764     0.2790  2.14222\nestrogen_ftook oestrogen treatment -0.61411     0.2549 -2.40904\nsubtype_fadenosquamous              1.78110     0.3252  5.47653\nsubtype_fother                      0.07823     0.2991  0.26153\nage_f65-79                          0.13110     0.2486  0.52742\nsmk_fyes                            0.01358     0.3992  0.03401\n\nIntercepts:\n                                         Value   Std. Error t value\nbien différencié|moyennement différencié -0.0205  0.2890    -0.0708\nmoyennement différencié|peu différencié   1.9682  0.3196     6.1589\n\nResidual Deviance: 540.4501 \nAIC: 556.4501 \n(2 observations deleted due to missingness)\n\n\nLes sorties donnent :\n\nLes coefficients \\(\\beta\\) (effets sur le score latent),\nLes seuils (cutpoints) séparant les catégories de GRADE.\n\n\n\n\n8.2 Test d’ajustement via interactions (LR tests)\n\n8.2.1 Interaction ESTROGEN × SUBTYPE\nOn ajoute l’interaction estrogen_f * subtype_f :\n\n\nCode\nmod_grade_es &lt;- polr(\n  grade_ord ~ race_f + estrogen_f * subtype_f + age_f + smk_f,\n  data = cancer,\n  Hess = TRUE\n)\n\nanova(mod_grade_base, mod_grade_es)\n\n\nLikelihood ratio tests of ordinal regression models\n\nResponse: grade_ord\n                                            Model Resid. df Resid. Dev   Test\n1 race_f + estrogen_f + subtype_f + age_f + smk_f       278   540.4501       \n2 race_f + estrogen_f * subtype_f + age_f + smk_f       276   537.5181 1 vs 2\n     Df LR stat.   Pr(Chi)\n1                         \n2     2 2.932012 0.2308457\n\n\n\nanova() réalise un test LR entre modèle sans interaction (mod_grade_base) et modèle avec interaction (mod_grade_es).\nOn lit la p-value :\n\nsi petite → l’interaction améliore le modèle ;\nsi grande → on peut s’en passer.\n\n\n\n\n\n8.2.2 Autres interactions possibles\nOn peut tester d’autres interactions pertinentes, par exemple :\n\nESTROGEN × AGE :\n\n\n\nCode\nmod_grade_eage &lt;- polr(\n  grade_ord ~ race_f + estrogen_f * age_f + subtype_f + smk_f,\n  data = cancer,\n  Hess = TRUE\n)\n\nanova(mod_grade_base, mod_grade_eage)\n\n\nLikelihood ratio tests of ordinal regression models\n\nResponse: grade_ord\n                                            Model Resid. df Resid. Dev   Test\n1 race_f + estrogen_f + subtype_f + age_f + smk_f       278   540.4501       \n2 race_f + estrogen_f * age_f + subtype_f + smk_f       277   539.2085 1 vs 2\n     Df LR stat.   Pr(Chi)\n1                         \n2     1 1.241621 0.2651588\n\n\n\n\nSUBTYPE × AGE :\n\n\n\nCode\nmod_grade_sage &lt;- polr(\n  grade_ord ~ race_f + estrogen_f + subtype_f * age_f + smk_f,\n  data = cancer,\n  Hess = TRUE\n)\n\nanova(mod_grade_base, mod_grade_sage)\n\n\nLikelihood ratio tests of ordinal regression models\n\nResponse: grade_ord\n                                            Model Resid. df Resid. Dev   Test\n1 race_f + estrogen_f + subtype_f + age_f + smk_f       278   540.4501       \n2 race_f + estrogen_f + subtype_f * age_f + smk_f       276   538.9157 1 vs 2\n     Df LR stat.   Pr(Chi)\n1                         \n2     2 1.534397 0.4643119\n\n\nPour chaque interaction :\n\nSi la p-value LR est faible → interaction importante → à garder ;\nSinon → pas de gain significatif → on privilégie le modèle sans interaction.\n\n\n\n\n\n8.3 Sélection de modèle\n\n\nCode\nsummary(mod_grade_base)\n\n\nCall:\npolr(formula = grade_ord ~ race_f + estrogen_f + subtype_f + \n    age_f + smk_f, data = cancer, Hess = TRUE)\n\nCoefficients:\n                                      Value Std. Error  t value\nrace_fnoire                         0.59764     0.2790  2.14222\nestrogen_ftook oestrogen treatment -0.61411     0.2549 -2.40904\nsubtype_fadenosquamous              1.78110     0.3252  5.47653\nsubtype_fother                      0.07823     0.2991  0.26153\nage_f65-79                          0.13110     0.2486  0.52742\nsmk_fyes                            0.01358     0.3992  0.03401\n\nIntercepts:\n                                         Value   Std. Error t value\nbien différencié|moyennement différencié -0.0205  0.2890    -0.0708\nmoyennement différencié|peu différencié   1.9682  0.3196     6.1589\n\nResidual Deviance: 540.4501 \nAIC: 556.4501 \n(2 observations deleted due to missingness)\n\n\n\n\n\n8.4 Interprétation du modèle ordinal final\n\nRace (noire vs non noire)\n\nCoefficient = 0,60 (t ≈ 2,14) → significatif.\nLes femmes noires ont des cotes ≈ 1,8 fois plus élevées d’avoir un grade plus mauvais (passer vers “moyennement/peu différencié”), toutes choses égales par ailleurs.\n\nTraitement aux œstrogènes (oui vs non)\n\nCoefficient = −0,61 (t ≈ −2,41) → significatif.\nLes femmes ayant reçu un traitement œstrogénique ont des cotes ≈ divisées par 2 d’avoir un grade plus mauvais. → Le traitement est associé à des grades un peu meilleurs.\n\nSous-type tumoral (réf. = adenocarcinomous)\n\nadenosquamous : coef = 1,78 (t ≈ 5,48) → très significatif.\n→ Cotes ≈ 6 fois plus élevées d’avoir un grade plus défavorable que l’adenocarcinome.\nother : effet faible et non significatif.\n\nÂge (65–79 ans) et tabagisme (smk_fyes)\n\nCoefficients proches de 0, t très faibles → pas d’association significative avec le grade, une fois contrôlé pour race, sous-type et œstrogènes."
  },
  {
    "objectID": "td3/td3.html#conclusion-td3",
    "href": "td3/td3.html#conclusion-td3",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "9 Conclusion TD3",
    "text": "9 Conclusion TD3\n\nOn a estimé :\n\nun logit multinomial nominal pour SUBTYPE ;\nun logit ordinal pour GRADE.\n\nOn a :\n\ntesté l’ajustement du modèle nominal via un Hosmer–Lemeshow multinomial ;\nutilisé des tests de rapport de vraisemblance pour :\n\nsimplifier les modèles (variables non significatives),\ntester l’intérêt d’interactions dans le modèle ordinal ;\n\nChoisi les spécifications finales.\n\n\nÀ retenir :\n\nPour les variables nominales, on compare chaque modalité à une référence via des odds-ratios.\nPour les variables ordinales, le modèle logit/probit ordonné repose sur une variable latente et des seuils, avec une interprétation en termes de tendance vers des catégories plus élevées ou plus basses."
  },
  {
    "objectID": "site.html",
    "href": "site.html",
    "title": "Modélisation statistique — Travaux Dirigés (M2)",
    "section": "",
    "text": "Ce site rassemble les trois TDs du module de modélisation statistique (M2).\nChaque page de TD contient l’énoncé, des rappels méthodologiques, et des indications Stata.\n\n\n\n\n\n\nConseils généraux\n\n\n\n\nConservez une trace reproductible de vos commandes (do-file ou Quarto).\nComparez systématiquement les modèles via tests d’ajustement (GOF, LR) et critères d’information (AIC/BIC).\n\n\n\n\n\n\n\n\n\n\n\nRégression log-linéaire sur mortalité par cancer du poumon, ajustement (deviance, Pearson), comparaison de modèles et interprétation via IRR.\nOuvrir l’énoncé TD 1\n\n\n\n\n\n\n\nModélisation du risque de défaut, GOF, Logit/Probit, ROC/AUC et seuils.\nOuvrir l’énoncé TD 2\n\n\n\n\n\n\n\nModèles multinomial et ordinal, interactions, tests et sélection (AIC).\nOuvrir l’énoncé TD 3\n\n\n\n\n\n\n\n\n\n\nSupport et consignes : chaque page de TD précise les données, commandes clés et livrables attendus.\n\nLogiciels : R, si besoin ce référer à ce tutoriel pour utiliser R.\n\nÉvaluation : clarté des commentaires, qualité des comparaisons de modèles, et interprétations économétriques.\n\n\n\n\n\n\n\nNote\n\n\n\nRessources utiles\n\nRévisions probabilité/GLM : notes de cours & fiches méthodes.\nBonnes pratiques : do-files commentés, tableaux lisibles, graphes annotés.\n\n\n\n\n\n\n\nTD 1 — Poisson (tabac & cancer du poumon) : encodage des facteurs, modèle log-linéaire, GOF (deviance/Pearson), LR tests, interprétation en ratios d’incidence.\n\nTD 2 — Logit (crédit) : recodage binaire de la variable dépendante, GOF groupé, lrtest entre modèles imbriqués, ROC/AUC, comparaison Logit/Probit, seuil optimal.\n\nTD 3 — Multinomial/Ordinal (endomètre) : mlogit sur sous-types, prédictions et matrice de classification, ologit sur le grade, tests d’interactions, sélection par AIC."
  },
  {
    "objectID": "site.html#accès-rapide-aux-tds",
    "href": "site.html#accès-rapide-aux-tds",
    "title": "Modélisation statistique — Travaux Dirigés (M2)",
    "section": "",
    "text": "Régression log-linéaire sur mortalité par cancer du poumon, ajustement (deviance, Pearson), comparaison de modèles et interprétation via IRR.\nOuvrir l’énoncé TD 1\n\n\n\n\n\n\n\nModélisation du risque de défaut, GOF, Logit/Probit, ROC/AUC et seuils.\nOuvrir l’énoncé TD 2\n\n\n\n\n\n\n\nModèles multinomial et ordinal, interactions, tests et sélection (AIC).\nOuvrir l’énoncé TD 3"
  },
  {
    "objectID": "site.html#organisation-20252026",
    "href": "site.html#organisation-20252026",
    "title": "Modélisation statistique — Travaux Dirigés (M2)",
    "section": "",
    "text": "Support et consignes : chaque page de TD précise les données, commandes clés et livrables attendus.\n\nLogiciels : R, si besoin ce référer à ce tutoriel pour utiliser R.\n\nÉvaluation : clarté des commentaires, qualité des comparaisons de modèles, et interprétations économétriques.\n\n\n\n\n\n\n\nNote\n\n\n\nRessources utiles\n\nRévisions probabilité/GLM : notes de cours & fiches méthodes.\nBonnes pratiques : do-files commentés, tableaux lisibles, graphes annotés."
  },
  {
    "objectID": "site.html#données-et-rappel-des-contenus",
    "href": "site.html#données-et-rappel-des-contenus",
    "title": "Modélisation statistique — Travaux Dirigés (M2)",
    "section": "",
    "text": "TD 1 — Poisson (tabac & cancer du poumon) : encodage des facteurs, modèle log-linéaire, GOF (deviance/Pearson), LR tests, interprétation en ratios d’incidence.\n\nTD 2 — Logit (crédit) : recodage binaire de la variable dépendante, GOF groupé, lrtest entre modèles imbriqués, ROC/AUC, comparaison Logit/Probit, seuil optimal.\n\nTD 3 — Multinomial/Ordinal (endomètre) : mlogit sur sous-types, prédictions et matrice de classification, ologit sur le grade, tests d’interactions, sélection par AIC."
  },
  {
    "objectID": "td1/enonce-td1.html",
    "href": "td1/enonce-td1.html",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "",
    "text": "On étudie d’anciennes données reliant tabagisme et décès par cancer du poumon.\nVariables : age (classes), smoking status (4 classes), population (centaines de milliers), deaths (décès annuels)."
  },
  {
    "objectID": "td1/enonce-td1.html#objectifs-de-ce-td",
    "href": "td1/enonce-td1.html#objectifs-de-ce-td",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "2.1 Objectifs de ce TD",
    "text": "2.1 Objectifs de ce TD\n\nImporter et préparer un tableau « comptages + exposition » (population à risque).\nAjuster un GLM Poisson avec offset (log-exposition).\nÉvaluer l’ajustement : déviance (vs modèle saturé) & Pearson.\nComparer des modèles via tests de rapport de vraisemblance (LR).\nInterpréter en ratios de taux d’incidence (IRR) et produire des comptes attendus."
  },
  {
    "objectID": "td1/enonce-td1.html#modèle-de-base",
    "href": "td1/enonce-td1.html#modèle-de-base",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.1 Modèle de base",
    "text": "4.1 Modèle de base\n\nAjuster un modèle Poisson log-linéaire avec effets de smoking_status et age et offset log(exposure).\n\nQ1 : Pourquoi utiliser des variables indicatrices plutôt que des codes numériques continus ?\n\nCalculer la déviance du modèle ajusté.\n\nQ2 : Interpréter la déviance et le p-value (DEV1).\n\nInterpréter l’effet de l’âge sur la probabilité de décès.\n\nQ3 : Que disent les coefficients d’âge en termes d’IRR ?"
  },
  {
    "objectID": "td1/enonce-td1.html#ajustement-du-modèle",
    "href": "td1/enonce-td1.html#ajustement-du-modèle",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.2 Ajustement du modèle",
    "text": "4.2 Ajustement du modèle\n\nRéaliser les deux tests d’ajustement : déviance GOF et Pearson GOF.\n\nQ4 : Justifier les degrés de liberté.\nQ5 : Discuter les conditions d’application du test du χ²."
  },
  {
    "objectID": "td1/enonce-td1.html#comparaison-de-modèles",
    "href": "td1/enonce-td1.html#comparaison-de-modèles",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.3 Comparaison de modèles",
    "text": "4.3 Comparaison de modèles\n\nAjuster un modèle sans la variable tabac et effectuer un test LR entre les deux modèles.\n\nQ6 : Conclure sur l’impact de l’usage du tabac sur la probabilité de décès."
  },
  {
    "objectID": "td1/enonce-td1.html#variable-binaire-cigarette",
    "href": "td1/enonce-td1.html#variable-binaire-cigarette",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.4 Variable binaire « cigarette »",
    "text": "4.4 Variable binaire « cigarette »\n\nCréer une variable binaire cigarette_user (=1 si l’individu fume des cigarettes, 0 sinon).\nAjuster un modèle avec age + cigarette_user.\nComparer ce modèle avec le modèle initial par un test LR.\n\nQ7 : Le type de produit fumé influence-t-il différemment le taux de décès ?"
  },
  {
    "objectID": "td1/enonce-td1.html#extensions-facultatif",
    "href": "td1/enonce-td1.html#extensions-facultatif",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.5 Extensions (facultatif)",
    "text": "4.5 Extensions (facultatif)\n\nCalculer et présenter les IRR avec IC à 95 %.\nPrésenter les comptes observés vs attendus et commenter.\nVérifier la présence éventuelle de sur-dispersion et proposer, si nécessaire, un modèle adapté (Quasi-Poisson ou Négative Binomiale)."
  },
  {
    "objectID": "td1/td1.html",
    "href": "td1/td1.html",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "",
    "text": "Contexte: On étudie d’anciennes données reliant tabagisme et décès par cancer du poumon. Variables : age (classes), smoking status (4 classes), population (centaines de milliers), deaths (décès annuels)."
  },
  {
    "objectID": "td1/td1.html#objectifs-de-ce-td",
    "href": "td1/td1.html#objectifs-de-ce-td",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "1.1 Objectifs de ce TD",
    "text": "1.1 Objectifs de ce TD\n\nImporter et préparer un tableau comptages + exposition (population à risque).\nAjuster un GLM Poisson avec offset (log-exposition).\nÉvaluer l’ajustement : déviance (vs modèle saturé) & Pearson.\nComparer des modèles via tests de rapport de vraisemblance (LR).\nInterpréter en ratios de taux d’incidence (IRR) et produire des comptes attendus."
  },
  {
    "objectID": "td1/td1.html#packages",
    "href": "td1/td1.html#packages",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "1.2 Packages",
    "text": "1.2 Packages\n\n\nCode\n# installer si nécessaire : install.packages(c(\"readxl\",\"dplyr\",\"tidyr\",\"janitor\",\"ggplot2\",\"broom\",\"gt\",\"performance\",\"DescTools\"))\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(janitor)\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(gt)\nlibrary(performance)   # check_overdispersion\nlibrary(DescTools)     # PChisq for GOF (si besoin)\n\n\n\n\n\n\n\n\nRappel de cours — Régression de Poisson\n\n\n\nLa régression de Poisson est un modèle linéaire généralisé (GLM) adapté aux données de comptage (ex. nombre de décès, d’accidents, de visites).\nFormulation :\n\nVariable dépendante : un comptage \\(Y_i \\in \\{0,1,2,\\dots\\}\\). - Loi supposée : \\(Y_i \\sim \\text{Poisson}(\\mu_i)\\) avec \\(\\mathbb{E}[Y_i] = \\mu_i\\).\nLien log : \\[\n\\log(\\mu_i) = \\beta_0 + \\beta_1 X_{1i} + \\dots + \\beta_p X_{pi} + \\log(\\text{exposition}_i)\n\\] où l’offset \\(\\log(\\text{exposition}_i)\\) tient compte de la taille de la population ou du temps d’observation.\n\nPourquoi utiliser ce modèle ?\n\nLes données sont des comptages positifs (non négatifs).\nLa variance est proportionnelle à la moyenne (\\(\\text{Var}(Y)=\\mu\\)).\nOn cherche à modéliser des taux d’incidence (décès/population, accidents/temps).\n\nInterprétation des coefficients :\n\nLes \\(\\beta_j\\) s’interprètent via l’Incidence Rate Ratio (IRR) :\n\\[\n  IRR_j = e^{\\beta_j}\n  \\] → \\(IRR_j &gt; 1\\) : le taux est plus élevé que la référence.\n→ \\(IRR_j &lt; 1\\) : le taux est plus faible.\n\nDiagnostics courants :\n\nTests de qualité d’ajustement (déviance, Pearson).\nVérification de la sur-dispersion (si \\(\\text{Var}(Y) &gt; \\mu\\), préférer quasi-Poisson ou binomiale négative).\n\nExtensions :\n\nModèle de Poisson avec offset (exposition).\nQuasi-Poisson pour corriger la variance.\nBinomiale négative pour sur-dispersion forte."
  },
  {
    "objectID": "td1/td1.html#importer-les-données-smoking_dat.xlsx",
    "href": "td1/td1.html#importer-les-données-smoking_dat.xlsx",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "2.1 Importer les données smoking_dat.xlsx",
    "text": "2.1 Importer les données smoking_dat.xlsx\n\nDans l’énoncé, les données à importer sont smoking_dat.xlsx et les variables age, smoking status, population, deaths.\n\n\n\n\n\n\n\nNote\n\n\n\nDictionnaire des variables :\n• age: en classes (40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-79, 80+).\n• smoking status: 4 classes (ne fume pas / fume le cigare ou la pipe / fume la cigarette et le cigare ou la pipe ; fume seulement la cigarette)\n• population: en centaine de milliers de personnes\n• deaths: comptage des décès par cancer du poumon en un an.\n\n\n\n\nCode\n# Chemin suggéré : placez le fichier dans data/smoking_dat.xlsx\n# Si vous avez un CSV, remplacez read_excel par read.csv(...)\ndata_path &lt;- \"data/smoking_dat.xlsx\"\n\ndf &lt;- read_excel(data_path) |&gt;\n  clean_names()\n\n# Harmonisation de noms\n# On s'attend à des colonnes: age (classes), smoking_status (4 classes), population, deaths\ndf &lt;- df |&gt;\n  rename(\n    age = matches(\"^age$|^age_class|^agecat\"),\n    smoking_status = matches(\"^smoking|^smoke\"),\n    population = matches(\"^pop|^population\"),\n    deaths = matches(\"^deaths|^dead\")\n  )\n\nglimpse(df)\n\n\nRows: 36\nColumns: 4\n$ age            &lt;chr&gt; \"40-44\", \"45-59\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"…\n$ smoking_status &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ population     &lt;dbl&gt; 656, 359, 249, 632, 1067, 897, 668, 361, 274, 145, 104,…\n$ deaths         &lt;dbl&gt; 18, 22, 19, 55, 117, 170, 179, 120, 120, 2, 4, 3, 38, 1…"
  },
  {
    "objectID": "td1/td1.html#coder-les-deux-variables-enregistrées-en-texte-avec-des-chiffres",
    "href": "td1/td1.html#coder-les-deux-variables-enregistrées-en-texte-avec-des-chiffres",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "2.2 Coder les deux variables enregistrées en texte avec des chiffres",
    "text": "2.2 Coder les deux variables enregistrées en texte avec des chiffres\n\nEn Stata on ferait encode + i.variable.\nEn R, il suffit de déclarer les variables comme factor.\n\n\n\nCode\ndf &lt;- df |&gt;\n  mutate(\n    age = factor(age, ordered = FALSE),\n    smoking_status = factor(smoking_status, ordered = FALSE)\n  )\n\n# Vérification des niveaux\nlevels(df$age); levels(df$smoking_status)\n\n\n[1] \"40-44\" \"45-59\" \"50-54\" \"55-59\" \"60-64\" \"65-69\" \"70-74\" \"75-79\" \"80+\"  \n\n\n[1] \"cigarPipeOnly\"  \"cigarretteOnly\" \"cigarrettePlus\" \"no\"            \n\n\n\n\n\n\n\n\nNote\n\n\n\nRappel : Les facteurs indiquent à R qu’il s’agit de variables qualitatives. Chaque modalité sera transformée en variable indicatrice (dummy) dans la régression.\n\n\n\n2.2.1 Unité d’exposition\nL’énoncé précise que population est en centaines de milliers. Pour une interprétation plus intuitive, on peut ramener l’exposition à l’unité personne (facultatif) :\n\n\nCode\n# Ici, on transforme 'population' en nombre de personnes si besoin.\n# Exemple: si population = 2.3 signifie 2.3 * 100 000 personnes :\nexpo_personnes &lt;- TRUE\nscale_factor &lt;- 1e5\n\ndf &lt;- df |&gt;\n  mutate(\n    exposure = if (expo_personnes) population * scale_factor else population\n  )\nsummary(df$exposure)\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n  9800000  36925000  85850000 155894444 230550000 605200000"
  },
  {
    "objectID": "td1/td1.html#appliquer-un-premier-modèle-de-régression-log-linéaire",
    "href": "td1/td1.html#appliquer-un-premier-modèle-de-régression-log-linéaire",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.1 Appliquer un premier modèle de régression log-linéaire",
    "text": "3.1 Appliquer un premier modèle de régression log-linéaire\nModèle Poisson log-linéaire avec effets de smoking_status et age, et offset log(exposure) : c’est l’équivalent de Stata poisson deaths i.smokecod i.agecod, exposure(pop).\n\n\n\n\n\n\nTip\n\n\n\nPourquoi un modèle de Poisson ?\nLes données sont des comptages (nombre de décès).\nLe modèle de Poisson relie l’espérance de ces comptages à des variables explicatives par une fonction de lien log :\n\\[\n\\log(\\mathbb{E}[Y]) = X\\beta\n\\]\nCette structure garantit que la prédiction est positive et que la variance est proportionnelle à la moyenne (hypothèse de Poisson).\n\n\nNous voulons expliquer le nombre de décès par l’âge et le statut tabagique, en tenant compte de l’exposition.\n\n\nCode\nmod1 &lt;- glm(deaths ~ smoking_status + age + offset(log(exposure)), \n            family = poisson(link = \"log\"), data = df)\n\nsummary(mod1)\n\n\n\nCall:\nglm(formula = deaths ~ smoking_status + age + offset(log(exposure)), \n    family = poisson(link = \"log\"), data = df)\n\nCoefficients:\n                              Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)                  -15.14514    0.06783 -223.293  &lt; 2e-16 ***\nsmoking_statuscigarretteOnly   0.36915    0.03791    9.737  &lt; 2e-16 ***\nsmoking_statuscigarrettePlus   0.17015    0.03643    4.671 3.00e-06 ***\nsmoking_statusno              -0.04781    0.04699   -1.017    0.309    \nage45-59                       0.55388    0.07999    6.924 4.38e-12 ***\nage50-54                       0.98039    0.07682   12.762  &lt; 2e-16 ***\nage55-59                       1.37946    0.06526   21.138  &lt; 2e-16 ***\nage60-64                       1.65423    0.06257   26.439  &lt; 2e-16 ***\nage65-69                       1.99817    0.06279   31.824  &lt; 2e-16 ***\nage70-74                       2.27141    0.06435   35.296  &lt; 2e-16 ***\nage75-79                       2.55858    0.06778   37.746  &lt; 2e-16 ***\nage80+                         2.84692    0.07242   39.310  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4055.984  on 35  degrees of freedom\nResidual deviance:   21.487  on 24  degrees of freedom\nAIC: 285.51\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nImportant\n\n\n\nL’argument offset(log(exposure)) ajoute le log de l’exposition avec un coefficient fixé à 1. Cela revient à modéliser un taux de décès (décès / population).\nQuelle interprétation?\nOn peut utiliser \\(\\exp(\\beta_i)\\) pour retrouver l’Incidence Rate Ratio (IRR). On le lit comme le coefficient multiplicateur de l’occurence de \\(Y\\) (ici le décès) par rapport à la catégorie de référence."
  },
  {
    "objectID": "td1/td1.html#calculer-la-déviance-du-modèle-ajusté.-dev1",
    "href": "td1/td1.html#calculer-la-déviance-du-modèle-ajusté.-dev1",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.2 Calculer la déviance du modèle ajusté. DEV1",
    "text": "3.2 Calculer la déviance du modèle ajusté. DEV1\n\n\nCode\ndev1 &lt;- deviance(mod1)     # Deviance du modèle vs saturé\ndf_dev1 &lt;- df.residual(mod1)\nc(dev1 = dev1, df = df_dev1, p_value = pchisq(dev1, df_dev1, lower.tail = FALSE))\n\n\n     dev1        df   p_value \n21.486738 24.000000  0.609872"
  },
  {
    "objectID": "td1/td1.html#quel-est-leffet-de-lâge-sur-la-probabilité-de-décès-par-cancer-du-poumon",
    "href": "td1/td1.html#quel-est-leffet-de-lâge-sur-la-probabilité-de-décès-par-cancer-du-poumon",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.3 Quel est l’effet de l’âge sur la probabilité de décès par cancer du poumon ?",
    "text": "3.3 Quel est l’effet de l’âge sur la probabilité de décès par cancer du poumon ?\n\nInterprétez les coefficients associés aux modalités d’âge (comparées à la catégorie de référence) en termes d’IRR (voir section IRR) et/ou d’impact sur le taux de décès (à exposition fixée). (Discussion attendue.)\n\nInterprétez les coefficients d’âge (IRR = exp(coef)) :\n\nIRR &gt; 1 : taux de décès plus élevé que la catégorie de référence.\nIRR &lt; 1 : taux plus faible."
  },
  {
    "objectID": "td1/td1.html#sauvegarde-du-modèle-utile-pour-lr-tests",
    "href": "td1/td1.html#sauvegarde-du-modèle-utile-pour-lr-tests",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.4 Sauvegarde du modèle (utile pour LR tests)",
    "text": "3.4 Sauvegarde du modèle (utile pour LR tests)\n\n\nCode\n# En R, on garde l'objet en mémoire (mod1). Pas besoin d'\"estimates store\".\n# On peut aussi l'ajouter à une liste si on veut gérer plusieurs modèles :\nmodels &lt;- list(mod1 = mod1)"
  },
  {
    "objectID": "td1/td1.html#tester-lajustement-de-ce-modèle",
    "href": "td1/td1.html#tester-lajustement-de-ce-modèle",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.5 Tester l’ajustement de ce modèle",
    "text": "3.5 Tester l’ajustement de ce modèle\nPour cela nous allons réaliser deux tests :\n\nDeviance GOF (modèle ajusté vs saturé).\nPearson GOF (comparaison effectifs attendus vs observés). Les degrés de liberté correspondent ici au nombre de cellules moins le nombre de paramètres estimés (y compris l’interception). L’énoncé suggère 24 df pour chacun de ces tests (voir justification plus bas).\n\n\n\nCode\n# Deviance test (déjà calculé ci-dessus)\ndev_stat  &lt;- deviance(mod1)\ndev_df    &lt;- df.residual(mod1)\ndev_p     &lt;- pchisq(dev_stat, dev_df, lower.tail = FALSE)\n\n# Pearson GOF (somme (y - mu)^2 / mu) et chi2 approx avec mêmes df résiduels)\nmu_hat    &lt;- fitted(mod1)         # comptages attendus\ny_obs     &lt;- df$deaths\npearson   &lt;- sum((y_obs - mu_hat)^2 / mu_hat)\npearson_p &lt;- pchisq(pearson, dev_df, lower.tail = FALSE)\n\ntibble(\n  test = c(\"Deviance GOF\", \"Pearson GOF\"),\n  statistic = c(dev_stat, pearson),\n  df = c(dev_df, dev_df),\n  p_value = c(dev_p, pearson_p)\n) |&gt;\n  gt()\n\n\n\n\n\n\n\n\ntest\nstatistic\ndf\np_value\n\n\n\n\nDeviance GOF\n21.48674\n24\n0.6098720\n\n\nPearson GOF\n20.61936\n24\n0.6610658"
  },
  {
    "objectID": "td1/td1.html#justifiez-pourquoi-ces-tests-sont-effectués-avec-le-même-df.",
    "href": "td1/td1.html#justifiez-pourquoi-ces-tests-sont-effectués-avec-le-même-df.",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.6 Justifiez pourquoi ces tests sont effectués avec le même df.",
    "text": "3.6 Justifiez pourquoi ces tests sont effectués avec le même df.\n\n\n\n\n\n\nTip\n\n\n\nRappel : pour un GLM Poisson, df = N - p, où N est le nombre de cellules et p le nombre de paramètres estimés (y compris l’interception). Discuter les conditions d’un χ² (souvent \\(\\hat\\mu ≥ 5\\) dans la plupart des cellules).\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLa p-value de ce modèl est elevée, on ne rejète donc pas H0, pour rappel, on rejète H0 quand une \\(\\text{p-value} &lt; 0,05\\). Dans ce test (deviance GOF):\n\nH0: absence de différences entre le modèle estimant parfaitement les observations et notre spécification\nH1: différences entre le modèle estimant parfaitements les observations et notre spécification\n\nC’est un test où l’on est rassuré par une p-value élevée!"
  },
  {
    "objectID": "td1/td1.html#ajuster-un-modèle-sans-la-variable-smoke-et-effectuer-un-test-de-rapport-de-vraisemblance-entre-ce-nouveau-modèle-et-celui-précédemment-sauvegardé",
    "href": "td1/td1.html#ajuster-un-modèle-sans-la-variable-smoke-et-effectuer-un-test-de-rapport-de-vraisemblance-entre-ce-nouveau-modèle-et-celui-précédemment-sauvegardé",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "3.7 Ajuster un modèle sans la variable smoke, et effectuer un test de rapport de vraisemblance entre ce nouveau modèle et celui précédemment sauvegardé",
    "text": "3.7 Ajuster un modèle sans la variable smoke, et effectuer un test de rapport de vraisemblance entre ce nouveau modèle et celui précédemment sauvegardé\nOn ajuste un modèle sans tabac et on compare à mod1 par LR test. En Stata : lrtest. En R : anova(mod0, mod1, test=\"Chisq\").\n\n\nCode\nmod0 &lt;- glm(deaths ~ age + offset(log(exposure)),\n            family = poisson, data = df)\n\nanova(mod0, mod1, test = \"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: deaths ~ age + offset(log(exposure))\nModel 2: deaths ~ smoking_status + age + offset(log(exposure))\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1        27    191.723                          \n2        24     21.487  3   170.24 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "td1/td1.html#construire-une-nouvelle-variable-qui-prend-la-valeur-1-si-lindividu-fume-des-cigarettes-0-sil-nen-fume-pas.",
    "href": "td1/td1.html#construire-une-nouvelle-variable-qui-prend-la-valeur-1-si-lindividu-fume-des-cigarettes-0-sil-nen-fume-pas.",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.1 Construire une nouvelle variable qui prend la valeur 1 si l’individu fume des cigarettes, 0 s’il n’en fume pas.",
    "text": "4.1 Construire une nouvelle variable qui prend la valeur 1 si l’individu fume des cigarettes, 0 s’il n’en fume pas.\nCréer une variable cigarette_user égale à 1 si l’individu fume des cigarettes, 0 sinon : l’énoncé demande de distinguer le type de produit et de concentrer l’attention sur la cigarette.\n\n\nCode\n# Adaptez le motif à vos libellés (ex.: \"fume seulement la cigarette\", \"cigarette + cigare/pipe\", etc.)\n# On classera 1 si l'étiquette contient \"cigarette\", 0 sinon.\ndf &lt;- df |&gt;\n  mutate(\n    cigarette_user = as.integer(grepl(\"cigarrette\", tolower(as.character(smoking_status)))))\n\ntable(df$cigarette_user, df$smoking_status)\n\n\n   \n    cigarPipeOnly cigarretteOnly cigarrettePlus no\n  0             9              0              0  9\n  1             0              9              9  0"
  },
  {
    "objectID": "td1/td1.html#ajuster-un-troisième-modèle-avec-effet-de-lâge-et-de-cette-variable-dusage-de-la-cigarette.",
    "href": "td1/td1.html#ajuster-un-troisième-modèle-avec-effet-de-lâge-et-de-cette-variable-dusage-de-la-cigarette.",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.2 Ajuster un troisième modèle avec effet de l’âge et de cette variable d’usage de la cigarette.",
    "text": "4.2 Ajuster un troisième modèle avec effet de l’âge et de cette variable d’usage de la cigarette.\n\n\nCode\nmod2 &lt;- glm(deaths ~ cigarette_user + age + offset(log(exposure)),\n            family = poisson, data = df)\n\nsummary(mod2)\n\n\n\nCall:\nglm(formula = deaths ~ cigarette_user + age + offset(log(exposure)), \n    family = poisson, data = df)\n\nCoefficients:\n                Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)    -15.15590    0.06378 -237.625  &lt; 2e-16 ***\ncigarette_user   0.26910    0.02757    9.762  &lt; 2e-16 ***\nage45-59         0.55342    0.07999    6.919 4.56e-12 ***\nage50-54         0.98480    0.07682   12.820  &lt; 2e-16 ***\nage55-59         1.37640    0.06526   21.092  &lt; 2e-16 ***\nage60-64         1.64629    0.06256   26.317  &lt; 2e-16 ***\nage65-69         1.99023    0.06277   31.708  &lt; 2e-16 ***\nage70-74         2.26143    0.06432   35.161  &lt; 2e-16 ***\nage75-79         2.54560    0.06766   37.626  &lt; 2e-16 ***\nage80+           2.82907    0.07215   39.211  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4055.984  on 35  degrees of freedom\nResidual deviance:   92.237  on 26  degrees of freedom\nAIC: 352.26\n\nNumber of Fisher Scoring iterations: 4\n\n\nCode\nanova(mod2, test = \"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: deaths\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              35     4056.0              \ncigarette_user  1     58.3        34     3997.6 2.195e-14 ***\nage             8   3905.4        26       92.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "td1/td1.html#comptes-attendus-tableau-observé-vs-attendu",
    "href": "td1/td1.html#comptes-attendus-tableau-observé-vs-attendu",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "7.1 Comptes attendus & tableau Observé vs Attendu",
    "text": "7.1 Comptes attendus & tableau Observé vs Attendu\n\n\nCode\ndf_preds &lt;- df |&gt;\n  mutate(\n    y_obs = deaths,\n    mu_hat = fitted(mod1)\n  )\n\ndf_preds |&gt;\n  select(age, smoking_status, exposure, y_obs, mu_hat) |&gt;\n  arrange(age, smoking_status) |&gt;\n  gt() |&gt;\n  fmt_number(columns = c(exposure, y_obs, mu_hat), decimals = 2)\n\n\n\n\n\n\n\n\nage\nsmoking_status\nexposure\ny_obs\nmu_hat\n\n\n\n\n40-44\ncigarPipeOnly\n14,500,000.00\n2.00\n3.84\n\n\n40-44\ncigarretteOnly\n341,000,000.00\n124.00\n130.50\n\n\n40-44\ncigarrettePlus\n453,100,000.00\n149.00\n142.11\n\n\n40-44\nno\n65,600,000.00\n18.00\n16.55\n\n\n45-59\ncigarPipeOnly\n10,400,000.00\n4.00\n4.79\n\n\n45-59\ncigarretteOnly\n223,900,000.00\n140.00\n149.10\n\n\n45-59\ncigarrettePlus\n303,000,000.00\n169.00\n165.36\n\n\n45-59\nno\n35,900,000.00\n22.00\n15.76\n\n\n50-54\ncigarPipeOnly\n9,800,000.00\n3.00\n6.91\n\n\n50-54\ncigarretteOnly\n185,100,000.00\n187.00\n188.82\n\n\n50-54\ncigarrettePlus\n226,700,000.00\n193.00\n189.53\n\n\n50-54\nno\n24,900,000.00\n19.00\n16.74\n\n\n55-59\ncigarPipeOnly\n37,200,000.00\n38.00\n39.10\n\n\n55-59\ncigarretteOnly\n327,000,000.00\n514.00\n497.17\n\n\n55-59\ncigarrettePlus\n468,200,000.00\n576.00\n583.40\n\n\n55-59\nno\n63,200,000.00\n55.00\n63.33\n\n\n60-64\ncigarPipeOnly\n84,600,000.00\n113.00\n117.04\n\n\n60-64\ncigarretteOnly\n379,100,000.00\n778.00\n758.66\n\n\n60-64\ncigarrettePlus\n605,200,000.00\n1,001.00\n992.58\n\n\n60-64\nno\n106,700,000.00\n117.00\n140.73\n\n\n65-69\ncigarPipeOnly\n94,900,000.00\n173.00\n185.19\n\n\n65-69\ncigarretteOnly\n242,100,000.00\n689.00\n683.37\n\n\n65-69\ncigarrettePlus\n388,000,000.00\n901.00\n897.57\n\n\n65-69\nno\n89,700,000.00\n170.00\n166.87\n\n\n70-74\ncigarPipeOnly\n82,400,000.00\n212.00\n211.32\n\n\n70-74\ncigarretteOnly\n119,500,000.00\n432.00\n443.30\n\n\n70-74\ncigarrettePlus\n203,300,000.00\n613.00\n618.07\n\n\n70-74\nno\n66,800,000.00\n179.00\n163.31\n\n\n75-79\ncigarPipeOnly\n66,700,000.00\n243.00\n227.95\n\n\n75-79\ncigarretteOnly\n43,600,000.00\n214.00\n215.54\n\n\n75-79\ncigarrettePlus\n87,100,000.00\n337.00\n352.89\n\n\n75-79\nno\n36,100,000.00\n120.00\n117.62\n\n\n80+\ncigarPipeOnly\n53,700,000.00\n253.00\n244.86\n\n\n80+\ncigarretteOnly\n11,300,000.00\n63.00\n74.53\n\n\n80+\ncigarrettePlus\n34,500,000.00\n189.00\n186.49\n\n\n80+\nno\n27,400,000.00\n120.00\n119.11"
  },
  {
    "objectID": "td1/td1.html#vérification-déventuelle-sur-dispersion",
    "href": "td1/td1.html#vérification-déventuelle-sur-dispersion",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "7.2 Vérification d’éventuelle sur-dispersion",
    "text": "7.2 Vérification d’éventuelle sur-dispersion\n\nLe GLM Poisson suppose Var(Y) = E[Y]. Si Var(Y) &gt;&gt; E[Y], la sur-dispersion peut invalider les tests usuels (SE sous-estimés).\n\n\n\nCode\ncheck_overdispersion(mod1)\n\n\n# Overdispersion test\n\n       dispersion ratio =  0.859\n  Pearson's Chi-Squared = 20.619\n                p-value =  0.661\n\n\n\nEn cas de sur-dispersion marquée, envisagez Quasi-Poisson (family = quasipoisson) ou Négative Binomiale (MASS::glm.nb) et comparez l’ajustement."
  },
  {
    "objectID": "td1/td1.html#graphiques-facultatifs",
    "href": "td1/td1.html#graphiques-facultatifs",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "7.3 Graphiques (facultatifs)",
    "text": "7.3 Graphiques (facultatifs)\n\n\nCode\nshapes_9 &lt;- c(16, 17, 15, 3, 7, 8, 0, 1, 2)  # à ta convenance\nggplot(df_preds, aes(mu_hat, y_obs, color = smoking_status, shape = age)) +\n  geom_point(size = 2) +\n  geom_abline(intercept = 0, slope = 1, linetype = 2) +\n  scale_shape_manual(values = shapes_9) +\n  labs(x = \"Comptes attendus (mod1)\", y = \"Comptes observés\",\n       title = \"Observé vs Attendu — GLM Poisson (mod1)\")"
  },
  {
    "objectID": "td1/td1.html#bilan",
    "href": "td1/td1.html#bilan",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "7.4 Bilan",
    "text": "7.4 Bilan\n\nLe modèle de Poisson permet d’estimer des taux de décès en fonction du tabagisme et de l’âge.\nLes tests d’ajustement (déviance, Pearson) valident le modèle si p-value élevée.\nLe tabagisme a un impact significatif sur la mortalité par cancer du poumon.\nLes IRR offrent une interprétation intuitive : par rapport à la catégorie de référence, combien de fois le taux de décès est-il multiplié.\n\n\nConseil pratique : en recherche appliquée, vérifiez toujours la sur-dispersion et documentez les hypothèses de variance (Poisson vs quasi-Poisson vs binomiale négative)."
  },
  {
    "objectID": "global-slides.html",
    "href": "global-slides.html",
    "title": "Présentation globale",
    "section": "",
    "text": "TD1 : Regressions de poisson\nTD2: Regressions Logit\nTD3 : Regressions multinom\nTD4 : Analyse de survie\n\n\n\n\n\nTD1 → {{&lt; revealjs file=\"/td1/td1-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}\n\n\n\n\n\n\nTD2 → {{&lt; revealjs file=\"/td2/td2-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}\n\n\n\n\n\n\nTD3 → {{&lt; revealjs file=\"/td3/td3-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}\n\n\n\n\n\n\nTD4 → {{&lt; revealjs file=\"/td4/td4-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}\n\n\n\n\n\nRaccourcis Reveal.js :\n- F : plein écran\n- S : notes orateur\n- Esc : vue mosaïque"
  },
  {
    "objectID": "global-slides.html#td-1",
    "href": "global-slides.html#td-1",
    "title": "Présentation globale",
    "section": "",
    "text": "TD1 → {{&lt; revealjs file=\"/td1/td1-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}"
  },
  {
    "objectID": "global-slides.html#td-2",
    "href": "global-slides.html#td-2",
    "title": "Présentation globale",
    "section": "",
    "text": "TD2 → {{&lt; revealjs file=\"/td2/td2-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}"
  },
  {
    "objectID": "global-slides.html#td-3",
    "href": "global-slides.html#td-3",
    "title": "Présentation globale",
    "section": "",
    "text": "TD3 → {{&lt; revealjs file=\"/td3/td3-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}"
  },
  {
    "objectID": "global-slides.html#td-4",
    "href": "global-slides.html#td-4",
    "title": "Présentation globale",
    "section": "",
    "text": "TD4 → {{&lt; revealjs file=\"/td4/td4-slides.html\" height=\"500px\" class=\"ratio ratio-16x9\" &gt;}}"
  },
  {
    "objectID": "global-slides.html#astuce-projection",
    "href": "global-slides.html#astuce-projection",
    "title": "Présentation globale",
    "section": "",
    "text": "Raccourcis Reveal.js :\n- F : plein écran\n- S : notes orateur\n- Esc : vue mosaïque"
  },
  {
    "objectID": "td1/td1-slides.html#modèle-mod2",
    "href": "td1/td1-slides.html#modèle-mod2",
    "title": "TD 1 — Régression de Poisson (R)",
    "section": "10.1 Modèle (mod2)",
    "text": "10.1 Modèle (mod2)\n\n\nCode\nmod2 &lt;- glm(deaths ~ cigarette_user + age + offset(log(exposure)),\n            family = poisson, data = df)\n\nsummary(mod2)\n\n\n\nCall:\nglm(formula = deaths ~ cigarette_user + age + offset(log(exposure)), \n    family = poisson, data = df)\n\nCoefficients:\n                Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)    -15.15590    0.06378 -237.625  &lt; 2e-16 ***\ncigarette_user   0.26910    0.02757    9.762  &lt; 2e-16 ***\nage45-59         0.55342    0.07999    6.919 4.56e-12 ***\nage50-54         0.98480    0.07682   12.820  &lt; 2e-16 ***\nage55-59         1.37640    0.06526   21.092  &lt; 2e-16 ***\nage60-64         1.64629    0.06256   26.317  &lt; 2e-16 ***\nage65-69         1.99023    0.06277   31.708  &lt; 2e-16 ***\nage70-74         2.26143    0.06432   35.161  &lt; 2e-16 ***\nage75-79         2.54560    0.06766   37.626  &lt; 2e-16 ***\nage80+           2.82907    0.07215   39.211  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4055.984  on 35  degrees of freedom\nResidual deviance:   92.237  on 26  degrees of freedom\nAIC: 352.26\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "td1/td1-slides.html#anova",
    "href": "td1/td1-slides.html#anova",
    "title": "TD 1 — Régression de Poisson (R)",
    "section": "10.2 Anova",
    "text": "10.2 Anova\n\n\nCode\nanova(mod2, test = \"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: deaths\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              35     4056.0              \ncigarette_user  1     58.3        34     3997.6 2.195e-14 ***\nage             8   3905.4        26       92.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "td1/énoncé-td1.html",
    "href": "td1/énoncé-td1.html",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "",
    "text": "On étudie d’anciennes données reliant tabagisme et décès par cancer du poumon.\nVariables : age (classes), smoking status (4 classes), population (centaines de milliers), deaths (décès annuels)."
  },
  {
    "objectID": "td1/énoncé-td1.html#objectifs-de-ce-td",
    "href": "td1/énoncé-td1.html#objectifs-de-ce-td",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "2.1 Objectifs de ce TD",
    "text": "2.1 Objectifs de ce TD\n\nImporter et préparer un tableau « comptages + exposition » (population à risque).\nAjuster un GLM Poisson avec offset (log-exposition).\nÉvaluer l’ajustement : déviance (vs modèle saturé) & Pearson.\nComparer des modèles via tests de rapport de vraisemblance (LR).\nInterpréter en ratios de taux d’incidence (IRR) et produire des comptes attendus."
  },
  {
    "objectID": "td1/énoncé-td1.html#modèle-de-base",
    "href": "td1/énoncé-td1.html#modèle-de-base",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.1 Modèle de base",
    "text": "4.1 Modèle de base\n\nAjuster un modèle Poisson log-linéaire avec effets de smoking_status et age et offset log(exposure).\n\nQ1 : Pourquoi utiliser des variables indicatrices plutôt que des codes numériques continus ?\n\nCalculer la déviance du modèle ajusté.\n\nQ2 : Interpréter la déviance et le p-value (DEV1).\n\nInterpréter l’effet de l’âge sur la probabilité de décès.\n\nQ3 : Que disent les coefficients d’âge en termes d’IRR ?"
  },
  {
    "objectID": "td1/énoncé-td1.html#ajustement-du-modèle",
    "href": "td1/énoncé-td1.html#ajustement-du-modèle",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.2 Ajustement du modèle",
    "text": "4.2 Ajustement du modèle\n\nRéaliser les deux tests d’ajustement : déviance GOF et Pearson GOF.\n\nQ4 : Justifier les degrés de liberté.\nQ5 : Discuter les conditions d’application du test du χ²."
  },
  {
    "objectID": "td1/énoncé-td1.html#comparaison-de-modèles",
    "href": "td1/énoncé-td1.html#comparaison-de-modèles",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.3 Comparaison de modèles",
    "text": "4.3 Comparaison de modèles\n\nAjuster un modèle sans la variable tabac et effectuer un test LR entre les deux modèles.\n\nQ6 : Conclure sur l’impact de l’usage du tabac sur la probabilité de décès."
  },
  {
    "objectID": "td1/énoncé-td1.html#variable-binaire-cigarette",
    "href": "td1/énoncé-td1.html#variable-binaire-cigarette",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.4 Variable binaire « cigarette »",
    "text": "4.4 Variable binaire « cigarette »\n\nCréer une variable binaire cigarette_user (=1 si l’individu fume des cigarettes, 0 sinon).\nAjuster un modèle avec age + cigarette_user.\nComparer ce modèle avec le modèle initial par un test LR.\n\nQ7 : Le type de produit fumé influence-t-il différemment le taux de décès ?"
  },
  {
    "objectID": "td1/énoncé-td1.html#extensions-facultatif",
    "href": "td1/énoncé-td1.html#extensions-facultatif",
    "title": "TD 1 — Modèle de Poisson (R)",
    "section": "4.5 Extensions (facultatif)",
    "text": "4.5 Extensions (facultatif)\n\nCalculer et présenter les IRR avec IC à 95 %.\nPrésenter les comptes observés vs attendus et commenter.\nVérifier la présence éventuelle de sur-dispersion et proposer, si nécessaire, un modèle adapté (Quasi-Poisson ou Négative Binomiale)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "td3/td3-slides.html#objectifs-du-td",
    "href": "td3/td3-slides.html#objectifs-du-td",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "1 Objectifs du TD",
    "text": "1 Objectifs du TD\n\nManipuler un modèle logit multinomial nominal (SUBTYPE).\nManipuler un modèle logit ordinal (GRADE).\nSavoir :\n\npréparer les données (codage en facteurs / variables ordinales) ;\nestimer, simplifier et interpréter un modèle ;\ntester :\n\nl’ajustement (Hosmer–Lemeshow multinomial) ;\ndes interactions via test de rapport de vraisemblance (LR).\n\n\n\nDonnées : cancer.dta (288 femmes avec cancer de l’endomètre)."
  },
  {
    "objectID": "td3/td3-slides.html#packages-utilisés",
    "href": "td3/td3-slides.html#packages-utilisés",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "2 Packages utilisés",
    "text": "2 Packages utilisés\n\n\nCode\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(haven)\nlibrary(broom)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(nnet)            # multinom (logit multinomial nominal)\nlibrary(generalhoslem)   # logitgof : test de Hosmer–Lemeshow multinomial\nlibrary(MASS)            # polr : logit ordinal\n\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "td3/td3-slides.html#import-des-données-et-préparation",
    "href": "td3/td3-slides.html#import-des-données-et-préparation",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "3 Import des données et préparation",
    "text": "3 Import des données et préparation\nOn suppose que le fichier cancer.dta se trouve dans le dossier ./data/.\n\n\nCode\ncancer_raw &lt;- read_dta(\"./data/cancer.dta\") |&gt;\n  clean_names()\n\nglimpse(cancer_raw)\n\n\nRows: 288\nColumns: 7\n$ id       &lt;dbl&gt; 10009, 10025, 10038, 10042, 10049, 10113, 10131, 10160, 10164…\n$ grade    &lt;dbl+lbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 2, 1, 2, 2, …\n$ race     &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ estrogen &lt;dbl+lbl&gt; 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, …\n$ subtype  &lt;dbl+lbl&gt; 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, …\n$ age      &lt;dbl+lbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, …\n$ smoking  &lt;dbl+lbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nOn dispose notamment des variables :\n\ngrade (3 modalités ordonnées),\nrace,\nestrogen,\nsubtype,\nage,\nsmoking."
  },
  {
    "objectID": "td3/td3-slides.html#recodage-des-variables",
    "href": "td3/td3-slides.html#recodage-des-variables",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "4 Recodage des variables",
    "text": "4 Recodage des variables\nOn crée des facteurs explicites pour la régression, en choisissant des références cohérentes avec l’énoncé :\n\n\nCode\ncancer &lt;- cancer_raw |&gt;\n  mutate(\n    # convertir les labels Stata en facteurs R\n    grade_f    = as_factor(grade),\n    subtype_f  = as_factor(subtype),\n    race_f     = as_factor(race),\n    estrogen_f = as_factor(estrogen),\n    age_f      = as_factor(age),\n    smk_f      = as_factor(smoking),\n    \n    # forcer l'ordre pour l'ordinal (adapter les noms à ce que tu vois)\n    grade_ord = fct_relevel(\n      grade_f,\n      \"bien différencié\",\n      \"moyennement différencié\",\n      \"peu différencié\"\n    )\n  )\n\ncancer |&gt;\n  dplyr::select(grade, grade_ord, subtype, subtype_f,\n         race_f, estrogen_f, age_f, smk_f) |&gt;\n  head()\n\n\n# A tibble: 6 × 8\n  grade                grade_ord subtype subtype_f race_f estrogen_f age_f smk_f\n  &lt;dbl+lbl&gt;            &lt;fct&gt;     &lt;dbl+l&gt; &lt;fct&gt;     &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;\n1 1 [moyennement diff… moyennem… 1 [ade… adenosqu… blanc… never too… 50-64 yes  \n2 0 [bien différencié] bien dif… 2 [oth… other     blanc… took oest… 50-64 no   \n3 1 [moyennement diff… moyennem… 1 [ade… adenosqu… blanc… never too… 65-79 no   \n4 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… never too… 65-79 no   \n5 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… took oest… 50-64 no   \n6 0 [bien différencié] bien dif… 0 [ade… adenocar… blanc… took oest… 65-79 no"
  },
  {
    "objectID": "td3/td3-slides.html#modèle-multinomial-pour-expliquer-subtype",
    "href": "td3/td3-slides.html#modèle-multinomial-pour-expliquer-subtype",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "5 Modèle multinomial pour expliquer SUBTYPE",
    "text": "5 Modèle multinomial pour expliquer SUBTYPE\nVariables explicatives : RACE, ESTROGEN, SMK, AGE."
  },
  {
    "objectID": "td3/td3-slides.html#b.-modèle-ordinal-pour-expliquer-grade",
    "href": "td3/td3-slides.html#b.-modèle-ordinal-pour-expliquer-grade",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "6 B. Modèle ordinal pour expliquer GRADE",
    "text": "6 B. Modèle ordinal pour expliquer GRADE\nOn modélise le stade de la tumeur (bien / moyennement / peu différenciée) en fonction de :\n\nRACE, ESTROGEN, SUBTYPE, AGE, SMK."
  },
  {
    "objectID": "td3/td3-slides.html#conclusion-td3",
    "href": "td3/td3-slides.html#conclusion-td3",
    "title": "TD 3 — Régression multinomiale (R)",
    "section": "7 Conclusion TD3",
    "text": "7 Conclusion TD3\n\nOn a estimé :\n\nun logit multinomial nominal pour SUBTYPE ;\nun logit ordinal pour GRADE.\n\nOn a :\n\ntesté l’ajustement du modèle nominal via un Hosmer–Lemeshow multinomial ;\nutilisé des tests de rapport de vraisemblance pour :\n\nsimplifier les modèles (variables non significatives),\ntester l’intérêt d’interactions dans le modèle ordinal ;\n\nChoisi les spécifications finales.\n\n\nÀ retenir :\n\nPour les variables nominales, on compare chaque modalité à une référence via des odds-ratios.\nPour les variables ordinales, le modèle logit/probit ordonné repose sur une variable latente et des seuils, avec une interprétation en termes de tendance vers des catégories plus élevées ou plus basses."
  },
  {
    "objectID": "td3/enonce-td3.html",
    "href": "td3/enonce-td3.html",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "",
    "text": "Un modèle de régression multinomiale est un modèle Logit ou Probit dans lequel la variable à expliquer \\(Y\\) est une variable qualitative à \\(k &gt; 2\\) modalités. Cette variable peut être qualitative nominale ou ordinale.\n\n\nDans le cas d’une variable expliquée nominale, on prend n’importe quelle modalité comme modalité de référence (modalité 0), et on estime des pseudo-côtes, c’est-à-dire :\n\n\\(\\displaystyle \\frac{\\Pr(Y = 1)}{\\Pr(Y = 0)}\\)\n\n\\(\\displaystyle \\frac{\\Pr(Y = 2)}{\\Pr(Y = 0)}\\)\n\netc.\n\nPar exemple, dans le cas \\(k = 3\\) modalités de \\(Y\\), on a :\n\\(\\Pr(Y = 0) + \\Pr(Y = 1) + \\Pr(Y = 2) = 1\\)\n\nMAIS \\(\\Pr(Y = 0) + \\Pr(Y = 1) &lt; 1\\) et \\(\\Pr(Y = 0) + \\Pr(Y = 2) &lt; 1\\)\nOn estime alors les paramètres \\(\\beta_g\\) tels que :\n\\[\n\\ln \\left(\\frac{\\Pr(Y = g)}{\\Pr(Y = 0)}\\right)\n= \\beta_{g0} + \\sum_{j=1}^{p} \\beta_{gj} X_j\n\\]\navec \\(g = 1, \\dots, k-1\\).\nOn estime donc :\n\n\\((k - 1)\\) paramètres pour chaque variable explicative quantitative ;\n\\((k - 1)(q - 1)\\) paramètres pour une variable explicative qualitative à \\(q\\) modalités.\n\n\n\n\nDans le cas d’une variable expliquée ordinale, \\(Y = 0\\) ou \\(1\\) ou \\(2\\), etc. représente une réponse graduée.\nLa résolution suppose l’existence d’une variable continue sous-jacente \\(Y^*\\), et de \\((k - 1)\\) bornes \\(c_j\\) telles que :\n\nsi \\(y_i^* &lt; c_1\\) alors \\(y_i = 1\\)\nsi \\(c_{j-1} &lt; y_i^* &lt; c_j\\) alors \\(y_i = j\\)\nsi \\(y_i^* &gt; c_{k-1}\\) alors \\(y_i = k\\)\n\nOn a :\n\\[\ny_i^* = X_i B + \\varepsilon_i\n\\]\net on estime conjointement :\n\nles paramètres \\(\\beta_j\\) correspondant à chaque variable explicative ;\nles seuils \\(c_g\\) (\\(g = 1, \\dots, k - 1\\)).\n\nOn prédit alors l’appartenance de chaque individu à chaque classe par les formules :\n\\[\\Pr(Y_i = 0) = \\Phi(c_1 - X_i B)\\]\n\\[\\Pr(Y_i = g) = \\Phi(c_g - X_i B) - \\Phi(c_{g-1} - X_i B)\\]\noù \\(\\Phi\\) est :\n\nla fonction de répartition d’une loi gaussienne centrée réduite dans le cas du modèle Probit multivarié ;\nl’inverse de la fonction Logit dans le cas du Logit multivarié."
  },
  {
    "objectID": "td3/enonce-td3.html#introduction",
    "href": "td3/enonce-td3.html#introduction",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "",
    "text": "Un modèle de régression multinomiale est un modèle Logit ou Probit dans lequel la variable à expliquer \\(Y\\) est une variable qualitative à \\(k &gt; 2\\) modalités. Cette variable peut être qualitative nominale ou ordinale.\n\n\nDans le cas d’une variable expliquée nominale, on prend n’importe quelle modalité comme modalité de référence (modalité 0), et on estime des pseudo-côtes, c’est-à-dire :\n\n\\(\\displaystyle \\frac{\\Pr(Y = 1)}{\\Pr(Y = 0)}\\)\n\n\\(\\displaystyle \\frac{\\Pr(Y = 2)}{\\Pr(Y = 0)}\\)\n\netc.\n\nPar exemple, dans le cas \\(k = 3\\) modalités de \\(Y\\), on a :\n\\(\\Pr(Y = 0) + \\Pr(Y = 1) + \\Pr(Y = 2) = 1\\)\n\nMAIS \\(\\Pr(Y = 0) + \\Pr(Y = 1) &lt; 1\\) et \\(\\Pr(Y = 0) + \\Pr(Y = 2) &lt; 1\\)\nOn estime alors les paramètres \\(\\beta_g\\) tels que :\n\\[\n\\ln \\left(\\frac{\\Pr(Y = g)}{\\Pr(Y = 0)}\\right)\n= \\beta_{g0} + \\sum_{j=1}^{p} \\beta_{gj} X_j\n\\]\navec \\(g = 1, \\dots, k-1\\).\nOn estime donc :\n\n\\((k - 1)\\) paramètres pour chaque variable explicative quantitative ;\n\\((k - 1)(q - 1)\\) paramètres pour une variable explicative qualitative à \\(q\\) modalités.\n\n\n\n\nDans le cas d’une variable expliquée ordinale, \\(Y = 0\\) ou \\(1\\) ou \\(2\\), etc. représente une réponse graduée.\nLa résolution suppose l’existence d’une variable continue sous-jacente \\(Y^*\\), et de \\((k - 1)\\) bornes \\(c_j\\) telles que :\n\nsi \\(y_i^* &lt; c_1\\) alors \\(y_i = 1\\)\nsi \\(c_{j-1} &lt; y_i^* &lt; c_j\\) alors \\(y_i = j\\)\nsi \\(y_i^* &gt; c_{k-1}\\) alors \\(y_i = k\\)\n\nOn a :\n\\[\ny_i^* = X_i B + \\varepsilon_i\n\\]\net on estime conjointement :\n\nles paramètres \\(\\beta_j\\) correspondant à chaque variable explicative ;\nles seuils \\(c_g\\) (\\(g = 1, \\dots, k - 1\\)).\n\nOn prédit alors l’appartenance de chaque individu à chaque classe par les formules :\n\\[\\Pr(Y_i = 0) = \\Phi(c_1 - X_i B)\\]\n\\[\\Pr(Y_i = g) = \\Phi(c_g - X_i B) - \\Phi(c_{g-1} - X_i B)\\]\noù \\(\\Phi\\) est :\n\nla fonction de répartition d’une loi gaussienne centrée réduite dans le cas du modèle Probit multivarié ;\nl’inverse de la fonction Logit dans le cas du Logit multivarié."
  },
  {
    "objectID": "td3/enonce-td3.html#présentation-de-létude-et-des-données",
    "href": "td3/enonce-td3.html#présentation-de-létude-et-des-données",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "2 Présentation de l’étude et des données",
    "text": "2 Présentation de l’étude et des données\nLes données étudiées proviennent de Hill et al. (1995) et sont utilisées comme exemple dans l’ouvrage de Kleinbaum et Klein.\n\n288 femmes avec un cancer de l’endomètre participent à l’étude.\n\n\n2.1 Dictionnaire des variables\n\nID : identifiant individuel.\nGRADE : variable ordinale indiquant le stade de la tumeur\n\n0 : bien différenciée\n1 : modérément différenciée\n2 : peu différenciée\n\nRACE : variable indicatrice à deux modalités\n\n1 : peau noire\n0 : peau blanche\n\nESTROGEN : variable indicatrice à deux modalités\n\n1 : la femme a déjà pris des œstrogènes\n0 : sinon\n\nSUBTYPE : variable qualitative à trois modalités codant le sous-type de tissu cancéreux\n\n0 : Adénocarcinome\n1 : Adenosquamous\n2 : Autre\n\nAGE : âge recodé en deux classes\n\n0 : 50–64 ans\n1 : 65–79 ans\n\nSMK : variable binaire indiquant le statut tabagique au moment de l’étude\n\n1 : fumeuse\n0 : non-fumeuse\n\n\n\n\n2.2 Références\n\nHill, H.A., Coates, R.J., Austin, H., Correa, P., Robboy, S.J., Chen, V., Click, L.A., Barrett, R.J., Boyce, J.G., Kotz, H.L., and Harlan, L.C., Racial differences in tumor grade among women with endometrial cancer, Gynecol. Oncol. 56: 154–163, 1995.\nDavid G. Kleinbaum, Mitchel Klein, Logistic Regression – A Self‐Learning Text, Third Edition, Springer, 2010."
  },
  {
    "objectID": "td3/enonce-td3.html#import-des-données",
    "href": "td3/enonce-td3.html#import-des-données",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "3 Import des données",
    "text": "3 Import des données\nOuvrir R et importer les données (cancer.dta utiliser le package haven)."
  },
  {
    "objectID": "td3/enonce-td3.html#modèle-multinomial-pour-expliquer-la-variable-subtype",
    "href": "td3/enonce-td3.html#modèle-multinomial-pour-expliquer-la-variable-subtype",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "4 Modèle multinomial pour expliquer la variable SUBTYPE",
    "text": "4 Modèle multinomial pour expliquer la variable SUBTYPE\nLes variables explicatives sont : RACE, ESTROGEN, SMK et AGE.\n\nEstimation du premier modèle\nAppliquer un premier modèle de régression logit multinomiale prenant en compte les effets des quatre variables explicatives (commande R : nnet).\nSauvegarde des résultats\nSauvegarder les résultats du modèle ajusté.\nValeurs prédites et distribution\nGénérer les valeurs prédites.\nObserver et expliquer la répartition de ces données (commande R : predict).\nTest d’ajustement du modèle\nTester l’ajustement de ce modèle aux données (commande R : generalhoslem), en réduisant le nombre de groupes jusqu’à ce que le test soit applicable.\n\nExpliquer ce qui se passe.\nLe modèle est-il ajusté aux données ?\n\nSimplification du modèle\nEssayer de simplifier ce modèle, en se basant sur des tests de rapport de vraisemblance entre modèles emboîtés.\n\nCombien de degrés de liberté sont appliqués à chaque test ?\nQuel modèle est finalement choisi ?\n\nInterprétation\nInterpréter les résultats du modèle final.\nTableau de contingence des individus bien et mal classés\n\nTabuler la variable SUBTYPE pour constater qu’il y a :\n\n186 adénocarcinomes\n45 adenosquames\n57 autres cas\n\nTabuler les valeurs prédites dans cancer_sub et construire une nouvelle variable pred_subtype prenant la valeur 0 pour les 186 (environ) individus avec les plus grandes valeurs de cancer_sub.\nÉtablir le tableau de contingence des variables subtype_f et pred_subtype, et calculer la proportion de cas mal prédits."
  },
  {
    "objectID": "td3/enonce-td3.html#b.-modèle-multinomial-ordonné-pour-expliquer-la-variable-grade",
    "href": "td3/enonce-td3.html#b.-modèle-multinomial-ordonné-pour-expliquer-la-variable-grade",
    "title": "TD3 – Modèles de régression multinomiale",
    "section": "5 B. Modèle multinomial ordonné pour expliquer la variable GRADE",
    "text": "5 B. Modèle multinomial ordonné pour expliquer la variable GRADE\nLe stade de la tumeur dépend des variables précédentes mais aussi du type de cancer.\n\nModèle ordonné de base\nAjuster un modèle de régression multinomiale ordonnée, avec comme variables explicatives RACE, ESTROGEN, SUBTYPE, AGE et SMK (commande R : polr() (MASS) ).\n\nAttention : il faut bien utiliser la variable grade_ord.\n\nTest d’ajustement via interactions (en R)\nR, comme Stata, ne fournit pas de test d’ajustement global « clé en main » pour les modèles logit/probit ordonnés.\nOn va donc tester l’apport de certaines interactions en comparant des modèles emboîtés au moyen de tests de rapport de vraisemblance (Likelihood Ratio, LR).\nOn utilise pour cela la fonction polr() du package MASS, qui permet d’estimer un modèle logit ordinal.\n\nModèle de base (rappel de la question 8)\n\nAjuster dans R un premier modèle de régression multinomiale ordonnée avec GRADE comme variable expliquée et les variables explicatives : RACE, ESTROGEN, SUBTYPE, AGE et SMK.\nOn utilisera la fonction polr() du package MASS (modèle noté par exemple mod_base).\n\nAjout de l’interaction ESTROGEN × SUBTYPE\n\nAjuster un deuxième modèle ordinal contenant tous les effets simples et, en plus, l’effet de l’interaction entre ESTROGEN et SUBTYPE.\nEn R, on peut écrire cette interaction sous la forme ESTROGEN * SUBTYPE, qui inclut automatiquement les effets simples et le terme d’interaction.\nNoter ce modèle, par exemple, mod_int_ES.\n\nTest de rapport de vraisemblance entre les deux modèles\n\nComparer mod_base et mod_int_ES à l’aide d’un test de rapport de vraisemblance (LR test) via la fonction anova(mod_base, mod_int_ES) dans R.\n\nInterpréter :\n\nla statistique de test (χ²),\nle nombre de degrés de liberté (lié au nombre de paramètres supplémentaires dans le modèle avec interaction),\nla p-value.\n\nConclure : l’interaction ESTROGEN × SUBTYPE améliore-t-elle significativement le modèle ? Faut-il la conserver dans le modèle final ?\n\nAutres interactions possibles\n\nRépéter la même démarche avec une ou deux autres interactions en effets simples, par exemple :\n\nESTROGEN × AGE ;\nSUBTYPE × AGE ;\nou toute autre interaction jugée pertinente.\n\n\nPour chaque nouvelle interaction :\n\nAjuster le modèle étendu (par exemple mod_int_EAGE, mod_int_SAGE, etc.) ;\nComparer ce modèle au modèle de base mod_base au moyen d’un test LR via anova() ;\nDiscuter de l’intérêt de conserver ou non l’interaction dans le modèle au vu de la p-value et, éventuellement, du critère AIC.\n\n\nDiscussion\n\nÀ partir de ces tests, proposer un modèle ordinal « raisonnable » :\n\nsuffisamment souple pour capter les effets importants ;\n\nmais pas trop complexe (principe de parcimonie).\n\n\nDiscuter brièvement des limites de ce type de « test d’ajustement via interactions » pour juger de la qualité globale du modèle.\n\n\nSélection de modèle par AIC\nEn utilisant le critère AIC, rechercher un modèle plus simple permettant de prédire le stade de la tumeur selon son type.\nModèle final et interprétation\n\nQuel modèle final choisit-on ?\nInterpréter les résultats de ce modèle."
  },
  {
    "objectID": "td2/td2-slides.html#quand-utiliser-ces-modèles",
    "href": "td2/td2-slides.html#quand-utiliser-ces-modèles",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.1 Quand utiliser ces modèles ?",
    "text": "1.1 Quand utiliser ces modèles ?\nLa régression logistique et la régression probit sont utilisées lorsque la variable à expliquer est binaire :\n\\(Y_i \\in {0,1}\\)\n\nExemple : défaut de paiement / pas de défaut\nObjectif : estimer la probabilité \\(P(Y_i = 1 \\mid X_i)\\) en fonction de caractéristiques \\(X_i\\)\n\nLes variables explicatives peuvent être quantitatives ou qualitatives."
  },
  {
    "objectID": "td2/td2-slides.html#pourquoi-ne-pas-utiliser-une-régression-linéaire",
    "href": "td2/td2-slides.html#pourquoi-ne-pas-utiliser-une-régression-linéaire",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.2 Pourquoi ne pas utiliser une régression linéaire ?",
    "text": "1.2 Pourquoi ne pas utiliser une régression linéaire ?\nUne régression linéaire classique :\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\)\npeut donner des valeurs prédites hors de [0, 1], ce qui est absurde pour une probabilité.\nIl faut donc introduire une fonction de lien qui transforme l’intervalle (0, 1) en \\(\\mathbb{R}\\)."
  },
  {
    "objectID": "td2/td2-slides.html#fonction-de-lien-du-modèle-logit",
    "href": "td2/td2-slides.html#fonction-de-lien-du-modèle-logit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.3 Fonction de lien du modèle Logit",
    "text": "1.3 Fonction de lien du modèle Logit\n\\(\\text{logit}(p) = \\ln\\left(\\frac{p}{1 - p}\\right) \\quad \\text{et} \\quad p = \\frac{e^{x}}{1 + e^{x}} = \\frac{1}{1 + e^{-x}}\\)\nLe modèle s’écrit :\n\\(\\text{logit}(P(Y_i = 1)) = \\beta_0 + \\beta1 X{i1} + \\dots + \\beta_p X{ip}\\)\nLes coefficients \\(\\beta_j\\) s’interprètent via les odds-ratios : \\(OR_j = e^{\\beta_j}\\)"
  },
  {
    "objectID": "td2/td2-slides.html#fonction-de-lien-du-modèle-probit",
    "href": "td2/td2-slides.html#fonction-de-lien-du-modèle-probit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.4 Fonction de lien du modèle Probit",
    "text": "1.4 Fonction de lien du modèle Probit\nLe modèle Probit suppose qu’il existe une variable latente \\(Y_i^*\\) telle que :\n\\(Y_i^* = \\beta_0 + \\beta1 X{i1} + \\dots + \\beta_p X{ip} + \\varepsilon_i \\quad \\text{avec} \\quad \\varepsilon_i \\sim \\mathcal{N}(0,1)\\)\net on observe :\n\\(Y_i = 1 \\text{ si } Y_i^* &gt; 0\\)\nd’où :\n\\(P(Y_i = 1) = \\Phi(\\beta_0 + \\beta_1 X_i)\\) où \\(\\Phi\\) est la fonction de répartition de la loi normale centrée réduite."
  },
  {
    "objectID": "td2/td2-slides.html#comparaison-graphique-des-liens-logit-et-probit",
    "href": "td2/td2-slides.html#comparaison-graphique-des-liens-logit-et-probit",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.5 Comparaison graphique des liens Logit et Probit",
    "text": "1.5 Comparaison graphique des liens Logit et Probit\n\n\nCode\nlibrary(ggplot2)\n\nx &lt;- seq(-6, 6, length.out = 200) \n\ndf_link &lt;- data.frame( x = x, Logit = 1 / (1 + exp(-x)), Probit = pnorm(x) )\n\nggplot(df_link, aes(x = x)) + geom_line(aes(y = Logit, color = \"Logit\")) + geom_line(aes(y = Probit, color = \"Probit\"), linetype = 2) + scale_color_manual(values = c(\"Logit\" = \"steelblue\", \"Probit\" = \"firebrick\")) + labs( title = \"Comparaison des liens Logit et Probit\", x = \"Score linéaire (Xβ)\", y = \"Probabilité prédite\", color = \"Modèle\" ) + theme_minimal()\n\n\n\n\nFigure 1: Comparaison des fonctions de lien Logit et Probit\nObservation :\n\nLes deux courbes sont très proches ; la principale différence réside dans la forme légèrement plus aplatie du Probit aux extrémités.\nEn pratique, les résultats logit et probit sont très similaires (seuls les coefficients changent d’échelle : \\(\\beta_{\\text{logit}} ≈ 1.6 β_{\\text{probit}}\\)."
  },
  {
    "objectID": "td2/td2-slides.html#interprétation-économique",
    "href": "td2/td2-slides.html#interprétation-économique",
    "title": "TD 2 — Régression logistique (R)",
    "section": "1.6 Interprétation économique",
    "text": "1.6 Interprétation économique\n\nLogit : privilégié quand on interprète les coefficients en termes d’odds-ratios (très courant en santé et sciences sociales).\nProbit : privilégié en économie microéconométrique, car il se relie naturellement à un modèle de variable latente et au Tobit."
  },
  {
    "objectID": "td2/td2-slides.html#télécharger-le-fichier-bankloant.xls-depuis-lent-puis-importer-les-données-dans-r",
    "href": "td2/td2-slides.html#télécharger-le-fichier-bankloant.xls-depuis-lent-puis-importer-les-données-dans-r",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.1 Télécharger le fichier bankloanT.xls depuis l’ENT, puis importer les données dans R",
    "text": "2.1 Télécharger le fichier bankloanT.xls depuis l’ENT, puis importer les données dans R\n\n\nCode\ndf0 &lt;- read_excel(\"./data/bankloanT.xls\") |&gt; clean_names()\ndf0 |&gt; glimpse()\n\n\nRows: 850\nColumns: 9\n$ age      &lt;dbl&gt; 44, 26, 47, 31, 33, 45, 45, 35, 38, 32, 36, 47, 34, 39, 27, 4…\n$ ed       &lt;chr&gt; \"College degree\", \"High school degree\", \"Some college\", \"Did …\n$ employ   &lt;dbl&gt; 18, 6, 16, 5, 10, 21, 16, 17, 7, 0, 4, 23, 16, 8, 7, 8, 9, 0,…\n$ address  &lt;dbl&gt; 23, 6, 7, 7, 2, 26, 21, 4, 4, 4, 17, 11, 9, 0, 8, 18, 6, 5, 1…\n$ income   &lt;dbl&gt; 78, 30, 266, 23, 54, 132, 80, 42, 64, 20, 25, 115, 79, 21, 30…\n$ debtinc  &lt;chr&gt; \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"4\", \"4\", \"…\n$ creddebt &lt;chr&gt; \"0.56472\", \"0.1437\", \"2.19184\", \"0.046\", \"0.11988\", \"2.55816\"…\n$ othdebt  &lt;chr&gt; \"0.21528\", \"0.1563\", \"3.12816\", \"0.414\", \"1.50012\", \"1.40184\"…\n$ default  &lt;chr&gt; NA, \"No\", NA, NA, NA, \"No\", \"No\", \"No\", \"No\", \"Yes\", NA, \"No\"…"
  },
  {
    "objectID": "td2/td2-slides.html#etudier-la-distribution-de-la-variable-ed.-créer-une-variable-catégorielle-puis-une-variable-ne-contenant-que-4-classes.",
    "href": "td2/td2-slides.html#etudier-la-distribution-de-la-variable-ed.-créer-une-variable-catégorielle-puis-une-variable-ne-contenant-que-4-classes.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.2 Etudier la distribution de la variable ed. Créer une variable catégorielle, puis une variable ne contenant que 4 classes.",
    "text": "2.2 Etudier la distribution de la variable ed. Créer une variable catégorielle, puis une variable ne contenant que 4 classes.\n\n\nCode\ndf0 |&gt; count(ed) |&gt; arrange(desc(n))\n\n\n# A tibble: 5 × 2\n  ed                               n\n  &lt;chr&gt;                        &lt;int&gt;\n1 Did not complete high school   460\n2 High school degree             235\n3 Some college                   101\n4 College degree                  49\n5 Post-undergraduate degree        5"
  },
  {
    "objectID": "td2/td2-slides.html#etudier-la-matrice-des-corrélations.",
    "href": "td2/td2-slides.html#etudier-la-matrice-des-corrélations.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.3 Etudier la matrice des corrélations.",
    "text": "2.3 Etudier la matrice des corrélations.\n\n\nCode\nnum_vars &lt;- c(\"age\",\"employ\",\"address\",\"income\",\"debtinc\",\"creddebt\",\"othdebt\")\ndf1 &lt;- df1 |&gt;\n  mutate(\n    debtinc  = as.numeric(debtinc),\n    creddebt = as.numeric(creddebt),\n    othdebt  = as.numeric(othdebt)\n  )\ncor_mat &lt;- df1 |&gt;\n  select(all_of(num_vars)) |&gt;\n  drop_na() |&gt;\n  cor()\n\nlibrary(ggcorrplot)\nggcorrplot(\n  cor_mat,\n  hc.order = TRUE,           # ordonne les variables par similarité\n  lab = TRUE,                # affiche les coefficients\n  lab_size = 3,\n  colors = c(\"tomato2\", \"white\", \"seagreen3\"),\n  title = \"Corrélogramme des variables quantitatives\",\n  ggtheme = theme_minimal()\n)"
  },
  {
    "objectID": "td2/td2-slides.html#recoder-la-variable-à-expliquer-en-variable-quantitative-puis-réaliser-une-première-régression-logistique.",
    "href": "td2/td2-slides.html#recoder-la-variable-à-expliquer-en-variable-quantitative-puis-réaliser-une-première-régression-logistique.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.4 Recoder la variable à expliquer en variable quantitative puis réaliser une première régression logistique.",
    "text": "2.4 Recoder la variable à expliquer en variable quantitative puis réaliser une première régression logistique.\n\n\nCode\ndf2 &lt;- df1 |&gt;\n  mutate(\n    default_num = case_when(\n      default == \"Yes\" ~ 1,\n      default == \"No\"  ~ 0,\n      TRUE ~ NA_real_   # conserve les NA existants\n    )\n  )\nform1 &lt;- default_num ~ age + employ + address + income + debtinc + creddebt + othdebt\nmod1 &lt;- glm(form1, data=df2, family=binomial(\"logit\"))\nsummary(mod1)\n\n\n\nCall:\nglm(formula = form1, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.377693   0.571585  -2.410   0.0159 *  \nage          0.033694   0.017341   1.943   0.0520 .  \nemploy      -0.265035   0.031996  -8.283  &lt; 2e-16 ***\naddress     -0.103964   0.023193  -4.483 7.37e-06 ***\nincome      -0.007530   0.008099  -0.930   0.3525    \ndebtinc      0.065253   0.030620   2.131   0.0331 *  \ncreddebt     0.628263   0.113738   5.524 3.32e-08 ***\nothdebt      0.070289   0.077693   0.905   0.3656    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 552.21  on 692  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 568.21\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2-slides.html#réaliser-une-deuxième-régression-logistique-incluant-aussi-la-variable-educ-en-classe.",
    "href": "td2/td2-slides.html#réaliser-une-deuxième-régression-logistique-incluant-aussi-la-variable-educ-en-classe.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.5 Réaliser une deuxième régression logistique incluant aussi la variable educ en classe.",
    "text": "2.5 Réaliser une deuxième régression logistique incluant aussi la variable educ en classe.\n\n\nCode\nform2 &lt;- update(form1, . ~ . + ed4)\nmod2 &lt;- glm(form2, data=df2, family=binomial(\"logit\"))\nsummary(mod2)\n\n\n\nCall:\nglm(formula = form2, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.469161   0.585721  -2.508   0.0121 *  \nage          0.036527   0.017564   2.080   0.0376 *  \nemploy      -0.259784   0.033353  -7.789 6.76e-15 ***\naddress     -0.105959   0.023331  -4.542 5.58e-06 ***\nincome      -0.007386   0.007927  -0.932   0.3515    \ndebtinc      0.071049   0.030620   2.320   0.0203 *  \ncreddebt     0.616294   0.112296   5.488 4.06e-08 ***\nothdebt      0.052860   0.078374   0.674   0.5000    \ned4.L        0.003376   0.321415   0.011   0.9916    \ned4.Q       -0.334133   0.276144  -1.210   0.2263    \ned4.C       -0.030154   0.249875  -0.121   0.9039    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 550.03  on 689  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 572.03\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2-slides.html#tester-lajustement-de-ce-modèle-complet.",
    "href": "td2/td2-slides.html#tester-lajustement-de-ce-modèle-complet.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.6 Tester l’ajustement de ce modèle complet.",
    "text": "2.6 Tester l’ajustement de ce modèle complet.\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=4)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 2.3796, df = 2, p-value = 0.3043\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=5)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 0.9883, df = 3, p-value = 0.8041\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=6)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.3862, df = 4, p-value = 0.2499\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=7)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 2.0796, df = 5, p-value = 0.838\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=8)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 3.9178, df = 6, p-value = 0.6878\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=9)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.5538, df = 7, p-value = 0.5927\n\n\nCode\nhoslem.test(mod2$y, fitted(mod2), g=10)\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mod2$y, fitted(mod2)\nX-squared = 5.9712, df = 8, p-value = 0.6505"
  },
  {
    "objectID": "td2/td2-slides.html#grâce-à-la-commande-anova-réaliser-un-test-de-rapport-de-vraisemblance-entre-les-deux-modèles-ajustés.",
    "href": "td2/td2-slides.html#grâce-à-la-commande-anova-réaliser-un-test-de-rapport-de-vraisemblance-entre-les-deux-modèles-ajustés.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.7 Grâce à la commande anova, réaliser un test de rapport de vraisemblance entre les deux modèles ajustés.",
    "text": "2.7 Grâce à la commande anova, réaliser un test de rapport de vraisemblance entre les deux modèles ajustés.\n\n\nCode\nanova(mod1, mod2, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt\nModel 2: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt + ed4\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       692     552.21                     \n2       689     550.03  3    2.176   0.5367\n\n\n\nLa p-value = 0.54 → on ne rejette pas \\(H_0\\)​.\nAutrement dit :\n\nl’ajout de la variable d’éducation ed4 n’améliore pas significativement la qualité du modèle."
  },
  {
    "objectID": "td2/td2-slides.html#ôter-la-variable-la-moins-significative-du-modèle-retenu.",
    "href": "td2/td2-slides.html#ôter-la-variable-la-moins-significative-du-modèle-retenu.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.8 Ôter la variable la moins significative du modèle retenu.",
    "text": "2.8 Ôter la variable la moins significative du modèle retenu.\n\n\nCode\nform3 &lt;- update(form1, . ~ . - othdebt)\nmod3 &lt;- glm(form3, data=df2, family=binomial(\"logit\"))\nsummary(mod3)\n\n\n\nCall:\nglm(formula = form3, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.591125   0.522271  -3.047  0.00231 ** \nage          0.033618   0.017383   1.934  0.05312 .  \nemploy      -0.257986   0.030791  -8.379  &lt; 2e-16 ***\naddress     -0.103119   0.023141  -4.456 8.34e-06 ***\nincome      -0.002526   0.006320  -0.400  0.68939    \ndebtinc      0.086173   0.020071   4.293 1.76e-05 ***\ncreddebt     0.595490   0.104930   5.675 1.39e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 553.02  on 693  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 567.02\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\nanova(mod2, mod3, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt + \n    othdebt + ed4\nModel 2: default_num ~ age + employ + address + income + debtinc + creddebt\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       689     550.03                     \n2       693     553.02 -4  -2.9856   0.5602"
  },
  {
    "objectID": "td2/td2-slides.html#une-variable-est-à-nouveau-très-peu-significative.",
    "href": "td2/td2-slides.html#une-variable-est-à-nouveau-très-peu-significative.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.9 Une variable est à nouveau très peu significative.",
    "text": "2.9 Une variable est à nouveau très peu significative.\n\n\nCode\nform4 &lt;- update(form3, . ~ . - income)\nmod4 &lt;- glm(form4, data=df2, family=binomial(\"logit\"))\nsummary(mod4)\n\n\n\nCall:\nglm(formula = form4, family = binomial(\"logit\"), data = df2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.63128    0.51268  -3.182  0.00146 ** \nage          0.03256    0.01717   1.896  0.05799 .  \nemploy      -0.26076    0.03011  -8.662  &lt; 2e-16 ***\naddress     -0.10365    0.02309  -4.490 7.13e-06 ***\ndebtinc      0.08926    0.01855   4.813 1.49e-06 ***\ncreddebt     0.57265    0.08723   6.565 5.20e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 553.18  on 694  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 565.18\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\nanova(mod3, mod4, test=\"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel 1: default_num ~ age + employ + address + income + debtinc + creddebt\nModel 2: default_num ~ age + employ + address + debtinc + creddebt\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       693     553.02                     \n2       694     553.18 -1 -0.15877   0.6903"
  },
  {
    "objectID": "td2/td2-slides.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-avec-une-règle-de-coupure-à-05",
    "href": "td2/td2-slides.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-avec-une-règle-de-coupure-à-05",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.10 Etablir le tableau de contingence des individus bien ou mal classés avec une règle de coupure à 0,5",
    "text": "2.10 Etablir le tableau de contingence des individus bien ou mal classés avec une règle de coupure à 0,5\n\n\nCode\n# Probabilités prédites\ndf2_nona &lt;- df2 |&gt; drop_na(age, employ, address, income, debtinc, creddebt, othdebt, default_num, ed4)\n\np_hat &lt;- predict(mod4, newdata = df2_nona, type = \"response\")\n\ndf2_nona &lt;- df2_nona |&gt;\n  mutate(\n    p_hat = p_hat,\n    pred_class = if_else(p_hat &gt;= 0.5, 1, 0)\n  )\n\n\ntable(Predicted = df2_nona$pred_class, Observed = df2_nona$default_num)\n\n\n         Observed\nPredicted   0   1\n        0 476  89\n        1  41  94\n\n\nCode\nmean(df2_nona$pred_class == df2_nona$default_num, na.rm = TRUE)\n\n\n[1] 0.8142857"
  },
  {
    "objectID": "td2/td2-slides.html#etablir-la-courbe-roc-pour-le-meilleur-modèle-puis-calculer-les-probabilités-prédites-et-étudier-leur-distribution",
    "href": "td2/td2-slides.html#etablir-la-courbe-roc-pour-le-meilleur-modèle-puis-calculer-les-probabilités-prédites-et-étudier-leur-distribution",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.11 Etablir la courbe ROC pour le « meilleur » modèle, puis calculer les “probabilités prédites” et étudier leur distribution",
    "text": "2.11 Etablir la courbe ROC pour le « meilleur » modèle, puis calculer les “probabilités prédites” et étudier leur distribution\n\n\nCode\nroc_obj &lt;- roc(df2_nona$default_num, df2_nona$p_hat)\n\nplot(roc_obj, main=\"Courbe ROC — Modèle logit 2025\")\n\n\n\n\n\n\n\n\n\nCode\nauc(roc_obj)\n\n\nArea under the curve: 0.8582\n\n\nCode\nggplot(df2_nona, aes(x = p_hat, fill = factor(default_num))) +\n  geom_histogram(alpha = 0.6, position = \"identity\", bins = 30) +\n  labs(title = \"Distribution des probabilités prédites par classe réelle\",\n       x = \"p̂(default = 1)\", fill = \"Défaut observé\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n2.11.1 Interprétation du graphe\n\nL’axe des abscisses montre les probabilités prédites de défaut \\(\\hat{p} = P(\\text{default}=1|X)\\) .\nL’axe des ordonnées montre le nombre d’individus dans chaque intervalle de probabilité.\nLa couleur rouge (0) représente les emprunteurs qui n’ont pas fait défaut.\nLa couleur bleue (1) représente les emprunteurs qui ont fait défaut."
  },
  {
    "objectID": "td2/td2-slides.html#refaire-la-même-modélisation-avec-un-modèle-probit-et-observer-les-différences-et-ressemblances-avec-la-modélisation-logit.",
    "href": "td2/td2-slides.html#refaire-la-même-modélisation-avec-un-modèle-probit-et-observer-les-différences-et-ressemblances-avec-la-modélisation-logit.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.12 Refaire la même modélisation avec un modèle Probit et observer les différences et ressemblances avec la modélisation Logit.",
    "text": "2.12 Refaire la même modélisation avec un modèle Probit et observer les différences et ressemblances avec la modélisation Logit.\n\n\nCode\nmod_probit &lt;- glm(formula(mod4), data=df2, family=binomial(\"probit\"))\nsummary(mod_probit)\n\n\n\nCall:\nglm(formula = formula(mod4), family = binomial(\"probit\"), data = df2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.963869   0.297087  -3.244  0.00118 ** \nage          0.018237   0.009972   1.829  0.06742 .  \nemploy      -0.144955   0.016217  -8.939  &lt; 2e-16 ***\naddress     -0.055609   0.012835  -4.333 1.47e-05 ***\ndebtinc      0.051049   0.010563   4.833 1.35e-06 ***\ncreddebt     0.322172   0.048056   6.704 2.03e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 804.36  on 699  degrees of freedom\nResidual deviance: 554.57  on 694  degrees of freedom\n  (150 observations deleted due to missingness)\nAIC: 566.57\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "td2/td2-slides.html#pour-aller-plus-loin",
    "href": "td2/td2-slides.html#pour-aller-plus-loin",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.13 Pour aller plus loin…",
    "text": "2.13 Pour aller plus loin…\nSupposant qu’un individu ne remboursant pas son emprunt coûte en moyenne 100000$, et qu’un individu payant son emprunt rapporte en moyenne 40000$, on peut calculer (…) qu’il est optimal de n’accorder un prêt qu’aux individus ayant une probabilité de rembourser estimée à 0,7 ou plus."
  },
  {
    "objectID": "td2/td2-slides.html#règle-de-décision-probabilité-de-remboursement-0.7",
    "href": "td2/td2-slides.html#règle-de-décision-probabilité-de-remboursement-0.7",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.14 Règle de décision (probabilité de remboursement >= 0.7)",
    "text": "2.14 Règle de décision (probabilité de remboursement &gt;= 0.7)\n\n\nCode\ndf2_nona &lt;- df2_nona |&gt; mutate(p_repay = 1 - p_hat, grant = as.numeric(p_repay &gt;= 0.7))\nmean(df2_nona$grant, na.rm = TRUE)\n\n\n[1] 0.64"
  },
  {
    "objectID": "td2/td2-slides.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-en-considérant-comme-défaillants-potentiels-tous-les-individus-ayant-moins-de-70-de-chances-de-rembourser.",
    "href": "td2/td2-slides.html#etablir-le-tableau-de-contingence-des-individus-bien-ou-mal-classés-en-considérant-comme-défaillants-potentiels-tous-les-individus-ayant-moins-de-70-de-chances-de-rembourser.",
    "title": "TD 2 — Régression logistique (R)",
    "section": "2.15 Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser.",
    "text": "2.15 Etablir le tableau de contingence des individus bien ou mal classés en considérant comme défaillants potentiels tous les individus ayant moins de 70% de chances de rembourser.\n\n\nCode\nthr_default &lt;- 0.3\ntable(Predicted = df2_nona$p_hat &gt;= thr_default, Observed = df2_nona$default_num)\n\n\n         Observed\nPredicted   0   1\n    FALSE 405  43\n    TRUE  112 140\n\n\nCode\ntab &lt;- table(Predicted = df2_nona$p_hat &gt;= thr_default,\n             Observed = df2_nona$default_num)\naccuracy &lt;- sum(diag(tab)) / sum(tab)\naccuracy\n\n\n[1] 0.7785714\n\n\nCode\nprop.table(tab, 2)   # pourcentage par classe observée\n\n\n         Observed\nPredicted         0         1\n    FALSE 0.7833656 0.2349727\n    TRUE  0.2166344 0.7650273\n\n\n\nEn fixant le seuil à 0,3 (c’est-à-dire en considérant comme « défaillant potentiel » tout individu ayant moins de 70 % de chances de rembourser), le modèle devient plus prudent : il classe davantage d’individus comme risqués. Le nombre de vrais positifs (défaillants correctement détectés) augmente, mais au prix d’une hausse des faux positifs (bons payeurs injustement rejetés).\nAutrement dit, la règle minimise les pertes dues aux impayés, mais réduit le volume de prêts accordés. C’est un compromis classique entre risque de crédit et rentabilité :\n\nPlus le seuil est bas, plus la banque protège son portefeuille, mais plus elle refuse de bons clients."
  }
]