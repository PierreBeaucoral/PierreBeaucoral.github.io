[
  {
    "objectID": "Quizz.html",
    "href": "Quizz.html",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "",
    "text": "Objectif : quiz de 2h pour réviser Introduction à l’économétrie en vue de l’examen (questions de cours + applications, sans EViews).\n\nCoche les réponses directement dans la page.\nClique sur « Corriger le quiz » pour voir ton score global.\nLes encadrés verts = bonnes réponses ; rouges = à retravailler.\nCertains exercices (calculs, mini-études de cas, tests sur les erreurs, IV) ne sont pas scorés automatiquement : entraîne-toi comme pour l’examen."
  },
  {
    "objectID": "Quizz.html#notions-de-base",
    "href": "Quizz.html#notions-de-base",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "1 1. Notions de base",
    "text": "1 1. Notions de base\n\n1.1 Q1 – Variables et échantillon\n\n\nQ1.1 – Comment définir une variable expliquée (dépendante) dans un modèle de régression ?\n\n  C’est la variable qui cause toujours toutes les autres. \n  C’est la variable dont on cherche à expliquer la variation à l’aide d’autres variables. \n  C’est n’importe quelle variable binaire. \n  C’est la variable qui a le plus de variance dans l’échantillon. \n\n\nSolution et commentaire\n\nLa variable expliquée (ou dépendante) est celle dont on cherche à modéliser la variation en fonction des variables explicatives (ou régressseurs).\nPar exemple, le salaire en fonction du niveau d’éducation, de l’expérience, etc.\n\n\n\n\nQ1.2 – Qu’est-ce qu’un estimateur sans biais ?\n\n  Un estimateur dont l’espérance est égale à la vraie valeur du paramètre. \n  Un estimateur qui donne forcément la vraie valeur dans l’échantillon observé. \n  Un estimateur qui a la plus petite variance possible. \n  Un estimateur toujours positif. \n\n\nSolution et commentaire\n\nUn estimateur \\(\\hat\\theta\\) est sans biais si \\(\\mathbb E[\\hat\\theta] = \\theta\\), où \\(\\theta\\) est le vrai paramètre à estimer.\nCela ne veut pas dire que dans un échantillon donné, \\(\\hat\\theta = \\theta\\), mais qu’en moyenne (sur des échantillons répétés), l’estimateur « vise juste ».\n\n\n\n\nQ1.3 – Erreur de mesure classique sur la variable expliquée \\(Y\\)\n\nOn observe \\(Y^{obs} = Y + u\\), où \\(u\\) est un bruit de mesure indépendant de tout. Que se passe-t-il pour l’estimation MCO (OLS) d’un modèle linéaire ?\n  Les coefficients OLS restent sans biais mais les erreurs standards sont plus grandes. \n  Les coefficients OLS sont biaisés vers zéro. \n  Les coefficients OLS sont biaisés sans direction claire. \n  Le modèle ne peut pas être estimé par OLS. \n\n\nSolution et commentaire\n\nUne erreur de mesure classique sur \\(Y\\) ajoute du bruit au côté gauche mais n’introduit pas de corrélation entre les régressseurs et l’erreur.\nLes MCO restent donc sans biais mais moins précis (variance plus grande)."
  },
  {
    "objectID": "Quizz.html#modèle-de-régression-linéaire-simple",
    "href": "Quizz.html#modèle-de-régression-linéaire-simple",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "2 2. Modèle de régression linéaire simple",
    "text": "2 2. Modèle de régression linéaire simple\nConsidère le modèle :\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + u_i.\n\\]\n\n2.1 Q2 – Interprétation et hypothèses\n\n\nQ2.1 – Interprétation de \\(\\beta_1\\)\n\n  La valeur de \\(Y\\) lorsque \\(X=0\\). \n  La variation moyenne de \\(Y\\) associée à une augmentation d’une unité de \\(X\\). \n  La corrélation entre \\(X\\) et \\(Y\\). \n  La variance de \\(Y\\). \n\n\nSolution et commentaire\n\nDans un modèle linéaire simple, \\(\\beta_1\\) mesure la pente de la relation moyenne entre \\(Y\\) et \\(X\\) :\nune augmentation d’une unité de \\(X\\) est associée à une variation moyenne de \\(\\beta_1\\) unités de \\(Y\\).\n\n\n\n\nQ2.2 – Quelles hypothèses sont nécessaires pour obtenir un estimateur MCO sans biais de \\(\\beta_1\\) ? (plusieurs réponses)\n\n  Les erreurs \\(u_i\\) suivent une loi normale. \n  \\(\\mathbb E[u_i \\mid X_i] = 0\\). \n  Il existe de la variation dans \\(X_i\\) (pas de constante parfaite). \n  La taille d’échantillon \\(n\\) est supérieure à 1000. \n  \\(\\{(X_i, Y_i)\\}\\) sont i.i.d. (indépendants et identiquement distribués). \n\n\nSolution et commentaire\n\nPour l’absence de biais en MCO, on a besoin notamment de : - Exogénéité conditionnelle : \\(\\mathbb E[u_i \\mid X_i] = 0\\) ; - Variation dans \\(X\\) (pas de colinéarité parfaite) ; - Échantillon i.i.d. dans la plupart des cadres.\nLa normalité des erreurs n’est pas nécessaire pour le sans biais (elle sert plutôt pour certains résultats exacts en petits échantillons).\n\n\n\n\nQ2.3 – Coefficient de détermination \\(R^2\\)\n\n  C’est la corrélation entre \\(Y\\) et \\(\\hat Y\\). \n  C’est la variance de \\(Y\\). \n  C’est la part de la variance de \\(Y\\) expliquée par le modèle. \n  C’est la pente de la droite de régression. \n\n\nSolution et commentaire\n\nLe \\(R^2\\) est défini comme : \\[\nR^2 = \\frac{\\text{SCR}}{\\text{SCT}} = 1 - \\frac{\\text{SCE}}{\\text{SCT}},\n\\] c’est-à-dire la fraction de la variance totale de \\(Y\\) expliquée par la régression."
  },
  {
    "objectID": "Quizz.html#régression-multiple-et-interprétation-des-coefficients",
    "href": "Quizz.html#régression-multiple-et-interprétation-des-coefficients",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "3 3. Régression multiple et interprétation des coefficients",
    "text": "3 3. Régression multiple et interprétation des coefficients\nOn considère maintenant : \\[\nY_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + u_i.\n\\]\n\n3.1 Q3 – Effets partiels et variables omises\n\n\nQ3.1 – Interprétation de \\(\\beta_1\\) dans une régression multiple\n\n  C’est l’effet moyen sur \\(Y\\) d’une augmentation d’une unité de \\(X_1\\) en maintenant les autres régressseurs constants. \n  C’est la corrélation simple entre \\(X_1\\) et \\(Y\\). \n  C’est la covariance entre \\(X_1\\) et \\(X_2\\). \n  C’est le changement moyen de \\(X_2\\) quand \\(X_1\\) augmente d’une unité. \n\n\nSolution et commentaire\n\nDans une régression multiple, \\(\\beta_1\\) mesure un effet partiel : la variation de \\(Y\\) lorsque \\(X_1\\) augmente, toutes choses égales par ailleurs (c’est-à-dire à \\(X_2\\) fixé).\n\n\n\n\nQ3.2 – Biais de variable omise (plusieurs réponses)\n\nOn omet une variable \\(Z\\) pertinente. Dans quelles situations le coefficient estimé \\(\\tilde\\beta_1\\) sur \\(X_1\\) est-il biaisé ?\n  Quand \\(Z\\) est corrélée avec \\(X_1\\) et a un effet causal sur \\(Y\\). \n  Quand \\(Z\\) est complètement indépendante de \\(X_1\\). \n  Quand \\(Z\\) n’a aucun effet sur \\(Y\\). \n  Quand \\(Z\\) capture un facteur confondant commun à \\(X_1\\) et \\(Y\\). \n\n\nSolution et commentaire\n\nLe biais de variable omise apparaît quand la variable manquante : - a un effet sur \\(Y\\) et - est corrélée avec \\(X_1\\).\nDans ce cas, l’effet de \\(Z\\) est « absorbé » dans le coefficient de \\(X_1\\), qui devient biaisé.\n\n\n\n\nQ3.3 – Multicolinéarité parfaite\n\n  Se produit lorsque l’un des régressseurs est une combinaison linéaire exacte des autres. \n  Se produit lorsque les erreurs sont corrélées dans le temps. \n  Se produit lorsque \\(Y\\) suit une loi normale. \n  Est nécessaire pour identifier le modèle. \n\n\nSolution et commentaire\n\nLa multicolinéarité parfaite (par ex. \\(X_3 = 2X_1 + X_2\\) pour toutes les observations) empêche l’inversion de \\(X'X\\).\nLe logiciel ne peut alors pas estimer tous les coefficients ; il en « enlève » au moins un."
  },
  {
    "objectID": "Quizz.html#tests-sur-les-coefficients-t-f-intervalles-de-confiance",
    "href": "Quizz.html#tests-sur-les-coefficients-t-f-intervalles-de-confiance",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "4 4. Tests sur les coefficients : \\(t\\), \\(F\\), intervalles de confiance",
    "text": "4 4. Tests sur les coefficients : \\(t\\), \\(F\\), intervalles de confiance\n\n4.1 Q4 – Tests sur les coefficients\n\n\nQ4.1 – Statistique de test \\(t\\) pour \\(H_0 : \\beta_j = 0\\)\n\n  \\(t = \\dfrac{\\hat\\beta_j - 0}{\\text{se}(\\hat\\beta_j)}\\) \n  \\(t = \\dfrac{\\hat\\beta_j}{\\hat\\sigma^2}\\) \n  \\(t = \\dfrac{\\hat\\beta_j}{n}\\) \n  \\(t = \\dfrac{\\hat\\beta_j - 1}{\\text{se}(\\hat\\beta_j)}\\) \n\n\nSolution et commentaire\n\nPour tester \\(H_0 : \\beta_j = 0\\), on utilise : \\[\nt = \\frac{\\hat\\beta_j - 0}{\\text{se}(\\hat\\beta_j)}.\n\\] On compare ensuite \\(|t|\\) à la valeur tabulée \\(t^{*}_{\\alpha/2,\\ \\text{ddl}}\\) (par exemple au seuil de 5 %, avec les degrés de liberté adaptés).\nSi \\(|t| &gt; t^{*}\\), on rejette \\(H_0\\) ; sinon, on ne la rejette pas.\n\n\n\n\nQ4.2 – Règle de décision avec la table de Student (seuil 5 %)\n\nOn teste \\(H_0 : \\beta_1 = 0\\) dans un modèle avec 100 observations et 4 coefficients estimés (constante incluse). On obtient \\(t = 2{,}30\\).\nOn rappelle que la valeur tabulée à 5 % (bilatéral) pour environ 96 degrés de liberté est \\(t^* \\approx 1{,}98\\).\n  On rejette \\(H_0\\) car \\(|t| = 2{,}30 &gt; 1{,}98\\). \n  On ne rejette pas \\(H_0\\) car \\(|t| = 2{,}30 &lt; 1{,}98\\). \n  On ne peut rien dire sans connaître le \\(R^2\\). \n  Il faut forcément utiliser un logiciel pour conclure. \n\n\nSolution et commentaire\n\nDegrés de liberté \\(\\text{ddl} = n - K = 100 - 4 = 96\\).\nAu seuil de 5 % (bilatéral), la valeur tabulée est \\(t^* \\approx 1{,}98\\).\nComme \\(|t| = 2{,}30 &gt; 1{,}98\\), on rejette \\(H_0\\) et on conclut que \\(\\beta_1\\) est significativement différent de 0 au seuil de 5 %.\n\n\n\n\nQ4.3 – Test \\(F\\) pour plusieurs restrictions linéaires\n\n  Permet de tester conjointement des hypothèses du type \\(R\\beta = r\\) (par ex. \\(\\beta_2 = 0\\) et \\(\\beta_3 = 0\\)). \n  Ne sert qu’à tester la normalité des résidus. \n  Ne s’applique que dans le cas d’une seule restriction. \n  Est identique au test \\(t\\). \n\n\nSolution et commentaire\n\nLe test \\(F\\) permet de tester plusieurs restrictions linéaires en même temps, par exemple : \\[\nH_0 : \\beta_2 = 0 \\quad\\text{et}\\quad \\beta_3 = 0.\n\\] On compare la qualité d’ajustement du modèle restreint et du modèle non restreint, puis la statistique \\(F\\) à une valeur tabulée de la loi \\(F\\) (selon les degrés de liberté).\n\n\n\n\n4.2 Exercice calculé (non scoré automatiquement)\nConsidère un estimateur \\(\\hat\\beta_1 = 0{,}8\\) avec \\(\\text{se}(\\hat\\beta_1) = 0{,}25\\) et un échantillon de taille \\(n = 120\\).\n\nCalcule la statistique \\(t\\) pour \\(H_0 : \\beta_1 = 0\\).\n\nDonne la règle de décision au seuil de 5 % (en utilisant la table de Student, avec \\(n-K\\) degrés de liberté).\n\nConstruis un intervalle de confiance à 95 % pour \\(\\beta_1\\) et interprète-le.\n\n\nFais ces calculs sur papier : c’est exactement le type de raisonnement de l’examen."
  },
  {
    "objectID": "Quizz.html#tests-dhypothèses-sur-les-erreurs-hétéroscédasticité-autocorrélation",
    "href": "Quizz.html#tests-dhypothèses-sur-les-erreurs-hétéroscédasticité-autocorrélation",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "5 5. Tests d’hypothèses sur les erreurs : hétéroscédasticité & autocorrélation",
    "text": "5 5. Tests d’hypothèses sur les erreurs : hétéroscédasticité & autocorrélation\n\n5.1 Q5 – Hétéroscédasticité\n\n\nQ5.1 – Hétéroscédasticité (définition)\n\n  Signifie que les erreurs ont une moyenne non nulle. \n  Signifie que la variance conditionnelle de l’erreur dépend des régressseurs. \n  Signifie que les erreurs sont corrélées dans le temps. \n  Signifie que les régressseurs sont corrélés entre eux. \n\n\nSolution et commentaire\n\nL’hétéroscédasticité correspond à : \\[\n\\text{Var}(u_i \\mid X_i) = \\sigma_i^2\n\\] qui varie avec \\(i\\) (et donc avec les régressseurs).\nElle rend les erreurs standards MCO classiques incorrectes, d’où l’usage d’erreurs standards robustes.\n\n\n\n\nQ5.2 – Tests pour l’hétéroscédasticité (plusieurs réponses)\n\nQuels tests sont classiquement utilisés pour détecter l’hétéroscédasticité des erreurs dans un modèle MCO ?\n  Test de Breusch–Pagan. \n  Test de White. \n  Test de Durbin–Watson. \n  Test de Jarque–Bera. \n  Inspection des résidus (nuage résidus vs prédits) comme indicateur visuel. \n\n\nSolution et commentaire\n\n\nBreusch–Pagan et White sont des tests standard pour l’hétéroscédasticité.\n\nDurbin–Watson teste l’autocorrélation des résidus (séries temporelles).\n\nJarque–Bera teste la normalité des résidus.\n\nLe graphique « résidus vs valeurs ajustées » peut aider à détecter des motifs de variance non constante.\n\n\n\n\n\nQ5.3 – Décision pour un test de type \\(\\chi^2\\) (Breusch–Pagan / White)\n\nOn effectue un test de Breusch–Pagan d’homoscédasticité. On obtient une statistique de test \\(BP = 7{,}2\\) avec 2 degrés de liberté.\nAu seuil de 5 %, la valeur tabulée de \\(\\chi^2_2\\) est environ \\(5{,}99\\).\n  On rejette l’hypothèse d’homoscédasticité car \\(7{,}2 &gt; 5{,}99\\). \n  On ne rejette pas l’hypothèse d’homoscédasticité car \\(7{,}2 &lt; 5{,}99\\). \n  On ne peut rien dire sans connaître le \\(R^2\\). \n  La statistique doit être comparée à une loi de Student, pas à une loi \\(\\chi^2\\). \n\n\nSolution et commentaire\n\nLes tests de Breusch–Pagan / White sont basés sur une statistique \\(\\chi^2\\).\nComme \\(BP = 7{,}2 &gt; 5{,}99\\), on rejette l’hypothèse d’homoscédasticité au seuil de 5 % et on conclut à la présence d’hétéroscédasticité.\nOn utilisera alors par exemple des erreurs standards robustes pour les tests sur les coefficients.\n\n\n\n\n5.2 Q6 – Autocorrélation\n\n\nQ5.4 – Autocorrélation des erreurs\n\n  Correspond au fait que les erreurs ont une variance non constante. \n  Correspond au fait que les erreurs sont corrélées dans le temps (par exemple \\(u_t\\) corrélé à \\(u_{t-1}\\)). \n  Correspond au fait que les régressseurs sont corrélés entre eux. \n  Ne peut se produire qu’en coupe transversale. \n\n\nSolution et commentaire\n\nL’autocorrélation (ou corrélation sérielle) est un problème typique des données de séries temporelles : les erreurs \\(u_t\\) sont corrélées entre périodes.\nLes MCO restent en général sans biais mais inefficients, et les erreurs standards classiques sont fausses.\n\n\n\n\nQ5.5 – Tests pour l’autocorrélation (plusieurs réponses)\n\n  Test de Durbin–Watson (autocorrélation d’ordre 1). \n  Test de Breusch–Godfrey (autocorrélation d’ordre supérieur). \n  Test de Breusch–Pagan. \n  Test de White. \n\n\nSolution et commentaire\n\n\nDurbin–Watson : test spécifique (principalement pour une autocorrélation d’ordre 1).\n\nBreusch–Godfrey : plus général, permet de tester plusieurs retards.\n\nBreusch–Pagan et White concernent l’hétéroscédasticité, pas l’autocorrélation.\n\n\n\n\n\nQ5.6 – Utiliser la table de Durbin–Watson (dL, dU)\n\nOn estime un modèle de régression sur une série temporelle, avec :\n\ntaille d’échantillon : (n = 50)\n\nnombre de régressseurs (constante incluse) : (k = 3)\n\nstatistique de Durbin–Watson observée : (DW = 1{,}20)\n\nPour un test au seuil de 5 % (bilatéral), la table de Durbin–Watson fournit, pour ces valeurs de (n) et (k) :\n\nborne inférieure : (d_L = 1{,}33)\n\nborne supérieure : (d_U = 1{,}65)\n\nOn rappelle que pour tester l’hypothèse d’absence d’autocorrélation positive des erreurs :\n\nsi (DW &lt; d_L) : on rejette (H_0) (on conclut à une autocorrélation positive) ;\n\nsi (d_L DW d_U) : zone d’indétermination ;\n\nsi (DW &gt; d_U) : on ne rejette pas (H_0).\n\nQuelle conclusion tirer ici ?\n  On rejette l’hypothèse d’absence d’autocorrélation positive, car (DW = 1{,}20 &lt; d_L = 1{,}33). \n  On est en zone d’indétermination, car (d_L DW d_U). \n  On ne rejette pas l’hypothèse d’absence d’autocorrélation positive, car (DW &gt; d_U). \n  On ne peut rien dire : la table de Durbin–Watson ne donne pas de bornes (d_L) et (d_U). \n\n\nSolution et commentaire\n\nIci, (DW = 1{,}20) et les bornes tabulées au seuil de 5 % sont (d_L = 1{,}33) et (d_U = 1{,}65).\nOn a (DW &lt; d_L), donc on est dans la zone où on rejette l’hypothèse d’absence d’autocorrélation positive des erreurs.\nOn conclut qu’il y a des indices d’autocorrélation positive.\nRappel de la règle (test d’autocorrélation positive) :\n\nsi (DW &lt; d_L) : rejet de (H_0 : ) ;\n\nsi (d_L DW d_U) : zone d’indétermination ;\n\nsi (DW &gt; d_U) : on ne rejette pas (H_0)."
  },
  {
    "objectID": "Quizz.html#endogénéité-variables-instrumentales-vi",
    "href": "Quizz.html#endogénéité-variables-instrumentales-vi",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "6 6. Endogénéité & variables instrumentales (VI)",
    "text": "6 6. Endogénéité & variables instrumentales (VI)\n\n6.1 Q7 – Idée générale\n\n\nQ6.1 – Endogénéité d’un régressseur\n\n  Signifie que la variable expliquée \\(Y\\) est binaire. \n  Signifie qu’un régressseur est corrélé avec le terme d’erreur \\(u\\). \n  Signifie que le \\(R^2\\) est faible. \n  Signifie que les erreurs sont hétéroscédastiques. \n\n\nSolution et commentaire\n\nL’endogénéité viole l’hypothèse clé \\(\\mathbb E[u_i \\mid X_i] = 0\\) (ou \\(\\text{Cov}(X,u)=0\\)).\nElle peut venir d’une variable omise, d’une causalité inverse, d’une erreur de mesure, etc.\nDans ce cas, les MCO sont en général biaisés et inconsistants.\n\n\n\n\nQ6.2 – Conditions pour un instrument valide (plusieurs réponses)\n\nOn souhaite instrumenter une variable endogène \\(x_i\\) à l’aide d’une variable \\(z_i\\). Quelles sont les deux grandes conditions pour que \\(z_i\\) soit un instrument valide ?\n  Pertinence : \\(\\text{Cov}(z_i, x_i) \\neq 0\\). \n  Normalité : \\(z_i\\) doit suivre une loi normale. \n  Exogénéité : \\(\\text{Cov}(z_i, u_i) = 0\\). \n  \\(z_i\\) doit être binaire (0/1). \n\n\nSolution et commentaire\n\nUn bon instrument doit être : 1. Pertinent : corrélé à la variable endogène \\(x_i\\). 2. Exogène (valide) : non corrélé au terme d’erreur \\(u_i\\).\nLa normalité ou le caractère binaire ne sont pas des conditions nécessaires.\n\n\n\n\nQ6.3 – Exact-identification et sur-identification\n\nOn note \\(K\\) le nombre de variables endogènes à instrumenter et \\(L\\) le nombre d’instruments disponibles (hors régressseurs exogènes).\nQuel cas correspond à un modèle sur-identifié ?\n  \\(L &lt; K\\). \n  \\(L = K\\). \n  \\(L &gt; K\\). \n  \\(L = 0\\). \n\n\nSolution et commentaire\n\n\n\\(L &lt; K\\) : modèle sous-identifié (pas assez d’instruments).\n\n\\(L = K\\) : exactement identifié.\n\n\\(L &gt; K\\) : sur-identifié : on a plus de conditions d’exogénéité que nécessaire, ce qui permet en principe de tester la validité globale des instruments (test de sur-identification type Sargan/Hansen).\n\n\n\n\n\n6.2 Cas « exogénéité de \\(x\\) » (question ouverte, non scorée)\nOn suspecte que la variable revenu est endogène dans une équation de demande. On propose d’utiliser comme instruments :\n\nrevenu_moyen_region (revenu moyen dans la région de résidence)\n\ndistance_travail (distance domicile–travail)\n\n\nDiscute si ces instruments sont plausiblement pertinents.\n\nDiscute si ces instruments sont plausiblement exogènes (peuvent-ils affecter la demande autrement que via revenu ?).\n\nPropose un exemple d’instrument qui serait clairement non valide."
  },
  {
    "objectID": "Quizz.html#mini-cas-examen-questions-ouvertes-non-scorées",
    "href": "Quizz.html#mini-cas-examen-questions-ouvertes-non-scorées",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "7 7. Mini-cas « examen » (questions ouvertes, non scorées)",
    "text": "7 7. Mini-cas « examen » (questions ouvertes, non scorées)\nCes questions imitent le style de l’épreuve finale : réponse rédigée + raisonnement.\n\n7.1 Cas 1 – Salaire et éducation\nOn estime le modèle \\[\n\\log(\\text{wage}_i) = \\beta_0 + \\beta_1 \\text{educ}_i + \\beta_2 \\text{exp}_i + u_i,\n\\] où wage est le salaire horaire, educ le nombre d’années d’étude et exp l’expérience professionnelle.\n\nComment interpréter le coefficient \\(\\beta_1\\) dans ce modèle semi-log ?\n\nPropose deux variables supplémentaires qu’il serait pertinent d’ajouter, et explique pourquoi.\n\nDonne un exemple de source possible d’endogénéité dans ce modèle (par rapport à educ). Quelle conséquence sur l’estimation de \\(\\beta_1\\) ?\n\n\nRéponds en quelques lignes comme tu le ferais à l’examen.\n\n\n\nVoir des éléments de réponse\n\n1. Interprétation de \\(\\beta_1\\) dans un modèle semi-log\n\nLe modèle est de type log-linéaire :\n\\[\\log(\\text{wage}) = \\beta_0 + \\beta_1 \\text{educ} + \\dots\\]\nUne augmentation d’une année d’éducation est associée à une variation approximative de \\(100 \\times \\beta_1\\) % du salaire horaire.\n\nPlus précisément, l’effet en pourcentage est \\(100 \\times (\\exp(\\beta_1) - 1)\\) %, mais pour des valeurs « raisonnables » de \\(\\beta_1\\) la différence est faible.\n\n2. Variables supplémentaires possibles\nExemples de variables pertinentes (au moins deux) :\n\nSecteur d’activité (industrie, services, public/privé) : les salaires sont très différents selon le secteur.\n\nRégion ou ville de résidence : le niveau de salaire dépend du marché du travail local et du coût de la vie.\n\nTaille de l’entreprise, type de contrat, genre, etc.\n\nIdée : ajouter des variables qui expliquent le salaire et qui sont corrélées à educ pour réduire le biais de variable omise.\n3. Source d’endogénéité sur educ\nExemples :\n\nCapacité innée / motivation : les individus plus capables ou plus motivés font plus d’études et gagnent plus, même à niveau d’étude égal.\n\nOrigine sociale / milieu familial : les familles favorisées financent plus d’études et offrent des réseaux professionnels.\n\nSi ces facteurs ne sont pas dans le modèle, ils se retrouvent dans l’erreur \\(u_i\\) et sont corrélés avec educ.\nConséquence : l’estimateur MCO de \\(\\beta_1\\) est biaisé et inconsistant (souvent biais vers le haut si les capacités non observées augmentent à la fois education et salaire).\n\n\n\n\n7.2 Cas 2 – Effet d’un programme de formation sur l’emploi\nUne politique publique propose une formation à certains chômeurs. On dispose d’une variable train_i (1 si l’individu a suivi la formation, 0 sinon) et d’une variable employ_i (1 si l’individu est en emploi 6 mois plus tard, 0 sinon). On estime : \\[\n\\text{employ}_i = \\gamma_0 + \\gamma_1 \\text{train}_i + \\gamma_2 \\text{age}_i + \\gamma_3 \\text{female}_i + v_i.\n\\]\n\nQue mesure \\(\\gamma_1\\) dans ce modèle linéaire avec variable dépendante binaire ?\n\nPourquoi l’estimation de \\(\\gamma_1\\) pourrait-elle être biaisée (donne au moins une raison) ?\n\nPropose une stratégie (même simple) pour réduire ce biais.\n\n\n\nVoir des éléments de réponse\n\n1. Interprétation de \\(\\gamma_1\\)\n\nemploy vaut 0 ou 1, on est dans un modèle de probabilité linéaire.\n\n\\(\\gamma_1\\) mesure l’effet moyen de la formation sur la probabilité d’être en emploi :\n&gt; suivre la formation augmente (en moyenne) la probabilité d’être en emploi de \\(\\gamma_1\\) points de pourcentage par rapport à ceux qui ne la suivent pas (à âge et sexe donnés).\n\n2. Pourquoi \\(\\gamma_1\\) peut être biaisé ?\nAu moins une raison :\n\nSélection des participants : les personnes les plus motivées ou les plus employables sont plus susceptibles de demander / obtenir la formation.\n\nLa formation n’est pas assignée de façon aléatoire : elle dépend d’un conseiller, de critères administratifs, etc.\n\nCes facteurs (motivation, employabilité, réseau, santé…) influencent aussi employ, donc train est corrélée avec l’erreur \\(v_i\\) → endogénéité.\n\n3. Stratégies pour réduire le biais\nIdées à citer (même si ce n’est pas parfait) :\n\nAjouter davantage de variables de contrôle : niveau d’éducation, expérience, historique d’emploi, etc.\n\nUtiliser un panel avant/après avec groupe de contrôle et faire une approche type différences-en-différences (si données sur plusieurs périodes).\n\nApproche expérimentale : assignation aléatoire des formations (RCT).\n\nApproche quasi-expérimentale : variable instrumentale qui influence la participation à la formation mais pas directement l’emploi (par exemple, distance au centre de formation, règles d’éligibilité… sous conditions).\n\n\n\n\n\n7.3 Cas 3 – Tests de significativité\nOn te fournit un tableau de résultats de régression MCO (comme dans les TD). Pour une variable X :\n\nCoefficient estimé \\(\\hat\\beta_X = 0{,}45\\)\n\nErreur standard robuste \\(\\text{se}(\\hat\\beta_X) = 0{,}18\\)\n\nTaille d’échantillon \\(n = 250\\)\n\n\nCalcule la statistique \\(t\\) et commente la significativité au seuil de 5 % (en utilisant la table de Student).\n\nExplique la différence entre significativité statistique (au sens des tests \\(t\\)) et importance économique.\n\nDonne un exemple de situation où un effet statistiquement faible peut être économiquement important.\n\n\n\nVoir des éléments de réponse\n\n1. Statistique \\(t\\) et significativité\nOn teste \\(H_0 : \\beta_X = 0\\) avec \\[\nt = \\frac{\\hat\\beta_X - 0}{\\text{se}(\\hat\\beta_X)}\n  = \\frac{0{,}45}{0{,}18}\n  = 2{,}5.\n\\]\n\nLes degrés de liberté sont environ \\(n - K \\approx 250 - K\\) (par ex. \\(\\approx 245\\)).\n\nAu seuil de 5 % (bilatéral), la valeur tabulée de Student est environ 2.\n\nComme \\(|t| = 2{,}5 &gt; 2\\), on rejette \\(H_0\\) au seuil de 5 % : le coefficient est statistiquement différent de 0.\n\n2. Significativité statistique vs importance économique\n\nSignificativité statistique : le test \\(t\\) indique si l’on peut rejeter \\(H_0 : \\beta_X = 0\\) en comparant \\(|t|\\) à la valeur tabulée de Student.\n\nElle dépend de la taille de l’effet mais aussi de la précision (erreur standard) et de la taille d’échantillon.\n\n\nImportance économique : taille pratique de l’effet.\n\nUn effet peut être statistiquement significatif mais très faible en magnitude → peu d’intérêt économique.\n\nÀ l’inverse, un effet peut être économiquement important mais mal mesuré (échantillon trop petit, mesure bruitée) → difficulté à obtenir un \\(t\\) élevé.\n\n\n3. Exemple d’effet statistiquement faible mais économiquement important\nExemples possibles :\n\nUne politique qui réduit la probabilité de chômage de 1 point de pourcentage.\n\nStatistiquement, c’est un petit effet (surtout si l’erreur standard est grande), mais pour un grand nombre d’individus, cela signifie beaucoup d’emplois supplémentaires.\n\n\nUne petite baisse du taux de mortalité due à une intervention de santé publique (ex.: vaccination) :\n\nL’effet individuel est faible, mais à l’échelle d’un pays, cela représente un grand nombre de vies sauvées.\n\n\nIdée à retenir : toujours combiner lecture des tests \\(t\\) et des valeurs tabulées avec une réflexion sur la taille de l’effet et le contexte économique."
  },
  {
    "objectID": "Quizz.html#mini-sondages-type-wooclap-pour-la-discussion-en-classe",
    "href": "Quizz.html#mini-sondages-type-wooclap-pour-la-discussion-en-classe",
    "title": "Quiz de révision – Introduction à l’économétrie (L3)",
    "section": "8 8. Mini-sondages « type Wooclap » (pour la discussion en classe)",
    "text": "8 8. Mini-sondages « type Wooclap » (pour la discussion en classe)\nCes questions n’ont pas de « bonne » réponse unique : elles servent à lancer le débat.\n\nPoll 1 – Quelle erreur te semble la plus grave dans une étude empirique ?\n\nA. Ne pas avoir un R² très élevé\n\nB. Ne pas vérifier les hypothèses du modèle (hétéroscédasticité, autocorrélation, endogénéité, etc.)\n\nC. Oublier de préciser ses sources de données\n\nD. Ne pas arrondir correctement les chiffres dans les tableaux\n\n\nEn groupe, justifiez votre choix : que se passe-t-il si on viole les hypothèses du modèle ? si les données ne sont pas bien documentées ?\n\n\n\nPoll 2 – Quand tu lis un résultat empirique, qu’est-ce que tu regardes en premier ?\n\nA. Le signe des coefficients\n\nB. La taille (magnitude) des effets\n\nC. Les statistiques t et la comparaison avec les valeurs tabulées\n\nD. L’échantillon, les variables, la stratégie d’identification\n\n\nDiscutez : comment hiérarchiser ces éléments pour juger de la crédibilité d’un résultat ?\n\n\n\n\n\nCorriger le quiz\n\n\nRéinitialiser\n\n\n\nScore non calculé."
  },
  {
    "objectID": "slides/global-slides.html",
    "href": "slides/global-slides.html",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD1 : EViews & préparation\nTD2: Gestion de bases de données & analyse statistique\nTD3 : MCO & lecture des sorties\nTD4 : Homoscédasticité (GQ, BP, White)\nTD5 : Auto-corrélation (DW, BG), CO, COMFAC\nTD6 : Endogénéité & 2SLS (Nakamura&Nakamura)\nTD7 : IV avancé (MROZ), Sargan, White\nTD8 : Normalité (Jarque–Bera), stabilité\nTD9 : Simulation de Monte Carlo\n\n\n\n\n\nTD1 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\nTD2 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\nTD3 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\n\nTD4 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\n\nTD5 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\n\nTD6 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\nTD7 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\nTD8 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\n\nTD9 →     View slides in full screen\n       \n      \n    \n  \n\n\n\n\n\nRaccourcis Reveal.js :\n- F : plein écran\n- S : notes orateur\n- Esc : vue mosaïque"
  },
  {
    "objectID": "slides/global-slides.html#td-1",
    "href": "slides/global-slides.html#td-1",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD1 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-2",
    "href": "slides/global-slides.html#td-2",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD2 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-3",
    "href": "slides/global-slides.html#td-3",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD3 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-4",
    "href": "slides/global-slides.html#td-4",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD4 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-5",
    "href": "slides/global-slides.html#td-5",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD5 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-6",
    "href": "slides/global-slides.html#td-6",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD6 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-7",
    "href": "slides/global-slides.html#td-7",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD7 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-8",
    "href": "slides/global-slides.html#td-8",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD8 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#td-9",
    "href": "slides/global-slides.html#td-9",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "TD9 →     View slides in full screen"
  },
  {
    "objectID": "slides/global-slides.html#astuce-projection",
    "href": "slides/global-slides.html#astuce-projection",
    "title": "Présentation globale — TD1→TD8",
    "section": "",
    "text": "Raccourcis Reveal.js :\n- F : plein écran\n- S : notes orateur\n- Esc : vue mosaïque"
  },
  {
    "objectID": "td9/td9.html",
    "href": "td9/td9.html",
    "title": "Économétrie — TD 9",
    "section": "",
    "text": "Code\nlibrary(knitr)\nknit_hooks$set(optipng = hook_optipng)"
  },
  {
    "objectID": "td9/td9.html#origines-de-la-méthode",
    "href": "td9/td9.html#origines-de-la-méthode",
    "title": "Économétrie — TD 9",
    "section": "1.1 1.1 Origines de la méthode",
    "text": "1.1 1.1 Origines de la méthode\n\n« The Monte Carlo method … is an invention of statistical sampling for the solution of mathematical problems for which direct methods are not feasible. » @metropolis1949.\n\n\nLe nom Monte Carlo fait référence au casino de Monaco, symbole du hasard.\nMise en œuvre pour la première fois dans les années 1940, durant le projet Manhattan en physique nucléaire.\nObjectif initial : approximer des intégrales complexes ou des probabilités impossibles à calculer analytiquement.\n\nArticle original Metropolis & Ulam (1949)"
  },
  {
    "objectID": "td9/td9.html#idée-en-économétrie",
    "href": "td9/td9.html#idée-en-économétrie",
    "title": "Économétrie — TD 9",
    "section": "1.2 1.2 Idée en économétrie",
    "text": "1.2 1.2 Idée en économétrie\nUne simulation de Monte Carlo est une expérience de pensée codée sur ordinateur :\n\nSpécifier un modèle théorique connu (par exemple une régression linéaire).\nFixer les « vrais » paramètres et la distribution de l’erreur (normale, χ², etc.).\nGénérer artificiellement de nombreux échantillons de données.\nEstimer sur chacun de ces échantillons le même modèle que l’on veut étudier.\nObserver empiriquement la distribution des estimateurs : biais, variance, forme, robustesse des tests.\n\n\n\n\n\n\n\nTip\n\n\n\nLa simulation de Monte Carlo agit comme un laboratoire virtuel : elle permet de vérifier et d’illustrer les propriétés théoriques des estimateurs quand la démonstration analytique est complexe ou quand on veut observer leur comportement “en pratique”."
  },
  {
    "objectID": "td9/td9.html#étapes-générales-dune-simulation",
    "href": "td9/td9.html#étapes-générales-dune-simulation",
    "title": "Économétrie — TD 9",
    "section": "2.1 2.1 Étapes générales d’une simulation",
    "text": "2.1 2.1 Étapes générales d’une simulation\n\nFixer la taille d’échantillon \\(n\\) et le nombre de répliques \\(R\\).\nDéfinir le modèle :\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i\n\\] avec par exemple \\(\\varepsilon_i \\sim \\mathcal{N}(0,1)\\).\nPour chaque réplication \\(r = 1,\\dots,R\\) :\n\nGénérer les \\(x_i\\) et les erreurs \\(\\varepsilon_i\\).\nCalculer \\(y_i\\).\nEstimer \\((\\hat\\alpha_r,\\hat\\beta_r)\\) par MCO.\n\nAnalyser la distribution empirique des \\(\\hat\\beta_r\\) : moyenne, variance, skewness, kurtosis, comparaison à la valeur vraie \\(\\beta\\)."
  },
  {
    "objectID": "td9/td9.html#commandes-eviews-utiles",
    "href": "td9/td9.html#commandes-eviews-utiles",
    "title": "Économétrie — TD 9",
    "section": "2.2 2.2 Commandes EViews utiles",
    "text": "2.2 2.2 Commandes EViews utiles\n\n\n\n\n\n\n\nAction\nCommande\n\n\n\n\nGénérer une normale centrée réduite\nseries e = nrnd\n\n\nGénérer une loi χ²(v)\nseries e = @rchisq(v)\n\n\nCréer une variable simulée\nseries y1 = 7 + 0.4*lsize + 0.8*bed + 0.2*bath + 0.2*airco + e\n\n\nEstimer par MCO\nls y1 c lsize bed bath airco\n\n\nLancer un programme\nrun Montecarlo.prg"
  },
  {
    "objectID": "td9/td9.html#q1-générer-y1-et-estimer",
    "href": "td9/td9.html#q1-générer-y1-et-estimer",
    "title": "Économétrie — TD 9",
    "section": "4.1 Q1 — Générer y1 et estimer",
    "text": "4.1 Q1 — Générer y1 et estimer\n\nEn supposant $\\varepsilon \\sim \\mathcal{N}(0,1)$, générez une série y1 et estimezl’équation par MCO.\n\n\n\nAfficher la réponse\n\nEViews :\nseries e = nrnd\nseries y1 = 7 + 0.4*lsize + 0.8*bed + 0.2*bath + 0.2*airco + e\nls y1 c lsize bed bath airco\nLes coefficients estimés doivent être proches des valeurs vraies (0.4, 0.8, 0.2, 0.2) avec de légères fluctuations aléatoires."
  },
  {
    "objectID": "td9/td9.html#q2-répéter-y2y5",
    "href": "td9/td9.html#q2-répéter-y2y5",
    "title": "Économétrie — TD 9",
    "section": "4.2 Q2 — Répéter y2…y5",
    "text": "4.2 Q2 — Répéter y2…y5\n\nRefaire la Q1 pour y2 à y5, même modèle, nouvelles erreurs.\n\n\n\nAfficher la réponse\n\nMême démarche en changeant le nom de la série (y2, y3 …). Comparer les \\(\\hat\\beta\\) obtenus : on doit observer une dispersion autour des valeurs vraies, illustrant la variabilité d’échantillonnage."
  },
  {
    "objectID": "td9/td9.html#q3-programme-monte-carlo",
    "href": "td9/td9.html#q3-programme-monte-carlo",
    "title": "Économétrie — TD 9",
    "section": "4.3 Q3 — Programme Monte Carlo",
    "text": "4.3 Q3 — Programme Monte Carlo\n\nOuvrez Montecarlo.prg, exécutez-le. Les coefficients sont enregistrés dans la matrice resultat. Faites un histogramme et calculez moyenne, variance, skewness, kurtosis.\n\n\n\nAfficher la réponse\n\nrun Montecarlo.prg\nPuis View → Descriptive Statistics → Histogram & Stats sur chaque colonne de resultat.\nLes estimateurs doivent avoir :\n\nune moyenne proche du vrai paramètre (absence de biais),\nune variance reflétant la précision,\nskewness ≈ 0 et kurtosis ≈ 3 si les erreurs sont normales."
  },
  {
    "objectID": "td9/td9.html#q4-1000-itérations",
    "href": "td9/td9.html#q4-1000-itérations",
    "title": "Économétrie — TD 9",
    "section": "4.4 Q4 — 1000 itérations",
    "text": "4.4 Q4 — 1000 itérations\n\nAppliquer la même procédure avec 1000 itérations.\n\n\n\nAfficher la réponse\n\nDans Montecarlo.prg, modifier :\n!nbiter = 1000\net exécuter.\nLa moyenne des \\(\\hat\\beta\\) se rapproche encore plus de la valeur vraie,\net la variance estimée se stabilise — illustration de la loi des grands nombres."
  },
  {
    "objectID": "td9/td9.html#q5-variance-derreur-différente",
    "href": "td9/td9.html#q5-variance-derreur-différente",
    "title": "Économétrie — TD 9",
    "section": "4.5 Q5 — Variance d’erreur différente",
    "text": "4.5 Q5 — Variance d’erreur différente\n\nRefaire 1–4 en supposant \\(\\varepsilon \\sim \\mathcal{N}(0,0.625)\\), 1000 puis 5000 simulations.\n\n\n\nAfficher la réponse\n\nseries e = sqrt(0.625)*nrnd\nUne variance d’erreur plus faible ⇒ des estimateurs plus précis (variance plus faible).\nAvec 5000 simulations, l’évaluation des moments (moyenne, variance, skewness, kurtosis) devient plus stable."
  },
  {
    "objectID": "td9/td9.html#q6-erreurs-non-normales",
    "href": "td9/td9.html#q6-erreurs-non-normales",
    "title": "Économétrie — TD 9",
    "section": "4.6 Q6 — Erreurs non normales",
    "text": "4.6 Q6 — Erreurs non normales\n\nRefaire 1–4 avec \\(\\varepsilon \\sim \\chi^2(7)\\), 1000 puis 5000 simulations.\n\n\n\nAfficher la réponse\n\nseries e = @rchisq(7)\nLa distribution est asymétrique (skewness &gt; 0). Les MCO restent asymptotiquement sans biais, mais les tests t/F, fondés sur la normalité, peuvent avoir un risque de première espèce mal calibré.\n⇒ Utiliser des erreurs-types robustes (White, HAC) ou des tests non paramétriques pour l’inférence."
  },
  {
    "objectID": "td8/td8.html",
    "href": "td8/td8.html",
    "title": "Économétrie — TD 8",
    "section": "",
    "text": "À quoi sert la normalité ?\nSi les résidus ne sont pas normaux, les statistiques classiques (t, F) ne suivent plus exactement les lois théoriques de référence. Le niveau nominal du test — par exemple 5 % — n’est alors plus garanti : la probabilité réelle de rejeter à tort l’hypothèse nulle (erreur de première espèce) peut être plus élevée que 5 %. En d’autres termes, on croit contrôler le risque de faux positif, mais il est en réalité mal calibré : on peut conclure qu’un coefficient est « significatif » alors que ce n’est qu’un artefact de la distribution anormale des erreurs. C’est précisément pour éviter ce gonflement du risque de première espèce que l’on vérifie la normalité ou, à défaut, qu’on emploie des méthodes d’inférence robustes"
  },
  {
    "objectID": "td8/td8.html#intuition-visuelle",
    "href": "td8/td8.html#intuition-visuelle",
    "title": "Économétrie — TD 8",
    "section": "2.1 Intuition visuelle",
    "text": "2.1 Intuition visuelle\n\n\\(\\eta\\neq 0\\) : distribution asymétrique (queue plus longue d’un côté).\n\\(\\nu&gt;3\\) : queues épaisses (beaucoup d’outliers) ; \\(\\nu&lt;3\\) : aplatie."
  },
  {
    "objectID": "td8/td8.html#plusieurs-cas-régression-simulés",
    "href": "td8/td8.html#plusieurs-cas-régression-simulés",
    "title": "Économétrie — TD 8",
    "section": "3.1 Plusieurs cas « régression » simulés",
    "text": "3.1 Plusieurs cas « régression » simulés\n\n\n\n\n\n\n\n\nFigure 2: Points simulés : vert = normalité non rejetée (5%), rouge = rejet."
  },
  {
    "objectID": "td8/td8-correction.html",
    "href": "td8/td8-correction.html",
    "title": "TD 8 — Correction & rappels (examen)",
    "section": "",
    "text": "Instrumentation : QTCACAO = γ₀ + γ₁ Z + γ₂ PETROLE + γ₃ OCDE + v.\n\nPertinence : significativité de Z en 1ère étape (t ou F).\n\n2SLS : interpréter coefficients et SE robustes si hétéroscédasticité.\n\nSargan (χ²(k−p)) : pour S = 2.38 et df = 2 ⇒ non‑rejet de l’exogénéité des instruments à 5%."
  },
  {
    "objectID": "td8/td8-correction.html#a-offre-de-cacao-iv",
    "href": "td8/td8-correction.html#a-offre-de-cacao-iv",
    "title": "TD 8 — Correction & rappels (examen)",
    "section": "",
    "text": "Instrumentation : QTCACAO = γ₀ + γ₁ Z + γ₂ PETROLE + γ₃ OCDE + v.\n\nPertinence : significativité de Z en 1ère étape (t ou F).\n\n2SLS : interpréter coefficients et SE robustes si hétéroscédasticité.\n\nSargan (χ²(k−p)) : pour S = 2.38 et df = 2 ⇒ non‑rejet de l’exogénéité des instruments à 5%."
  },
  {
    "objectID": "td8/td8-correction.html#b-demande-de-cigarettes-white",
    "href": "td8/td8-correction.html#b-demande-de-cigarettes-white",
    "title": "TD 8 — Correction & rappels (examen)",
    "section": "B) Demande de cigarettes — White",
    "text": "B) Demande de cigarettes — White\n\nConséquences de l’hétéroscédasticité : SE biaisés, tests t/F invalides (coefficients MCO restent sans biais mais inefficients).\n\nWhite : W = N·R² ; avec R² = 0.064 et N ≈ 807, W ≈ 51.6 → hétéroscédasticité.\n\nCorrection de White : comparer les écarts‑types et la significativité (prix devient significatif)."
  },
  {
    "objectID": "td8/td8-correction.html#remarques-générales",
    "href": "td8/td8-correction.html#remarques-générales",
    "title": "TD 8 — Correction & rappels (examen)",
    "section": "Remarques générales",
    "text": "Remarques générales\n\nToujours documenter l’identification (sources d’endogénéité, sens du biais, choix des instruments).\n\nPrivilégier tableaux de decision clairs (seuils 1/5/10%)."
  },
  {
    "objectID": "td7/td7-slides.html#notation-vi-forme-matricielle",
    "href": "td7/td7-slides.html#notation-vi-forme-matricielle",
    "title": "Économétrie — TD 7",
    "section": "2.1 Notation VI (forme matricielle)",
    "text": "2.1 Notation VI (forme matricielle)\n\nOn empile les données :\n\n\\(y\\) : vecteur \\((n\\times 1)\\)\n\\(X\\) : matrice \\((n\\times K)\\) des régresseurs (dont certains endogènes)\n\\(W\\) : régresseurs exogènes (optionnels)\n\\(Z\\) : matrice \\((n\\times L)\\) des instruments (et exogènes)\n\nConditions clés :\n\\[\nE[Z'u] = 0 \\quad\\text{(validité des instruments)}\n\\]\n\\[\n\\operatorname{rang}(E[Z'X]) = K \\quad\\text{(pertinence + identification)}\n\\]"
  },
  {
    "objectID": "td7/td7-slides.html#identification-exactement-vs-sur-identifié",
    "href": "td7/td7-slides.html#identification-exactement-vs-sur-identifié",
    "title": "Économétrie — TD 7",
    "section": "2.2 Identification : exactement vs sur-identifié",
    "text": "2.2 Identification : exactement vs sur-identifié\n\n\\(K\\) : nombre de variables endogènes à instrumenter\n\\(L\\) : nombre d’instruments (exogènes distincts)\n\nCas possibles :\n\nSous-identifié : \\(L &lt; K\\)\n⟶ pas assez d’instruments, le modèle n’est pas identifié\nExactement identifié : \\(L = K\\)\n⟶ autant d’instruments que de variables endogènes\nSur-identifié : \\(L &gt; K\\)\n⟶ plus d’instruments que nécessaire\n⟶ on dispose d’information supplémentaire sur les conditions d’orthogonalité \\(E[Z'u]=0\\)"
  },
  {
    "objectID": "td7/td7-slides.html#idée-de-la-sur-identification",
    "href": "td7/td7-slides.html#idée-de-la-sur-identification",
    "title": "Économétrie — TD 7",
    "section": "2.3 Idée de la sur-identification",
    "text": "2.3 Idée de la sur-identification\n\nQuand \\(L &gt; K\\), plusieurs “combinaisons” d’instruments pourraient identifier \\(\\beta\\).\nSi tous les instruments sont valides, toutes ces manières d’identifier \\(\\beta\\) devraient donner la même vraie valeur.\nIntuition :\n\nLes conditions d’exogénéité imposées par les instruments supplémentaires sont des restrictions supplémentaires sur le modèle.\n\nOn peut alors tester si ces restrictions supplémentaires sont compatibles avec les données.\n\n⟶ C’est l’objet du test de sur-identification de Sargan."
  },
  {
    "objectID": "td7/td7-slides.html#idée-informelle-du-test-de-sargan",
    "href": "td7/td7-slides.html#idée-informelle-du-test-de-sargan",
    "title": "Économétrie — TD 7",
    "section": "2.4 Idée informelle du test de Sargan",
    "text": "2.4 Idée informelle du test de Sargan\n\nOn estime le modèle par VI (2SLS) et on obtient les résidus :\n\\[\n\\hat{u}_i = y_i - \\hat{y}_i\n\\]\nSi les instruments sont vraiment exogènes, on doit avoir :\n\\[\nE[z_{ji} \\hat{u}_i] = 0 \\quad \\text{pour tous les instruments } j\n\\]\nLe test de Sargan vérifie donc dans les données si les résidus \\(\\hat{u}_i\\) sont “orthogonaux” aux instruments \\(Z\\).\nIdée pratique : si on peut expliquer les résidus par les instruments, alors ces derniers sont probablement corrélés aux erreurs, donc invalides."
  },
  {
    "objectID": "td7/td7-slides.html#construction-de-la-statistique-de-sargan-cas-homoscédastique",
    "href": "td7/td7-slides.html#construction-de-la-statistique-de-sargan-cas-homoscédastique",
    "title": "Économétrie — TD 7",
    "section": "2.5 Construction de la statistique de Sargan (cas homoscédastique)",
    "text": "2.5 Construction de la statistique de Sargan (cas homoscédastique)\nSupposons que l’on a estimé le modèle par 2SLS :\n\\[\ny = X\\hat{\\beta}_{2SLS} + \\hat{u}\n\\]\nÉtapes :\n\nÉtape 1 : estimer le modèle VI (2SLS) et récupérer les résidus \\(\\hat{u}\\).\nÉtape 2 : régresser \\(\\hat{u}\\) sur tous les instruments \\(Z\\) (et en pratique aussi les exogènes inclus dans \\(X\\)) :\n\\[\n\\hat{u}_i = \\delta_0 + Z_i'\\delta + v_i\n\\]\nÉtape 3 : récupérer le \\(R^2\\) de cette régression, noter \\(R^2_{\\hat{u}\\sim Z}\\).\nStatistique de Sargan :\n\\[\nJ = n \\times R^2_{\\hat{u}\\sim Z}\n\\]\noù \\(n\\) est la taille de l’échantillon."
  },
  {
    "objectID": "td7/td7-slides.html#loi-asymptotique-de-la-statistique",
    "href": "td7/td7-slides.html#loi-asymptotique-de-la-statistique",
    "title": "Économétrie — TD 7",
    "section": "2.6 Loi asymptotique de la statistique",
    "text": "2.6 Loi asymptotique de la statistique\nSous les hypothèses suivantes :\n\ninstruments valides : \\(E[Z'u]=0\\)\nhomoscédasticité des erreurs\nspécification correcte\n\nalors, sous \\(H_0\\) (tous les instruments sont valides) :\n\\[\nJ \\overset{a}{\\sim} \\chi^2_{L-K}\n\\]\n\n\\(L-K\\) : nombre de restrictions sur-identifiantes\n\n\\(L\\) : nb d’instruments\n\\(K\\) : nb de variables endogènes instrumentées\n\nOn peut alors calculer une p-value à partir de la loi \\(\\chi^2_{L-K}\\)."
  },
  {
    "objectID": "td7/td7-slides.html#hypothèses-du-test-de-sargan",
    "href": "td7/td7-slides.html#hypothèses-du-test-de-sargan",
    "title": "Économétrie — TD 7",
    "section": "2.7 Hypothèses du test de Sargan",
    "text": "2.7 Hypothèses du test de Sargan\n\nHypothèse nulle \\(H_0\\) : tous les instruments sont exogènes\n\\(\\Rightarrow E[Z'u] = 0\\)\nHypothèse alternative \\(H_1\\) : au moins un instrument est invalidé\n(corrélé aux erreurs, mauvaise spécification, etc.)\nAttention : le test repose sur plusieurs hypothèses :\n\nhomoscédasticité des erreurs \\(u_i\\)\nforme fonctionnelle correcte du modèle\naucune erreur de mesure “catastrophique” dans les variables, etc."
  },
  {
    "objectID": "td7/td7-slides.html#interprétation-du-test",
    "href": "td7/td7-slides.html#interprétation-du-test",
    "title": "Économétrie — TD 7",
    "section": "2.8 Interprétation du test",
    "text": "2.8 Interprétation du test\n\nOn calcule \\(J = nR^2\\) et la p-value associée à \\(\\chi^2_{L-K}\\).\np-value élevée (par ex. &gt; 5%) :\n\nOn ne rejette pas \\(H_0\\).\nOn ne trouve pas de preuve contre la validité globale des instruments.\n⟶ “Les instruments sont globalement compatibles avec les hypothèses d’exogénéité.”\n\np-value faible (par ex. &lt; 5%) :\n\nOn rejette \\(H_0\\).\nAu moins un des instruments est probablement corrélé à \\(u_i\\).\n⟶ “Les instruments ne sont pas tous valides.”\n\n\n⚠️ Le test ne dit pas quel instrument est invalide, uniquement s’il y a un problème global."
  },
  {
    "objectID": "td7/td7-slides.html#sargan-vs-hansen-j-test-robuste",
    "href": "td7/td7-slides.html#sargan-vs-hansen-j-test-robuste",
    "title": "Économétrie — TD 7",
    "section": "2.9 Sargan vs Hansen (J-test robuste)",
    "text": "2.9 Sargan vs Hansen (J-test robuste)\n\nLa statistique de Sargan est valable uniquement sous homoscédasticité.\nEn présence d’hétéroscédasticité (très fréquente en données micro ou panel), on utilise la version robuste :\n\nTest de Hansen J (ou Sargan-Hansen), issu du cadre GMM.\nMême logique : test de sur-identification avec loi \\(\\chi^2_{L-K}\\).\nMais construit avec une matrice de pondération robuste à l’hétéroscédasticité.\n\n\nEn pratique :\n\nSargan : 2SLS classique + hypothèse d’homoscédasticité.\nHansen J : IV-GMM (ou 2SLS “robuste”) + hétéroscédasticité possible."
  },
  {
    "objectID": "td7/td7-slides.html#exemple-de-sortie-interprétation-en-mots",
    "href": "td7/td7-slides.html#exemple-de-sortie-interprétation-en-mots",
    "title": "Économétrie — TD 7",
    "section": "3.1 Exemple de sortie (interprétation en mots)",
    "text": "3.1 Exemple de sortie (interprétation en mots)\nImaginons que l’on obtienne :\n\n\\(J = 3{,}2\\)\nddl = \\(L-K = 1\\)\nValeur de la table à 5% = \\(3,841\\)\n\nInterprétation :\n\nA 5% : \\(3,841&gt;J\\) ⟶ on ne rejette pas \\(H_0\\).\nOn ne trouve pas de preuve que les instruments sont globalement invalides.\n\nSi au contraire :\n\n\\(J = 7{,}9\\), ddl = 1, \\(J&gt;3,841\\)\n\nalors :\n\n⟶ on rejette \\(H_0\\).\nProbablement un problème d’exogénéité d’un (ou plusieurs) instrument(s)."
  },
  {
    "objectID": "td7/td7-slides.html#limites-et-mises-en-garde",
    "href": "td7/td7-slides.html#limites-et-mises-en-garde",
    "title": "Économétrie — TD 7",
    "section": "3.2 Limites et mises en garde",
    "text": "3.2 Limites et mises en garde\n\nLe test de Sargan ne teste pas :\n\nla pertinence des instruments (corrélation avec \\(x\\))\nla spécification complète du modèle structurel\n\nIl peut rejeter \\(H_0\\) non pas parce qu’un instrument est “mauvais”, mais parce que :\n\nle modèle est mal spécifié (omission d’une variable importante, non-linéarité, etc.)\nl’homoscédasticité est violée (dans ce cas, préférer Hansen J)\n\nNe pas interpréter “non rejet de \\(H_0\\)” comme une preuve que les instruments sont parfaits : c’est seulement “on ne détecte pas d’invalidité”."
  },
  {
    "objectID": "td7/td7-slides.html#lien-avec-les-conditions-dorthogonalité",
    "href": "td7/td7-slides.html#lien-avec-les-conditions-dorthogonalité",
    "title": "Économétrie — TD 7",
    "section": "3.3 Lien avec les conditions d’orthogonalité",
    "text": "3.3 Lien avec les conditions d’orthogonalité\nRappel :\n\nConditions d’exogénéité VI : \\(E[Z'u]=0\\)\nDans un modèle sur-identifié, on a plus de conditions que nécessaire pour identifier \\(\\beta\\).\n\nLe test de Sargan :\n\nteste si ces conditions supplémentaires sont consistantes entre elles,\nen utilisant les résidus \\(\\hat{u}\\) comme approximation de \\(u\\).\n\nInterprétation en termes de moments :\n\nOn veut que les “moments résiduels” \\(\\frac{1}{n}Z'\\hat{u}\\) soient “proches de 0”.\nSargan combine ces moments en une statistique quadratique (type GMM) qui suit approximativement une loi \\(\\chi^2\\) sous \\(H_0\\)."
  },
  {
    "objectID": "td6/td6.html",
    "href": "td6/td6.html",
    "title": "Économétrie — TD 6",
    "section": "",
    "text": "Ce polycopié reprend les notions des slides (TD 6) et les développe avec des explications, exemples simulés et schémas produits en R. Objectifs:\n1) Rappeler les hypothèses MCO et la notion d’exogénéité;\n2) Identifier trois sources d’endogénéité (omission, causalité inverse, erreur de mesure);\n3) Introduire la méthode des variables instrumentales (2SLS/DMC), les tests (faiblesse, Sargan/Hansen, DWH) et l’implémentation EViews.\n\n\n\n\n\n\nNote\n\n\n\nNotation. On note \\(Y\\) la variable expliquée, \\(X\\) la(les) variable(s) potentiellement endogène(s), \\(Z\\) l’instrument (ou le vecteur d’instruments), \\(W\\) les contrôles exogènes, et \\(u\\)/\\(\\\\varepsilon\\) l’erreur."
  },
  {
    "objectID": "td6/td6.html#omission-dune-variable-pertinente",
    "href": "td6/td6.html#omission-dune-variable-pertinente",
    "title": "Économétrie — TD 6",
    "section": "3.1 Omission d’une variable pertinente",
    "text": "3.1 Omission d’une variable pertinente\nVrai modèle \\(Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+u\\), mais on omet \\(X_2\\) et on estime \\(Y=\\beta_0+\\beta_1 X_1+u\\). Si \\(X_1\\) est corrélé avec \\(X_2\\), alors \\(\\mathrm{Cov}(X_1,u)\\neq 0\\) et \\(\\hat\\beta_1^{OLS}\\) est biaisé.\n\n\n# A tibble: 3 × 7\n# Groups:   group [3]\n  group         term  estimate std.error statistic  p.value where \n  &lt;chr&gt;         &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; \n1 A (faible X2) x        0.852    0.0323     26.4  4.32e-85 within\n2 B (fort X2)   x        0.829    0.0282     29.4  3.61e-96 within\n3 Pooled        x       -0.129    0.0340     -3.79 1.66e- 4 pooled\n\n\n\n\n\n\n\n\nFigure 2: Omission d’une variable: régressions séparées par un facteur latent → pente OLS “moyenne” biaisée.\n\n\n\n\n\nSens du biais (mémo) :\n\n\n\n\n\n\n\n\n\n\\(\\mathrm{corr}(X_1,X_2)&gt;0\\)\n\\(\\mathrm{corr}(X_1,X_2)&lt;0\\)\n\n\n\n\n\\(\\beta_2&gt;0\\)\nbiais positif\nbiais négatif\n\n\n\\(\\beta_2&lt;0\\)\nbiais négatif\nbiais positif"
  },
  {
    "objectID": "td6/td6.html#causalité-inverse",
    "href": "td6/td6.html#causalité-inverse",
    "title": "Économétrie — TD 6",
    "section": "3.2 Causalité inverse",
    "text": "3.2 Causalité inverse\nBoucle de rétroaction : \\(Y\\to X\\) et \\(X\\to Y\\).\nEx. dette publique ↔︎ croissance.\n\n\n\n\nCausalité inverse générique X ↔︎ Y avec exemples économiques\n\n\nEffet sur \\(\\hat\\beta_1^{OLS}\\) : il « récupère » une partie du retour \\(Y\\to X\\)."
  },
  {
    "objectID": "td6/td6.html#erreur-de-mesure-sur-x",
    "href": "td6/td6.html#erreur-de-mesure-sur-x",
    "title": "Économétrie — TD 6",
    "section": "3.3 Erreur de mesure sur \\(X\\)",
    "text": "3.3 Erreur de mesure sur \\(X\\)\nOn observe \\(\\tilde X = X + \\nu\\). L’OLS de \\(Y\\sim \\tilde X\\) subit un biais d’atténuation (vers 0).\n\n\n\n\n\n\n\n\nFigure 3: Erreur de mesure sur X : la pente OLS avec Xbruité est plus faible (biais d’atténuation)."
  },
  {
    "objectID": "td6/td6.html#principe",
    "href": "td6/td6.html#principe",
    "title": "Économétrie — TD 6",
    "section": "4.1 Principe",
    "text": "4.1 Principe\nBut : utiliser un instrument \\(Z\\) pour isoler la variation exogène de \\(X\\).\n\nPertinence : \\(\\mathrm{Cov}(Z,X)\\neq 0\\) (1ʳᵉ étape explicative).\nExogénéité exclue : \\(\\mathrm{Cov}(Z,u)=0\\) (Z n’affecte Y que via X).\n\nProcédure 2SLS :\n1) \\(X = \\pi_0 + \\pi_1 Z + W'\\pi + v\\) → obtenir \\(\\hat X\\) ;\n2) \\(Y = \\beta_0 + \\beta_1 \\hat X + W'\\gamma + u\\).\n\n\n\n\n\n\n\n\nFigure 4: Causalité inverse : X → Y et Y → X. Z est un instrument valide s’il n’affecte Y que via X.\n\n\n\n\nLecture attendue : \\(\\hat\\beta^{OLS}\\) sur \\(X\\) est biaisé (ici vers le haut, car \\(X\\) corrélé à \\(u\\)). L’estimateur 2SLS se rapproche de la vraie valeur (\\(1{.}5\\)) si \\(Z\\) est suffisamment pertinent et valide."
  },
  {
    "objectID": "td6/td6.html#instruments-faibles-pertinence",
    "href": "td6/td6.html#instruments-faibles-pertinence",
    "title": "Économétrie — TD 6",
    "section": "4.2 Instruments faibles (pertinence)",
    "text": "4.2 Instruments faibles (pertinence)\nOn regarde le F de 1ʳᵉ étape (régression de \\(X\\) sur \\(Z\\) et \\(W\\)) ; règle pratique usuelle : \\(F&gt;10\\)."
  },
  {
    "objectID": "td6/td6.html#validité-de-linstrument-exogénéité",
    "href": "td6/td6.html#validité-de-linstrument-exogénéité",
    "title": "Économétrie — TD 6",
    "section": "4.3 Validité de l’instrument (exogénéité)",
    "text": "4.3 Validité de l’instrument (exogénéité)\nSi l’on dispose de plus d’instruments que de variables endogènes (sur‑id), on peut tester l’orthogonalité (Sargan/Hansen‑J).\n\n\n\n\n\n\nCaution\n\n\n\nRappel : ces tests ne remplacent jamais l’argument économique."
  },
  {
    "objectID": "td6/td6.html#q1-charger-le-workfile",
    "href": "td6/td6.html#q1-charger-le-workfile",
    "title": "Économétrie — TD 6",
    "section": "8.1 Q1 — Charger le workfile",
    "text": "8.1 Q1 — Charger le workfile\n\nChargez le workfile Marshall (contient offre1–offre4, p1–p4, Y, W).\n\n\n\nAfficher la réponse\n\nEViews. File → Open → Workfile puis sélectionnez Marshall.wf*.\nVérifiez les séries (aperçu, stats descriptives : View → Descriptive Statistics)."
  },
  {
    "objectID": "td6/td6.html#q2-estimations-mco",
    "href": "td6/td6.html#q2-estimations-mco",
    "title": "Économétrie — TD 6",
    "section": "8.2 Q2 — Estimations MCO",
    "text": "8.2 Q2 — Estimations MCO\n\nEstimez offre1 = c + β p1, offre2 = c + β p2, offre3 = c + β p3 et\noffre4 = c + β p4 + π W (avec W exogène).\n\n\n\nAfficher la réponse\n\nQuick → Estimate Equation puis entrez :\noffre1 c p1 ; offre2 c p2 ; offre3 c p3 ; offre4 c p4 W.\nNotez signe/magnitude de \\(\\hat\\beta\\), p‑values, \\(R^2\\), résidus.\nRappel : si \\(\\mathrm{Cov}(P,\\varepsilon)\\neq 0\\), OLS biaisé."
  },
  {
    "objectID": "td6/td6.html#q3-test-dexogénéité-nakamura-nakamura-dwh",
    "href": "td6/td6.html#q3-test-dexogénéité-nakamura-nakamura-dwh",
    "title": "Économétrie — TD 6",
    "section": "8.3 Q3 — Test d’exogénéité (Nakamura & Nakamura / DWH)",
    "text": "8.3 Q3 — Test d’exogénéité (Nakamura & Nakamura / DWH)\n\nAvec Y comme instrument des prix, testez l’exogénéité des variables de prix.\n\n\n\nAfficher la réponse\n\nDans EViews : View → IV Diagnostics and Tests → Regressor Endogeneity Test.\n\\(H_0\\) : exogénéité. Si stat. (χ²/F) significative → rejeter \\(H_0\\) (prix endogène)."
  },
  {
    "objectID": "td6/td6.html#q4-estimation-en-vi-2sls",
    "href": "td6/td6.html#q4-estimation-en-vi-2sls",
    "title": "Économétrie — TD 6",
    "section": "8.4 Q4 — Estimation en VI (2SLS)",
    "text": "8.4 Q4 — Estimation en VI (2SLS)\n\nSi nécessaire, estimez les équations d’offre en 2SLS avec Y instrument (et W exogène dans offre4).\n\n\n\nAfficher la réponse\n\nQuick → Estimate Equation → Method: TSLS.\nEndogènes : p1 (ou p2/p3/p4). Instruments : Y (+ W en exogène).\nDiagnostics : F 1ʳᵉ étape (faiblesse), Hansen/Sargan (sur‑id), DWH (faut‑il instrumenter ?)."
  },
  {
    "objectID": "td6/td6-correction.html",
    "href": "td6/td6-correction.html",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "",
    "text": "Soit lwage = β₀ + β₁ educ + β₂ exper + β₃ expersq + ε.\nÉtapes :\n1. educ = γ₀ + γ₁ instruments + γ₂ exper + γ₃ expersq + ω (1ère étape)\n2. Extraire ω̂ et estimer lwage = β₀ + β₁ educ + β₂ exper + β₃ expersq + φ ω̂ + ε\n3. H0 : φ = 0 (exogène) vs H1 : φ ≠ 0 (endogène). Décision via t (ou F si plusieurs instruments).\nRésultats type : t(ω̂) avec 1 instrument ≈ 1.72 (&gt;1.645) ⇒ rejeter H0 (endogénéité).\nAvec 2 ou 3 instruments, la statistique F est très significative ⇒ endogénéité confirmée."
  },
  {
    "objectID": "td6/td6-correction.html#test-de-nakamura-nakamura",
    "href": "td6/td6-correction.html#test-de-nakamura-nakamura",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "",
    "text": "Soit lwage = β₀ + β₁ educ + β₂ exper + β₃ expersq + ε.\nÉtapes :\n1. educ = γ₀ + γ₁ instruments + γ₂ exper + γ₃ expersq + ω (1ère étape)\n2. Extraire ω̂ et estimer lwage = β₀ + β₁ educ + β₂ exper + β₃ expersq + φ ω̂ + ε\n3. H0 : φ = 0 (exogène) vs H1 : φ ≠ 0 (endogène). Décision via t (ou F si plusieurs instruments).\nRésultats type : t(ω̂) avec 1 instrument ≈ 1.72 (&gt;1.645) ⇒ rejeter H0 (endogénéité).\nAvec 2 ou 3 instruments, la statistique F est très significative ⇒ endogénéité confirmée."
  },
  {
    "objectID": "td6/td6-correction.html#sls",
    "href": "td6/td6-correction.html#sls",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "2) 2SLS",
    "text": "2) 2SLS\n\nMéthode TSLS sous EViews ; instruments : combinaisons de (motheduc, fatheduc, huseduc) + exogènes (exper, expersq).\n\nInterprétation : comparer coefficients & erreurs standard vs MCO."
  },
  {
    "objectID": "td6/td6-correction.html#qualité-des-instruments",
    "href": "td6/td6-correction.html#qualité-des-instruments",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "3) Qualité des instruments",
    "text": "3) Qualité des instruments\n\nPertinence : F de 1ère étape &gt; 10 ⇒ instruments forts.\n\nSargan : S = N·R² ~ χ²(k−p). Valeur observée faible ⇒ non rejet d’exogénéité des instruments."
  },
  {
    "objectID": "td6/td6-correction.html#white-sur-iv",
    "href": "td6/td6-correction.html#white-sur-iv",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "4) White (sur IV)",
    "text": "4) White (sur IV)\n\nSi W &lt; χ²_th ⇒ homoscédasticité plausible ; sinon, préférer SE robustes."
  },
  {
    "objectID": "td6/td6-correction.html#conclusion",
    "href": "td6/td6-correction.html#conclusion",
    "title": "TD 6 — Correction & explications (MROZ, IV/2SLS)",
    "section": "5) Conclusion",
    "text": "5) Conclusion\n\neduc est endogène ⇒ 2SLS requis. Instruments familiaux paraissent pertinents et exogènes au vu de Sargan ; commenter l’ampleur de l’effet et la robustesse."
  },
  {
    "objectID": "td4/td4.html",
    "href": "td4/td4.html",
    "title": "Économétrie — TD 4",
    "section": "",
    "text": "Ce document reprend les slides du TD 4 sous forme cours, avec des explications supplémentaires pour guider la lecture et la pratique sous EViews. L’objectif est de comprendre pourquoi on applique ces tests, comment les mettre en œuvre, et comment interpréter les résultats.\n\n\n\n\n\n\nNote\n\n\n\nÀ retenir. Les tests présentés concernent les hypothèses sur les erreurs du modèle MCO. Ils ne modifient pas la structure du modèle mais la validation des inférences que l’on effectue (significativité, intervalles de confiance)."
  },
  {
    "objectID": "td4/td4.html#les-hypothèses-des-estimations-mco",
    "href": "td4/td4.html#les-hypothèses-des-estimations-mco",
    "title": "Économétrie — TD 4",
    "section": "2.1 Les hypothèses des estimations MCO",
    "text": "2.1 Les hypothèses des estimations MCO\n\nL’estimateur des moindres carrés ordinaires (MCO) est le BLUE (Best Linear Unbiased Estimator) si certaines hypothèses sont respectées.\nCes hypothèses portent sur le terme d’erreur \\(\\varepsilon\\) :\n\nNormalité : \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2_\\varepsilon)\\)\nEspérance nulle : \\(\\mathbb{E}[\\varepsilon_i] = 0\\)\nHomoscédasticité : \\(\\mathrm{Var}(\\varepsilon_i) = \\sigma^2\\) (constante)\nIndépendance sérielle : \\(\\mathrm{Cov}(\\varepsilon_i,\\varepsilon_j)=0  \\forall i\\neq j\\)\nOrthogonalité : \\(\\mathrm{Cov}(x_i,\\varepsilon_i)=0\\) (exogénéité)\n\n\n\n\n\n\n\n\nCaution\n\n\n\nSensibilité. L’estimateur MCO est sensible aux observations extrêmes : soyez vigilants aux valeurs aberrantes et aux leviers."
  },
  {
    "objectID": "td4/td4.html#propriétés-des-estimateurs-rappels-sémantiques",
    "href": "td4/td4.html#propriétés-des-estimateurs-rappels-sémantiques",
    "title": "Économétrie — TD 4",
    "section": "2.2 Propriétés des estimateurs (rappels sémantiques)",
    "text": "2.2 Propriétés des estimateurs (rappels sémantiques)\n\nPetit échantillon\n\nSans biais : \\(\\mathbb{E}[\\hat\\beta] = \\beta\\)\nVariance minimale : \\(\\mathrm{Var}(\\hat\\beta) \\le \\mathrm{Var}(\\tilde\\beta)\\)\nEfficace : sans biais et à variance minimale\n\nGrand échantillon\n\nConvergent : \\(\\mathrm{Var}(\\hat\\beta) \\to 0\\) lorsque \\(N \\to \\infty\\)"
  },
  {
    "objectID": "td4/td4.html#hypothèses-problèmes-et-corrections",
    "href": "td4/td4.html#hypothèses-problèmes-et-corrections",
    "title": "Économétrie — TD 4",
    "section": "2.3 Hypothèses, problèmes et corrections",
    "text": "2.3 Hypothèses, problèmes et corrections\n\n\n\n\n\n\n\n\n\nPropriété / Hypothèse\nProblème si non respectée\nTest(s) associé(s)\nMéthode(s) de correction\n\n\n\n\nAbsence de biais (orthogonalité)\nBiais ; non‑convergence\n—\nInstrumentation (variables instrumentales)\n\n\nEfficience (sphéricité des erreurs)\nEstimation non efficace (mais pas de biais)\nHomoscédasticité : Breusch–Pagan, White ; Indépendance sérielle: Durbin–Watson, Breusch–Godfrey\nErreurs standards White (robustes) ; HAC (Newey–West)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFocus du TD. Nous traitons surtout les hypothèses d’efficience (3 et 4) : homoscédasticité et indépendance sérielle."
  },
  {
    "objectID": "td4/td4.html#intuition-et-indicateurs",
    "href": "td4/td4.html#intuition-et-indicateurs",
    "title": "Économétrie — TD 4",
    "section": "4.1 Intuition et indicateurs",
    "text": "4.1 Intuition et indicateurs\n\nLa normalité facilite certains tests de sphéricité.\nBera–Jarque (BJ) combine :\n\nSkewness (η) : asymétrie (η = 0 sous normalité)\nKurtosis (υ) : aplatissement (υ = 3 sous normalité)"
  },
  {
    "objectID": "td4/td4.html#statistique-hypothèses-décision",
    "href": "td4/td4.html#statistique-hypothèses-décision",
    "title": "Économétrie — TD 4",
    "section": "4.2 Statistique, hypothèses, décision",
    "text": "4.2 Statistique, hypothèses, décision\n\nStatistique : \\(BJ = N \\left[ \\frac{\\eta^2}{6} + \\frac{(\\upsilon-3)^2}{24} \\right]\\)\nSous \\(H_0\\), \\(BJ\\) suit approximativement une \\(\\chi^2\\).\nHypothèses :\n\n\\(H_0 :\\) normalité \\(BJ ≈ 0\\)\n\\(H_1 :\\) non‑normalité \\(BJ ≠ 0\\)\n\nRègle (5 %) : si \\(BJ &gt; \\chi^2_{2;0{,}95} \\approx 6\\) ⇒ rejeter \\(H_0\\)."
  },
  {
    "objectID": "td4/td4.html#mise-en-œuvre-dans-eviews",
    "href": "td4/td4.html#mise-en-œuvre-dans-eviews",
    "title": "Économétrie — TD 4",
    "section": "4.3 Mise en œuvre dans EViews",
    "text": "4.3 Mise en œuvre dans EViews\n\nOuvrir la fenêtre de l’équation.\nView → Residual Diagnostic → Histogram – Normality Test.\nLire BJ, p‑value, skewness et kurtosis ; conclure.\n\n\n\n\n\n\n\nTip\n\n\n\nLecture : une p‑value faible (≤ 5 %) → rejet de la normalité. On peut poursuivre les tests d’hétéroscédasticité / autocorrélation même si la normalité est discutée."
  },
  {
    "objectID": "td4/td4.html#test-de-breuschpagan-bp",
    "href": "td4/td4.html#test-de-breuschpagan-bp",
    "title": "Économétrie — TD 4",
    "section": "5.1 Test de Breusch–Pagan (BP)",
    "text": "5.1 Test de Breusch–Pagan (BP)\n\nIdée : la variance des erreurs dépend des variables explicatives.\nModèle estimé : \\(Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 Z_i + \\varepsilon_i\\) et \\(\\hat\\varepsilon_i = Y_i - \\hat\\beta_0 - \\hat\\beta_1 X_i - \\hat\\beta_2 Z_i\\) .\nHypothèses :\n\n\\(H_0 : \\mathrm{Var}(\\hat\\varepsilon_i) = \\sigma^2\\) (indépendante de X, Z)\n\\(H_1 : \\mathrm{Var}(\\hat\\varepsilon_i) = \\theta_0 + \\theta_1 X_i + \\theta_2 Z_i + \\omega_i\\)\n\nProcédure :\n\nEstimer le modèle MCO ; calculer \\(\\hat\\varepsilon_i^2\\).\nRégression de test : \\(\\hat\\varepsilon_i^2 = \\theta_0 + \\theta_1 X_i + \\theta_2 Z_i + \\omega_i\\).\n\\(BP = N × R²\\) de l’équation de test → \\(χ²(K − 1)\\) ;\nsi \\(BP ≥ χ²_th\\), rejeter \\(H₀\\).\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntuition : sous homoscédasticité, R² → 0 dans l’équation auxiliaire : X et Z n’expliquent pas la variance des résidus."
  },
  {
    "objectID": "td4/td4.html#test-de-white",
    "href": "td4/td4.html#test-de-white",
    "title": "Économétrie — TD 4",
    "section": "5.2 Test de White",
    "text": "5.2 Test de White\n\nMême logique que BP mais plus flexible (termes au carré et produits croisés).\nHypothèses :\n\n\\(H_0 : \\mathrm{Var}(\\hat\\varepsilon_i) = \\sigma^2\\)\n\\(H_1 : \\mathrm{Var}(\\hat\\varepsilon_i) = \\theta_0 + \\theta_1 X_i + \\theta_2 Z_i + \\theta_3 X_i^2 + \\theta_4 X_i Z_i + \\theta_5 Z_i^2 + \\omega_i\\)\n\nStatistiques :\n\n\\(W = N × R² → χ²(K − 1)\\) (K = nb de paramètres de l’équation auxiliaire)\nVariante petits échantillons (F‑test) : \\(W = \\left(\\frac{SCR_r - SCR_{nr}}{SCR_r}\\right)\\frac{N-k}{k-1} \\to F(k-1, N-k)\\)"
  },
  {
    "objectID": "td4/td4.html#mise-en-œuvre-dans-eviews-1",
    "href": "td4/td4.html#mise-en-œuvre-dans-eviews-1",
    "title": "Économétrie — TD 4",
    "section": "5.3 Mise en œuvre dans EViews",
    "text": "5.3 Mise en œuvre dans EViews\n\nView → Residual Diagnostic → Heteroskedasticity Tests\n\nBreusch–Pagan–Godfrey (BP)\nWhite"
  },
  {
    "objectID": "td4/td4.html#test-de-durbinwatson-dw",
    "href": "td4/td4.html#test-de-durbinwatson-dw",
    "title": "Économétrie — TD 4",
    "section": "6.1 Test de Durbin–Watson (DW)",
    "text": "6.1 Test de Durbin–Watson (DW)\n\nConditions : constante incluse ; \\(n &gt; 15\\) ; pas de variable dépendante retardée ; pas de données manquantes ; processus AR(1) uniquement.\nStatistique : \\(DW = \\frac{\\sum_{t=2}^T (\\hat\\varepsilon_t - \\hat\\varepsilon_{t-1})^2}{\\sum_{t=1}^T \\hat\\varepsilon_t^2} \\approx 2(1-\\hat\\rho)\\)\nLecture via bornes D_L et D_U (zones : rejet H₀, incertitude, acceptation).\n\n\n\n\n\n\n\nCaution\n\n\n\nLimites DW : zone d’incertitude, conditions restrictives → préférer souvent Breusch–Godfrey quand les conditions DW ne sont pas réunies."
  },
  {
    "objectID": "td4/td4.html#test-de-breuschgodfrey-bg",
    "href": "td4/td4.html#test-de-breuschgodfrey-bg",
    "title": "Économétrie — TD 4",
    "section": "6.2 Test de Breusch–Godfrey (BG)",
    "text": "6.2 Test de Breusch–Godfrey (BG)\n\nPlus flexible (AR(p) avec \\(p ≥ 1\\)).\nÉquation de test (ex. AR(2)) : \\(\\hat\\varepsilon_t = \\rho1 \\hat\\varepsilon{t-1} + \\rho2 \\hat\\varepsilon{t-2} + \\theta_1 X_t + \\theta_2 Z_t + \\omega_t\\)\nStatistique : \\(BG = T × R² → χ²(p)\\) ; rejeter \\(H₀\\) si \\(BG ≥ χ²_th\\).\nEViews : View → Residual Diagnostic → Serial correlation LM test (choisir les lags)."
  },
  {
    "objectID": "td4/td4.html#importez-le-fichier-de-travail-sur-les-compagnies-aériennes.",
    "href": "td4/td4.html#importez-le-fichier-de-travail-sur-les-compagnies-aériennes.",
    "title": "Économétrie — TD 4",
    "section": "8.1 Importez le fichier de travail sur les compagnies aériennes.",
    "text": "8.1 Importez le fichier de travail sur les compagnies aériennes."
  },
  {
    "objectID": "td4/td4.html#estimez-léquation-suivante-par-les-mco",
    "href": "td4/td4.html#estimez-léquation-suivante-par-les-mco",
    "title": "Économétrie — TD 4",
    "section": "8.2 Estimez l’équation suivante par les MCO :",
    "text": "8.2 Estimez l’équation suivante par les MCO :\n\\(log(Pass_i) =\\beta_0 + \\beta_1 Fatal_Passagers_i + \\beta_2 NonFatal_Passagers_i + \\beta_3 Low_cost_i \\ + \\beta_4 Public_i + \\beta_5 Inter_i + \\beta_6 Age_i + \\beta_7 Trafic_nat_i + \\beta_8 Trafic_dest_i +\\varepsilon_i\\)"
  },
  {
    "objectID": "td4/td4.html#homoscédasticité",
    "href": "td4/td4.html#homoscédasticité",
    "title": "Économétrie — TD 4",
    "section": "8.3 Homoscédasticité",
    "text": "8.3 Homoscédasticité\n· Qu’est-ce que l’homoscédasticité et quel problème induit son non-respect pour les MCO ?\n\n\nAfficher la réponse\n\nHomoscédasticité = la variance de l’erreur est constante pour toutes les valeurs des régressseurs :\n\n\\(\\mathrm{Var}(u_i\\mid X)=\\sigma^2\\) pour tout \\(i\\).\nSi cette hypothèse est violée (hétéroscédasticité) :\n\nLes estimateurs MCO \\(\\hat\\beta\\)​ restent sans biais et consistants si \\(E[u\\mid X]=0\\) tient, mais ils ne sont plus efficaces (plus BLUE) : il existe de meilleurs estimateurs (GLS/WLS).\nLes écarts-types MCO “classiques” sont faussés ⇒ tests t/F et IC peuvent être trompeurs (trop optimistes ou trop prudents).\nConséquence pratique majeure : mauvaise inférence.\n\nQue faire ?\n\nUtiliser des erreurs-types robustes à l’hétéroscédasticité (HC0–HC3/“White”)."
  },
  {
    "objectID": "td4/td4.html#homoscédasticité-1",
    "href": "td4/td4.html#homoscédasticité-1",
    "title": "Économétrie — TD 4",
    "section": "8.4 Homoscédasticité",
    "text": "8.4 Homoscédasticité\n· A l’aide des tests de Goldfeld et Quandt, de Breusch-Pagan-Koenker et de White, que peut-on conclure quant à l’homoscédasticité du terme d’erreurs ?\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td4/td4.html#corrections",
    "href": "td4/td4.html#corrections",
    "title": "Économétrie — TD 4",
    "section": "8.5 Correction(s)",
    "text": "8.5 Correction(s)\n· En fonction des résultats des divers tests, proposez une correction le cas échéant.\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td4/td4.html#corrections-1",
    "href": "td4/td4.html#corrections-1",
    "title": "Économétrie — TD 4",
    "section": "8.6 Correction(s)",
    "text": "8.6 Correction(s)\n· Vos conclusions quant à l’effet des accidents mortels et non mortels sont-elles modifiées ?\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td4/td4-correction.html",
    "href": "td4/td4-correction.html",
    "title": "TD 4 — Correction & explications",
    "section": "",
    "text": "H0 : pas d’autocorrélation d’ordre 1 ; H1 : autocorrélation d’ordre 1.\nLecture : zone [0, DL] (rejet H0), [DU, 2] (non-rejet H0), entre DL et DU = doute (tables DW).\nExemple (issus du workfile AUTO) :\n\nHabillement : DW ≈ 1.68 → entre DU et 2 ⇒ pas d’autocorrélation (ordre 1).\n\nTéléphone : DW ≈ 0.90 → &lt; DL ⇒ autocorrélation.\n\nAérien : DW ≈ 1.46 → entre DL & DU ⇒ zone d’incertitude."
  },
  {
    "objectID": "td4/td4-correction.html#durbinwatson-dw",
    "href": "td4/td4-correction.html#durbinwatson-dw",
    "title": "TD 4 — Correction & explications",
    "section": "",
    "text": "H0 : pas d’autocorrélation d’ordre 1 ; H1 : autocorrélation d’ordre 1.\nLecture : zone [0, DL] (rejet H0), [DU, 2] (non-rejet H0), entre DL et DU = doute (tables DW).\nExemple (issus du workfile AUTO) :\n\nHabillement : DW ≈ 1.68 → entre DU et 2 ⇒ pas d’autocorrélation (ordre 1).\n\nTéléphone : DW ≈ 0.90 → &lt; DL ⇒ autocorrélation.\n\nAérien : DW ≈ 1.46 → entre DL & DU ⇒ zone d’incertitude."
  },
  {
    "objectID": "td4/td4-correction.html#breuschgodfrey-bg-ordre-1",
    "href": "td4/td4-correction.html#breuschgodfrey-bg-ordre-1",
    "title": "TD 4 — Correction & explications",
    "section": "2) Breusch–Godfrey (BG, ordre 1)",
    "text": "2) Breusch–Godfrey (BG, ordre 1)\n\nStatistique : BG = T·R² de l’équation de test (régression du résidu sur ses retards et X). Décision via χ²(1).\nProcédure : View → Residual Diagnostics → Serial Correlation LM Test (choisir lags).\nExemple :\n\nHabillement : BG &lt;&lt; 3.84 ⇒ pas d’autocorrélation.\n\nTéléphone : BG &gt;&gt; 3.84 ⇒ autocorrélation.\n\nAérien : BG &lt;&lt; 3.84 ⇒ pas d’autocorrélation."
  },
  {
    "objectID": "td4/td4-correction.html#correction-cochraneorcutt-ar1",
    "href": "td4/td4-correction.html#correction-cochraneorcutt-ar1",
    "title": "TD 4 — Correction & explications",
    "section": "3) Correction : Cochrane–Orcutt (AR(1))",
    "text": "3) Correction : Cochrane–Orcutt (AR(1))\n\nAjouter AR(1) dans la spécification de l’équation sous EViews (estime ρ).\n\nRe-estimer et comparer : SE, t, R² ajusté, Durbin–Watson (→ proche de 2 si correction pertinente)."
  },
  {
    "objectID": "td4/td4-correction.html#comfac-téléphone",
    "href": "td4/td4-correction.html#comfac-téléphone",
    "title": "TD 4 — Correction & explications",
    "section": "4) COMFAC (téléphone)",
    "text": "4) COMFAC (téléphone)\n\nH0 : contraintes de Cochrane–Orcutt valides ; H1 : invalides (spécification alternative avec variables retardées).\n\nStatistique : T · ln(SCRC / SCRNC) ~ χ²(c), où c = nb de contraintes CO.\n\nInterprétation : si rejet H0, la spécification avec AR(1) n’est pas suffisante → privilégier un modèle alternatif (par ex. lags des variables)."
  },
  {
    "objectID": "td4/td4-correction.html#remarques-pédagogiques",
    "href": "td4/td4-correction.html#remarques-pédagogiques",
    "title": "TD 4 — Correction & explications",
    "section": "Remarques pédagogiques",
    "text": "Remarques pédagogiques\n\nL’indépendance sérielle est cruciale pour l’efficience des MCO (BLUE).\n\nEn présence d’autocorrélation : erreurs standards biaisées → tests t/F non fiables sans correction."
  },
  {
    "objectID": "td3/td3-slides.html#modèle-de-régression-linéaire-simple",
    "href": "td3/td3-slides.html#modèle-de-régression-linéaire-simple",
    "title": "Économétrie — TD 3",
    "section": "1.1 Modèle de régression linéaire simple",
    "text": "1.1 Modèle de régression linéaire simple\nUne régression consiste à expliquer les variations d’une variable dépendante \\(Y\\) par celles d’une ou plusieurs variables indépendantes \\(X\\).\nOn suppose la relation (droite de régression) :\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\quad i=1,\\dots,N\\)\noù \\(\\varepsilon_i\\) est centré et non corrélé aux régressseurs.\nObjectif MCO (OLS). Estimer \\(\\beta_0,\\beta_1\\) en minimisant la somme des carrés :\n\\(\\min{\\sum_{i=0}^N \\varepsilon_i^2}= \\min\\sum_{i=0}^N \\big(Y_i - \\beta_0 - \\beta_1 X_i\\big)^2.\\)\n\n\n\n\n\n\nTip\n\n\n\\(\\beta_1\\) Représente ici la magnitude de “l’effet” de la variable \\(X_1\\) sur \\(Y\\). \\(\\varepsilon\\_i\\) Représente la partie non expliquée de la relation (ou terme d’erreur)"
  },
  {
    "objectID": "td3/td3-slides.html#forme-matricielle-régression-multiple",
    "href": "td3/td3-slides.html#forme-matricielle-régression-multiple",
    "title": "Économétrie — TD 3",
    "section": "1.2 Forme matricielle (régression multiple)",
    "text": "1.2 Forme matricielle (régression multiple)\nEn multiple :\\(Y = X\\beta + \\varepsilon,\\qquad \\hat\\beta = (X'X)^{-1}X'Y.\\)"
  },
  {
    "objectID": "td3/td3-slides.html#estimation",
    "href": "td3/td3-slides.html#estimation",
    "title": "Économétrie — TD 3",
    "section": "2.1 Estimation",
    "text": "2.1 Estimation\n\nFaire Object →New Object →Equation\nAutre méthode :\n\n1. Sélectionner les variables en débutant par la variable dépendante (Y)\n2. Faire Open →as Equation\n\nLa fenêtre ouverte a deux onglets :\n▶ Specification : Entrer la spécification choisie\n▶ Options :\n\nCet onglet sert pour la correction de la matrice de variance-covariance\nNous ignorons pour le moment cet onglet"
  },
  {
    "objectID": "td3/td3-slides.html#estimation-1",
    "href": "td3/td3-slides.html#estimation-1",
    "title": "Économétrie — TD 3",
    "section": "2.2 Estimation",
    "text": "2.2 Estimation\n\nEquation specification : Permet d’entrer l’équation estimée\n▶ Il faut mettre d’abord la variable expliquée (Y) puis les variables explicatives (X1 ; X2, . . .) : Y X1 X2 ... c\n▶ c sert à spécier l’introduction d’une constante\n▶ Nota : Si la deuxième méthode est utilisée, l’équation est déjà spéciée mais peut être modiée\nEstimation Settings :\n▶ Method : Permet de choisir l’estimateur (MCO [LS] par défaut)\n▶ Sample : Permet de choisir l’échantillon retenu"
  },
  {
    "objectID": "td3/td3-slides.html#commandes-post-estimations",
    "href": "td3/td3-slides.html#commandes-post-estimations",
    "title": "Économétrie — TD 3",
    "section": "2.3 Commandes post-estimations",
    "text": "2.3 Commandes post-estimations\n\nLes coeficients estimés sont conservés dans l’objet c\nLes résidus estimés de la dernière équation sont stockés dans”resid”\nName :\n\nPermet de conserver la régression dans un workfile\n\nView →representation :\n\nPermet de visualiser la ligne de commande eectuée, l’équation théorique et l’équation avec les valeurs estimées des coeficients\n\nView →estimation output :\n\nPermet de visualiser les résultats bruts de la régression."
  },
  {
    "objectID": "td3/td3-slides.html#commandes-post-estimations-1",
    "href": "td3/td3-slides.html#commandes-post-estimations-1",
    "title": "Économétrie — TD 3",
    "section": "2.4 Commandes post-estimations",
    "text": "2.4 Commandes post-estimations\n\nView →actual, fitted, residual :\n▶ actual : valeur de la variable dépendante utilisée dans la régression,\n▶ fitted : valeurs de la variable dépendante prédites par la régression en appliquant les coeficients de la régression sur les variables explicatives,\n▶ residual (actual-tted) : indication sur les erreurs de prévisionéventuelles, bornes à 5%.\nFreeze :\n\nPermet de conserver les résultats."
  },
  {
    "objectID": "td3/td3-slides.html#commandes-post-estimations-2",
    "href": "td3/td3-slides.html#commandes-post-estimations-2",
    "title": "Économétrie — TD 3",
    "section": "2.5 Commandes post-estimations",
    "text": "2.5 Commandes post-estimations\n\nIl est possible de vouloir conserver plusieurs éléments de l’équation estimée\n▶ Ex : Pour calculer des points de retournement ou pour certains tests il faut conserver les R2, la SCR, . . .\nPour ce faire, il sut généralement de créer un objet (scalaire, matrice) qui puisse accueillir ces nouveaux éléments\n▶ Exemples :\n\nScalaire : scalar nom=nomequation.operation\nMatrice : matrix nom=nomequation.operation\nEx : scalar rsq=eq1.@r2\nEx : matrix coefficients=eq1.@coefs\n\n\n\n\n\n\n\n\nTip\n\n\nL’opération commence par .@ en général"
  },
  {
    "objectID": "td3/td3-slides.html#commandes-post-estimations-3",
    "href": "td3/td3-slides.html#commandes-post-estimations-3",
    "title": "Économétrie — TD 3",
    "section": "2.6 Commandes post-estimations",
    "text": "2.6 Commandes post-estimations\nQuelques éléments disponibles (non exhaustif):\n\n\n\nÉlément\nOpération\nType d’objet\n\n\n\n\nR²\n@r2\nscalar\n\n\nR² ajusté\n@rbar2\nscalar\n\n\nSCR\n@ssr\nscalar\n\n\nCoefficient pour la i-ème variable\nc(i)\nscalar\n\n\nt-stat pour la i-ème variable\n@tstats(i)\nscalar\n\n\nMatrice de variance-covariance\n@coefcov\nmatrix\n\n\nMatrice des coefficients\n@coefs\nmatrix\n\n\nMatrice des t-stat\n@tstats\nmatrix\n\n\n\n\nUne liste plus complète est disponible dans Users Guide II page 16"
  },
  {
    "objectID": "td3/td3-slides.html#le-coeficient-de-détermination-le-r2",
    "href": "td3/td3-slides.html#le-coeficient-de-détermination-le-r2",
    "title": "Économétrie — TD 3",
    "section": "2.7 Le coeficient de détermination : Le \\(R^2\\)",
    "text": "2.7 Le coeficient de détermination : Le \\(R^2\\)\n\nLe pouvoir explicatif du modèle\n▶ L’économétrie cherche à expliquer les variations de Y. Ceci est la variabilité totale (SCT pour somme des carrés totale) et est donnée par : \\(SCT=\\sum_{i=1}^N(y_i - \\bar y)^2= SCE + SCR\\)\n▶ Cette variabilité se décompose en :\n\n\nVariabilité expliquée : SCE (pour somme des carrés expliquée)\nVariabilité non expliquée : SCR (pour somme des carrés des résidus)"
  },
  {
    "objectID": "td3/td3-slides.html#le-coefficient-de-détermination-le-r2",
    "href": "td3/td3-slides.html#le-coefficient-de-détermination-le-r2",
    "title": "Économétrie — TD 3",
    "section": "2.8 Le coefficient de détermination : le \\(R^2\\)",
    "text": "2.8 Le coefficient de détermination : le \\(R^2\\)\n\nLe coefficient de détermination mesure le pouvoir explicatif du modèle et se calcule comme suit :\n\n\\(R^2 = \\frac{SCE}{SCT} = 1 - \\frac{SCR}{SCT} \\quad\\text{avec}\\quad \\begin{cases}\n\\displaystyle SCR = \\sum_{i=1}^N \\hat{\\varepsilon}_i^2 \\\\\n\\displaystyle SCT = \\sum_{i=1}^N (y_i - \\bar{y})^2\n\\end{cases}\\)\n\nCe coefficient mesure la qualité de l’ajustement de la régression en indiquant le pourcentage de la variance totale expliquée par le modèle :\n\nSi ( \\(R^2 \\to 1\\) ) : le modèle est très explicatif.\nSi ( \\(R^2 \\to 0\\) ) : le modèle est peu explicatif."
  },
  {
    "objectID": "td3/td3-slides.html#le-coefficient-de-détermination-le-r2-1",
    "href": "td3/td3-slides.html#le-coefficient-de-détermination-le-r2-1",
    "title": "Économétrie — TD 3",
    "section": "2.9 Le coefficient de détermination : le \\(R^2\\)",
    "text": "2.9 Le coefficient de détermination : le \\(R^2\\)\n\nIl faut en réalité faire attention avec le ( \\(R^2\\) ) :\n\nLe ( \\(R^2\\) ) augmente mécaniquement avec l’ajout de variables explicatives.\nIl faut par conséquent privilégier une version ajustée du nombre de degrés de liberté, le ( \\(R^2\\) ) ajusté :\n\n\n\\(\\bar{R}^2 = 1 - (1 - R^2)\\frac{N-1}{N-p}\\)\n\n( \\(N\\) ) : nombre d’observations\n( \\(p\\)) : nombre de variables explicatives (sans la constante)\nLe ( \\(R^2\\)) n’est pas un objectif en soi, il ne faut pas chercher à le maximiser."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-simple",
    "href": "td3/td3-slides.html#la-significativité-simple",
    "title": "Économétrie — TD 3",
    "section": "3.1 La significativité simple",
    "text": "3.1 La significativité simple\n\nObjectif : déterminer si le coefficient estimé est précis.\nPour cela, on fait un test de Student à partir de :\n\nla valeur estimée du coefficient ( \\(\\hat{\\beta}_j\\) ),\net la valeur estimée de son écart-type ( \\(\\hat{\\sigma}_{\\beta}\\) ).\nRappel : l’écart-type mesure la dispersion d’une série autour de sa moyenne.\n\nLa statistique de test est la suivante :\n\n\\(t_{\\beta_j} = \\frac{\\hat{\\beta}_j - \\beta_{\\text{th}}}{\\hat{\\sigma}_{\\beta}}\\)\n\nLes hypothèses testées sont :\n\n\\(H_0 : \\beta_j = \\beta{\\text{th}}\\)\n\\(H_1 : \\beta_j \\neq \\beta{\\text{th}}\\)"
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-simple-1",
    "href": "td3/td3-slides.html#la-significativité-simple-1",
    "title": "Économétrie — TD 3",
    "section": "3.2 La significativité simple",
    "text": "3.2 La significativité simple\n\nLe test consiste souvent à savoir si le paramètre est significativement différent de 0 ( \\(\\beta_{\\text{th}} = 0\\) ).\nLa statistique de test devient donc :\n\n\\(t_{\\beta_j} = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma}_{\\beta}}\\)\n\nLes hypothèses testées deviennent :\n\n\\(H_0 : \\beta_j = 0\\)\n\\(H_1 : \\beta_j \\neq 0\\)"
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-simple-2",
    "href": "td3/td3-slides.html#la-significativité-simple-2",
    "title": "Économétrie — TD 3",
    "section": "3.3 La significativité simple",
    "text": "3.3 La significativité simple\n\nLa statistique de test calculée \\(t_{\\beta_j}\\) est comparée à la statistique théorique \\(t\\alpha\\) tabulée pour un risque de première espèce \\(\\alpha\\).\nRemarque : il s’agit en général d’un test bilatéral.\n\n\n\nCode\nalpha &lt;- 0.05\ndf    &lt;- 30\nxlim  &lt;- c(-4, 4)\ntcrit &lt;- qt(1 - alpha/2, df = df)\n\nxx &lt;- seq(xlim[1], xlim[2], length.out = 2000)\nyy &lt;- dt(xx, df = df)\n\nplot(xx, yy, type = \"l\", lwd = 2,\n     xlab = \"t\", ylab = \"densité\",\n     main = sprintf(\"Loi t(%d) — test bilatéral (α = %.2f)\", df, alpha),\n     xaxt = \"n\")  # on dessine l'axe X nous-mêmes\n\nshade_region &lt;- function(x_from, x_to, col){\n  xseq &lt;- seq(x_from, x_to, length.out = 500)\n  yseq &lt;- dt(xseq, df = df)\n  polygon(c(xseq, rev(xseq)), c(yseq, rep(0, length(yseq))),\n          col = col, border = NA)\n}\n\n# Colorier les zones\nshade_region(-tcrit, tcrit, col = rgb(0.2, 0.6, 1, 0.3))      # zone centrale\nshade_region(xlim[1], -tcrit, col = rgb(1, 0.2, 0.2, 0.35))   # queue gauche\nshade_region(tcrit, xlim[2],  col = rgb(1, 0.2, 0.2, 0.35))   # queue droite\n\n# Traits verticaux\nabline(v = c(-tcrit, tcrit), lwd = 2, lty = 2)\n\n# Axe X avec -t* et t* comme graduations\naxis(1,\n     at = c(xlim[1], -tcrit, 0, tcrit, xlim[2]),\n     labels = c(\"\", sprintf(\"-t* = %.2f\", -tcrit), \"0\", sprintf(\"t* = %.2f\", tcrit), \"\"),\n     tick = TRUE)\n\n# Étiquettes\ntext(0, max(yy)*0.65, expression(1 - alpha), cex = 1.4)\n# α/2 décalés sous l'axe X, vers l'extérieur\ntext(-tcrit, -0.015, expression(alpha/2), cex = 1.2, pos = 1, offset = 1)\ntext( tcrit, -0.015, expression(alpha/2), cex = 1.2, pos = 1, offset = 1)\n\nlegend(\"topright\",\n       legend = c(\"densité t(df)\",\n                  \"région d'acceptation (1-α)\",\n                  \"régions de rejet (α/2)\"),\n       lty = c(1, NA, NA), lwd = c(2, NA, NA),\n       pch = c(NA, 15, 15),\n       pt.cex = 2,\n       col = c(\"black\", rgb(0.2,0.6,1,0.3), rgb(1,0.2,0.2,0.35)),\n       bty = \"n\", cex = 0.9)\n\n\n\n\nFigure 2: Test bilatéral : α/2 décalés vers l’extérieur, -t* et t* en graduations de l’axe X."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-simple-procédure",
    "href": "td3/td3-slides.html#la-significativité-simple-procédure",
    "title": "Économétrie — TD 3",
    "section": "3.4 La significativité simple — procédure",
    "text": "3.4 La significativité simple — procédure\n\nCalculer la statistique de Student (Coef / SE) : \\(t_{\\beta_j} = \\hat{\\beta}j / {\\sigma}{\\hat\\beta}\\).\nChoisir un niveau de risque de première espèce \\(\\alpha\\).\nDéterminer la valeur critique tabulée \\(t_{\\alpha/2, \\nu}\\) pour un test bilatéral, avec \\(\\nu = N - p \\quad (\\text{ddl : nb d'observations } N \\text{ moins nb de paramètres } p)\\) .\nConclure sur la significativité selon la règle de décision :\n\nsi \\(|t| &lt; t_{\\alpha/2, \\nu}) (\\Rightarrow) \\text{ non-rejet de }H_0\\)\nsi \\(|t| \\ge t_{\\alpha/2, \\nu}) (\\Rightarrow)\\text{ rejet de }(H_0)\\)"
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe",
    "href": "td3/td3-slides.html#la-significativité-conjointe",
    "title": "Économétrie — TD 3",
    "section": "3.5 La significativité conjointe",
    "text": "3.5 La significativité conjointe\n\n\n\n\n\n\nTip\n\n\nDans un modèle, nous pouvons nous intéresser à déterminer si nos différentes variables ont un effet significatif sur notre variable \\(Y\\), dépendemment les unes des autres. C’est à dire, est-ce que mes variables sont significatives conjointement ( \\(X_1\\) significative ET \\(X_N\\) …)\n\n\n\nDans ce cadre, les simples tests de Student ne sont pas suffisants, pour tester plusieurs restrictions, il faut recourir à d’autres tests:\n▶ Test de Fisher dans le cas des modèles linéaires\n▶ Tests de Wald, du log de vraisemblance ou du multiplicateurs de Lagrange dans les cas plus complexes"
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-le-test-de-fisher-f-test",
    "href": "td3/td3-slides.html#la-significativité-conjointe-le-test-de-fisher-f-test",
    "title": "Économétrie — TD 3",
    "section": "3.6 La significativité conjointe le test de Fisher (F-test)",
    "text": "3.6 La significativité conjointe le test de Fisher (F-test)\n\nLe F-test permet de tester la significativité conjointe de plusieurs paramètres, voire la significativité globale d’un modèle linéaire. La statistique de test est la suivante :\n\n\\(F = \\displaystyle\\frac{SCR_r - SCR_{nr}}{SCR_{nr}}{\\displaystyle \\frac{N - p}{q}}\\)\noù :\n\n\\(q\\) : nombre de restrictions testées (sans la constante),\n\\(p\\) : nombre de paramètres dans le modèle non restreint (avec la constante),\n\\(N\\) : nombre d’observations.\n\\(SCR_r\\) : somme des carrés des résidus du modèle restreint (les paramètres imposés sont fixés),\n\\(SCR_{nr}\\) : somme des carrés des résidus du modèle non restreint (modèle usuel non contraint)."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-f-test-unilatéral",
    "href": "td3/td3-slides.html#la-significativité-conjointe-f-test-unilatéral",
    "title": "Économétrie — TD 3",
    "section": "3.7 La significativité conjointe — F-test (unilatéral)",
    "text": "3.7 La significativité conjointe — F-test (unilatéral)\n\nLe test de Fisher est unilatéral (rejet dans la queue droite).\nSous (H_0), la statistique suit une loi de Fisher–Snedecor : \\(F \\sim F(q, N-p)\\) , où \\(q\\) = nb de restrictions testées et \\(N-p\\) = ddl résiduels du modèle non restreint.\nLes logiciels (EViews, R, etc.) donnent directement (F), la p-value et la table ANOVA.\n\n\n\nCode\nalpha &lt;- 0.05\nq     &lt;- 3\ndf2   &lt;- 30\nFcrit &lt;- qf(1 - alpha, df1 = q, df2 = df2)\n\nxmax &lt;- qf(0.999, df1 = q, df2 = df2)\nxx   &lt;- seq(0, xmax, length.out = 2000)\nyy   &lt;- df(xx, df1 = q, df2 = df2)\n\nplot(xx, yy, type = \"l\", lwd = 2,\n     xlab = \"F\", ylab = \"densité\",\n     main = sprintf(\"Loi F(%d, %d) — test unilatéral (α = %.02f)\", q, df2, alpha),\n     cex.lab = 1.3, cex.axis = 1.2, xaxt = \"n\")\n\nshade_region &lt;- function(x_from, col){\n  xseq &lt;- seq(x_from, xmax, length.out = 600)\n  yseq &lt;- df(xseq, df1 = q, df2 = df2)\n  polygon(c(xseq, rev(xseq)), c(yseq, rep(0, length(yseq))),\n          col = col, border = NA)\n}\n\n# Zones\npolygon(c(0, xx[xx &lt;= Fcrit], Fcrit),\n        c(0, yy[xx &lt;= Fcrit], 0),\n        col = rgb(0.2, 0.6, 1, 0.15), border = NA)\nshade_region(Fcrit, col = rgb(1, 0.2, 0.2, 0.35))\n\nabline(v = Fcrit, lwd = 2, lty = 2)\n\n# Axe X plus lisible avec F* bien marqué\naxis(1,\n     at = c(0, Fcrit, round(xmax,1)),\n     labels = c(\"0\",\n                bquote(F^\"*\" == .(round(Fcrit,2))),\n                round(xmax,1)),\n     cex.axis = 1.2)\n\n# Étiquettes\ntext(mean(c(0,Fcrit))*0.5, max(yy)*0.5, expression(H[0]), cex = 1.4)\ntext((Fcrit + xmax)/2, max(yy)*0.25, expression(H[A]), cex = 1.4)\ntext(Fcrit, par(\"usr\")[3] - 0.02, expression(alpha),\n     xpd = NA, pos = 1, cex = 1.3)\n\nlegend(\"topright\",\n       legend = c(\"densité F(q, N−p)\",\n                  \"région H0 (non rejet)\",\n                  \"région de rejet (α)\"),\n       lty = c(1, NA, NA), lwd = c(2, NA, NA),\n       pch = c(NA, 15, 15), pt.cex = 2,\n       col = c(\"black\", rgb(0.2,0.6,1,0.15), rgb(1,0.2,0.2,0.35)),\n       bty = \"n\", cex = 1)\n\n\n\n\nFigure 3: Loi F(3,30) — test unilatéral : étiquettes lisibles."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-hypothèses-usuelles-du-f-test",
    "href": "td3/td3-slides.html#la-significativité-conjointe-hypothèses-usuelles-du-f-test",
    "title": "Économétrie — TD 3",
    "section": "3.8 La significativité conjointe — hypothèses usuelles du F-test",
    "text": "3.8 La significativité conjointe — hypothèses usuelles du F-test\n\nOn teste généralement la contrainte selon laquelle tous les coefficients (hors constante) sont nuls.\n\n\\(H_0\\) : tous les coefficients du modèle sont égaux à 0 (sauf l’intercept), c.-à-d. \\(H_0\\) : \\(\\beta_1=\\beta_2=\\cdots=\\beta_p=0\\)\n\\(H_1\\) : au moins un coefficient est différent de 0.\n\nDans ce cas, le modèle contraint est le modèle avec seule la constante. Règle de décision :\nsi \\(F &gt; F_{\\text{table}}\\) (au niveau \\(\\alpha)\\)et ddl \\((q, N-p)\\)) \\(\\Rightarrow\\) rejet de \\(H_0\\).\nInterprétation :\n\nNon-rejet de \\(H_0\\) \\(\\Rightarrow\\) pas de relation linéaire significative entre la variable expliquée et l’ensemble des variables explicatives.\nAutrement dit, la SCE (somme des carrés expliquée) n’est pas significativement différente de 0 ; la variabilité de (Y) demeure essentiellement aléatoire."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-f-test-procédure-eviews",
    "href": "td3/td3-slides.html#la-significativité-conjointe-f-test-procédure-eviews",
    "title": "Économétrie — TD 3",
    "section": "3.9 La significativité conjointe — F-Test : procédure EViews",
    "text": "3.9 La significativité conjointe — F-Test : procédure EViews\n\nProcédure à suivre :\n\nRégresser le modèle non contraint et relever la SCR.\nRégresser le modèle contraint et relever la SCR.\nCalculer la statistique de Fisher.\nComparer la valeur obtenue à la valeur théorique (table de Fisher)."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-f-test-exemple-de-commandes-eviews",
    "href": "td3/td3-slides.html#la-significativité-conjointe-f-test-exemple-de-commandes-eviews",
    "title": "Économétrie — TD 3",
    "section": "3.10 La significativité conjointe — F-Test : Exemple de commandes EViews",
    "text": "3.10 La significativité conjointe — F-Test : Exemple de commandes EViews\nequation eqnr Y X1 X2 X3 X4 X5 c\nscalar scrnr = eqnr.@ssr\nequation eqr Y X1 X3 c\nscalar scrr = eqr.@ssr\nscalar F = ((scrr - scrnr) / scrnr) * ((129 - 5) / 3)\nIci :\n\neqnr : estimation du modèle non restreint (toutes les variables).\neqr : estimation du modèle restreint.\nscrnr et scrr : sommes des carrés des résidus respectivement non restreint et restreint.\nF : statistique de Fisher calculée manuellement."
  },
  {
    "objectID": "td3/td3-slides.html#la-significativité-conjointe-wald-test",
    "href": "td3/td3-slides.html#la-significativité-conjointe-wald-test",
    "title": "Économétrie — TD 3",
    "section": "3.11 La significativité conjointe — Wald-test",
    "text": "3.11 La significativité conjointe — Wald-test\n\nLa procédure selon le Wald-test est pré-enregistrée dans EViews :\n\nOuvrir les résultats de l’estimation.\nMenu : View → Coefficient diagnostic → Wald test.\nSaisir les contraintes de la forme :\nc(numéro_coef1) = 0\nc(numéro_coef2) = 0\npar exemple :\nc(3) = 0\nc(5) = 0"
  },
  {
    "objectID": "td3/td3-slides.html#significativité-économique---un-tableau-récapitulatif",
    "href": "td3/td3-slides.html#significativité-économique---un-tableau-récapitulatif",
    "title": "Économétrie — TD 3",
    "section": "4.1 Significativité économique - un tableau récapitulatif :",
    "text": "4.1 Significativité économique - un tableau récapitulatif :\n\n\n\n\n\n\n\n\nVariable expliquée (Y)\nVariable explicative (X)\nInterprétation du coefficient \\(\\beta\\)\n\n\n\n\nNiveau\nNiveau\nUne augmentation de 1 unité de X entraîne une variation moyenne de \\(\\beta\\) unités de Y.\n\n\nNiveau\nLogarithme\nUne augmentation de 1 % de X entraîne une variation moyenne de \\(\\beta / 100\\) unités de Y.\n\n\nLogarithme\nNiveau\nUne augmentation de 1 unité de X entraîne une variation moyenne de \\(\\beta \\times 100\\) % de Y.\n\n\nLogarithme\nLogarithme\nUne augmentation de 1 % de X entraîne une variation moyenne de \\(\\beta\\) % de Y."
  },
  {
    "objectID": "td3/td3-slides.html#questions-réponses-td3-module-3",
    "href": "td3/td3-slides.html#questions-réponses-td3-module-3",
    "title": "Économétrie — TD 3",
    "section": "4.2 Questions – Réponses TD3 (Module 3)",
    "text": "4.2 Questions – Réponses TD3 (Module 3)"
  },
  {
    "objectID": "td2/td2.html",
    "href": "td2/td2.html",
    "title": "Économétrie — TD 2",
    "section": "",
    "text": "Ces diapositives introduisent les statistiques descriptives : elles servent à résumer et visualiser les variables avant toute modélisation (tendance centrale, dispersion, forme, comparaisons par modalité).\n\n\n\n\nCes commandes se tapent dans la fenêtre de commande d’EViews.\n\n\n\n\n\n\n\n\nCommande\nDescription\nExemple\n\n\n\n\ngroup\nCréer un groupe de variables\ngroup nom x y\n\n\nscalar\nCréer un scalaire et faire des calculs\nscalar k = 3*6\n\n\nmatrix\nCréer une matrice et faire des calculs (matriciels)\n(cf. Help)\n\n\ngenr\nGénérer une variable\n(cf. plus bas)\n\n\nrename\nRenommer une variable\nrename x y (renomme x en y)\n\n\ndelete\nEffacer un ou plusieurs objets\ndelete x y\n\n\nsmpl\nSélectionner un sous-échantillon\nsmpl if x&lt;10\n\n\n\n\n\n\n\nVous êtes souvent amenés à créer de nouvelles variables ou à en changer l’échelle.\nIl existe deux types de variables :\n\nVariable continue\nprend n’importe quelle valeur sur un intervalle donné.\nVariable discrète\nne prend qu’un nombre fini de valeurs.\n\n\n\n\n\n\nNote\n\n\n\nNota : les variables binaires (0/1) sont un cas particulier.\n\n\n\n\n\n\n\nCommande générale :\n\ngenr nouveau_nom = opération\nEx. genr lnx = log(x)\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention : saisir la ligne de commande dans la fenêtre de commande.\n\n\n\n\n\n\n\n\n\nFormule mathématique\nEViews\n\n\n\n\n\\(x + a\\)\nx+a\n\n\n\\(x - a\\)\nx-a\n\n\n\\(x \\cdot a\\)\nx*a\n\n\n\\(x / a\\)\nx/a\n\n\n\\(x^a\\)\nx^a\n\n\n\\(\\ln(x)\\)\nlog(x)\n\n\n\\(e^x\\)\nexp(x)\n\n\n\n\n\n\n\nUne variable muette est discrète 0/1 (binaire).\nExemples : - (=1) si l’individu est une femme, (0) sinon. - (=1) si le pays est OCDE, (0) sinon.\nDeux méthodes :\n\n\n\n\ngenr nouveau = x &gt; A\nEx. jeune vaut 1 si âge \\(\\le\\) 25, 0 sinon :\ngenr jeune = age &lt;= 25\n\n\n\n\n\nObjectif : riche vaut 1 si pibtete &gt; 10000, 0 sinon.\n\ngenr riche = 0\n\nsmpl if pibtete &gt; 10000\n\ngenr riche = 1\n\nsmpl @all\n\n\n\n\n\n\nUne variable discrète prend un nombre limité de valeurs (0, 1, …, n).\n- Peut venir d’un classement (ex. classes de revenus).\n- Peut coder un choix limité (pays d’immigration, parti politique, notes…).\n\n\n\n\n\n\nNote\n\n\n\nRemarque : une muette est un cas particulier de discrète.\n\n\nDeux méthodes :\n\n\n\nExemple : classes d’âge (\n\\[\n\\begin{array}{l}\nclasses= \\begin{cases}\n0 & si \\quad age \\leq 25 \\\\\n1 & si \\quad 25 &lt; age \\leq 35 \\\\\n2 & si \\quad 35 &lt; age \\leq 45 \\\\\n3 & si \\quad 45 &lt; age  \\\\\n\\end{cases}\n\\end{array}\n\\]\n)\nDans la fenêtre de commande :\ngenr dummy1 = age &gt; 25\ngenr dummy2 = age &gt; 35\ngenr dummy3 = age &gt; 45\ngenr classes = dummy1 + dummy2 + dummy3\n\n\n\n\nOn réplique la méthode 2 des muettes :\n\ngenr classes = 0\n\nsmpl if condition1 → genr classes = 1 → smpl @all\n\nsmpl if condition2 → genr classes = 2 → smpl @all\n\netc.\n\n\n\n\n\n\n\n\n\nLe but des statistiques descriptives est de décrire les variables.\nÉtape cruciale pour :\n- connaître sa base,\n- avoir une première idée des relations existantes.\n\n\n\n\n\n\n\nÉtude d’une variable\nÉtude d’une relation entre variables\n\n\n\n\nTableaux : statistiques descriptives\nCoefficients de corrélation\n\n\nFigures : histogramme, boîte à moustache, évolution\nNuage de points, droite de régression\n\n\n\n\n\n\n\nOuvrir la fenêtre de la série (double-clic).\n\nTableau des principales statistiques :\nView → Descriptive statistics & Tests → Stats Table\nGraphiques : View → Graph\n\nHistogramme : distribution\nLine : courbe temporelle\nBoxplot : boîte à moustache\n\n\n\n\n\n\nTest d’égalité de moyennes :\nView → Descriptive statistics & Tests → Stats by classification\n- Choisir la modalité via Series/Group for classify.\nGraphiques par modalité :\n- Option Categorical graph dans Graph type.\n- Renseigner la modalité dans factors — series defining categories.\n\n\n\n\nOuvrir les séries ensemble : sélectionner les variables → Open → as Group.\n\nCoefficients de corrélation :\n\nView → Covariance analysis\nDans Statistics, choisir Correlation\n\nNuage de points :\nView → Graph → Scatter\n\nUtile : Fit Line → Regression line (droite de régression)\n\n\n\n\n\n\nExplorer les différents graphiques et choisir celui qui illustre le mieux votre propos.\n\nPour modifier le graphique : bouton Options (fenêtre du graphique)\n\nPour restreindre à un sous-échantillon : onglet Sample\n\n\n\n\n\nPour enregistrer les objets : Freeze et nommer (Name).\n\nTableaux : le plus simple → Copy (Ctrl+C) et coller dans Excel.\n\nGraphiques :\nProc → Copy to Clipboard (ou Ctrl+C)\nou Object → View Options → Copy to Clipboard\npuis coller dans un document Word (.doc).\n\n\n\n\n\n\n\n\n\n\nAfficher la réponse\n\nOn créer le fichier workfile et on fait : file → workfile et ensuite on fait\nfile → Import → import from file.\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Accidents = fatal + non_fatal\n\n\n\n\n\n\n\nAfficher la réponse\n\nCommande :\ngenr Acc_pass = Accidents / passagers\nUtilité : Rapporter le nombre d’accidents au nombre de passagers permet d’évaluer le risque d’accident par passager, offrant un indicateur plus précis de la sécurité des compagnies, indépendamment de leur taille. Autrement dit, cela permet d’évaluer de manière précise la probabilité d’accident par rapport au nombre total de passagers.\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Dummy_acc = accidents &gt;= 1\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Dummy_fatal = fatal &gt;= 1 genr Dummy_non_fatal = non_fatal &gt;= 1\n\n\n\n\n\n\n\nAfficher la réponse\n\nPour voir la distribution, on utilise un histogramme.\nDans EViews : on clique sur la variable passagers → View → Graph → Distribution → OK.\nPour copier-coller : Proc → Copy to Clipboard (ou Ctrl+C) ou Object → View Options → Copy to Clipboard, puis coller dans un document Word (.doc).\nL’histogramme montre une distribution asymétrique à droite, indiquant que la plupart des valeurs sont concentrées à gauche, tandis qu’il y a quelques valeurs élevées moins fréquentes à droite. Cet histogramme montre une distribution très asymétrique avec une concentration élevée des données à gauche, ce qui indique que la majorité des valeurs observées sont faibles. À l’inverse, on observe que les valeurs plus élevées sont rares, avec quelques points dispersés à droite (points aberrants).\n\n\n\n\n\n\nsi le pays a connu au moins un accident\nsi le pays a connu au moins un accident mortel.\n\n\n\nAfficher la réponse\n\nDans EViews :\n\nOuvrir la série passagers → View → Descriptive statistics & Tests → Stats by classification.\nDans Series/Group for classify, sélectionner la variable indiquant :\n\n(i) s’il y a eu au moins un accident,\n(ii) s’il y a eu au moins un accident mortel.\n\nValider pour obtenir les tableaux de statistiques et, si souhaité, les graphes par modalité (Graph type → Categorical graph).\n\nInterprétation : Comparer les statistiques (moyenne, médiane, etc.) et les graphiques permet de voir si le nombre de passagers transportés est distribué différemment selon qu’il y a eu un accident ou un accident mortel.\n\nOn observe généralement une différence nette des moyennes : les compagnies ayant connu un (ou un accident mortel) présentent en moyenne un volume de passagers plus élevé, ce qui suggère qu’elles sont plus grandes et donc exposées à un risque absolu d’accident plus important.\n\n\n\n\n\n\n\nAfficher la réponse\n\nCréation de l’âge : genr age = 2013 - annee\nCorrélation : sélectionner les deux variables en Group → View → Covariance analysis → Statistics = Correlation.\nOn a un coefficient de corrélation de -0,1709 qui indique une faible corrélation positive entre les deux variables étudiées (relation faible, peut ne pas être significative).\nNuage de points : sélectionner les deux variables → View → Graph → Scatter. Les points montent de gauche à droite (tendance conjointe) et des points qui s’écartent du nuage principal peuvent indiquer des valeurs aberrantes."
  },
  {
    "objectID": "td2/td2.html#gestion-de-la-base-de-données",
    "href": "td2/td2.html#gestion-de-la-base-de-données",
    "title": "Économétrie — TD 2",
    "section": "",
    "text": "Ces commandes se tapent dans la fenêtre de commande d’EViews.\n\n\n\n\n\n\n\n\nCommande\nDescription\nExemple\n\n\n\n\ngroup\nCréer un groupe de variables\ngroup nom x y\n\n\nscalar\nCréer un scalaire et faire des calculs\nscalar k = 3*6\n\n\nmatrix\nCréer une matrice et faire des calculs (matriciels)\n(cf. Help)\n\n\ngenr\nGénérer une variable\n(cf. plus bas)\n\n\nrename\nRenommer une variable\nrename x y (renomme x en y)\n\n\ndelete\nEffacer un ou plusieurs objets\ndelete x y\n\n\nsmpl\nSélectionner un sous-échantillon\nsmpl if x&lt;10\n\n\n\n\n\n\n\nVous êtes souvent amenés à créer de nouvelles variables ou à en changer l’échelle.\nIl existe deux types de variables :\n\nVariable continue\nprend n’importe quelle valeur sur un intervalle donné.\nVariable discrète\nne prend qu’un nombre fini de valeurs.\n\n\n\n\n\n\nNote\n\n\n\nNota : les variables binaires (0/1) sont un cas particulier.\n\n\n\n\n\n\n\nCommande générale :\n\ngenr nouveau_nom = opération\nEx. genr lnx = log(x)\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention : saisir la ligne de commande dans la fenêtre de commande.\n\n\n\n\n\n\n\n\n\nFormule mathématique\nEViews\n\n\n\n\n\\(x + a\\)\nx+a\n\n\n\\(x - a\\)\nx-a\n\n\n\\(x \\cdot a\\)\nx*a\n\n\n\\(x / a\\)\nx/a\n\n\n\\(x^a\\)\nx^a\n\n\n\\(\\ln(x)\\)\nlog(x)\n\n\n\\(e^x\\)\nexp(x)\n\n\n\n\n\n\n\nUne variable muette est discrète 0/1 (binaire).\nExemples : - (=1) si l’individu est une femme, (0) sinon. - (=1) si le pays est OCDE, (0) sinon.\nDeux méthodes :\n\n\n\n\ngenr nouveau = x &gt; A\nEx. jeune vaut 1 si âge \\(\\le\\) 25, 0 sinon :\ngenr jeune = age &lt;= 25\n\n\n\n\n\nObjectif : riche vaut 1 si pibtete &gt; 10000, 0 sinon.\n\ngenr riche = 0\n\nsmpl if pibtete &gt; 10000\n\ngenr riche = 1\n\nsmpl @all\n\n\n\n\n\n\nUne variable discrète prend un nombre limité de valeurs (0, 1, …, n).\n- Peut venir d’un classement (ex. classes de revenus).\n- Peut coder un choix limité (pays d’immigration, parti politique, notes…).\n\n\n\n\n\n\nNote\n\n\n\nRemarque : une muette est un cas particulier de discrète.\n\n\nDeux méthodes :\n\n\n\nExemple : classes d’âge (\n\\[\n\\begin{array}{l}\nclasses= \\begin{cases}\n0 & si \\quad age \\leq 25 \\\\\n1 & si \\quad 25 &lt; age \\leq 35 \\\\\n2 & si \\quad 35 &lt; age \\leq 45 \\\\\n3 & si \\quad 45 &lt; age  \\\\\n\\end{cases}\n\\end{array}\n\\]\n)\nDans la fenêtre de commande :\ngenr dummy1 = age &gt; 25\ngenr dummy2 = age &gt; 35\ngenr dummy3 = age &gt; 45\ngenr classes = dummy1 + dummy2 + dummy3\n\n\n\n\nOn réplique la méthode 2 des muettes :\n\ngenr classes = 0\n\nsmpl if condition1 → genr classes = 1 → smpl @all\n\nsmpl if condition2 → genr classes = 2 → smpl @all\n\netc."
  },
  {
    "objectID": "td2/td2.html#exploration-de-la-base-de-données",
    "href": "td2/td2.html#exploration-de-la-base-de-données",
    "title": "Économétrie — TD 2",
    "section": "",
    "text": "Le but des statistiques descriptives est de décrire les variables.\nÉtape cruciale pour :\n- connaître sa base,\n- avoir une première idée des relations existantes.\n\n\n\n\n\n\n\nÉtude d’une variable\nÉtude d’une relation entre variables\n\n\n\n\nTableaux : statistiques descriptives\nCoefficients de corrélation\n\n\nFigures : histogramme, boîte à moustache, évolution\nNuage de points, droite de régression\n\n\n\n\n\n\n\nOuvrir la fenêtre de la série (double-clic).\n\nTableau des principales statistiques :\nView → Descriptive statistics & Tests → Stats Table\nGraphiques : View → Graph\n\nHistogramme : distribution\nLine : courbe temporelle\nBoxplot : boîte à moustache\n\n\n\n\n\n\nTest d’égalité de moyennes :\nView → Descriptive statistics & Tests → Stats by classification\n- Choisir la modalité via Series/Group for classify.\nGraphiques par modalité :\n- Option Categorical graph dans Graph type.\n- Renseigner la modalité dans factors — series defining categories.\n\n\n\n\nOuvrir les séries ensemble : sélectionner les variables → Open → as Group.\n\nCoefficients de corrélation :\n\nView → Covariance analysis\nDans Statistics, choisir Correlation\n\nNuage de points :\nView → Graph → Scatter\n\nUtile : Fit Line → Regression line (droite de régression)\n\n\n\n\n\n\nExplorer les différents graphiques et choisir celui qui illustre le mieux votre propos.\n\nPour modifier le graphique : bouton Options (fenêtre du graphique)\n\nPour restreindre à un sous-échantillon : onglet Sample\n\n\n\n\n\nPour enregistrer les objets : Freeze et nommer (Name).\n\nTableaux : le plus simple → Copy (Ctrl+C) et coller dans Excel.\n\nGraphiques :\nProc → Copy to Clipboard (ou Ctrl+C)\nou Object → View Options → Copy to Clipboard\npuis coller dans un document Word (.doc).\n\n\n\n\n\n\n\n\n\n\nAfficher la réponse\n\nOn créer le fichier workfile et on fait : file → workfile et ensuite on fait\nfile → Import → import from file.\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Accidents = fatal + non_fatal\n\n\n\n\n\n\n\nAfficher la réponse\n\nCommande :\ngenr Acc_pass = Accidents / passagers\nUtilité : Rapporter le nombre d’accidents au nombre de passagers permet d’évaluer le risque d’accident par passager, offrant un indicateur plus précis de la sécurité des compagnies, indépendamment de leur taille. Autrement dit, cela permet d’évaluer de manière précise la probabilité d’accident par rapport au nombre total de passagers.\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Dummy_acc = accidents &gt;= 1\n\n\n\n\n\n\n\nAfficher la réponse\n\ngenr Dummy_fatal = fatal &gt;= 1 genr Dummy_non_fatal = non_fatal &gt;= 1\n\n\n\n\n\n\n\nAfficher la réponse\n\nPour voir la distribution, on utilise un histogramme.\nDans EViews : on clique sur la variable passagers → View → Graph → Distribution → OK.\nPour copier-coller : Proc → Copy to Clipboard (ou Ctrl+C) ou Object → View Options → Copy to Clipboard, puis coller dans un document Word (.doc).\nL’histogramme montre une distribution asymétrique à droite, indiquant que la plupart des valeurs sont concentrées à gauche, tandis qu’il y a quelques valeurs élevées moins fréquentes à droite. Cet histogramme montre une distribution très asymétrique avec une concentration élevée des données à gauche, ce qui indique que la majorité des valeurs observées sont faibles. À l’inverse, on observe que les valeurs plus élevées sont rares, avec quelques points dispersés à droite (points aberrants).\n\n\n\n\n\n\nsi le pays a connu au moins un accident\nsi le pays a connu au moins un accident mortel.\n\n\n\nAfficher la réponse\n\nDans EViews :\n\nOuvrir la série passagers → View → Descriptive statistics & Tests → Stats by classification.\nDans Series/Group for classify, sélectionner la variable indiquant :\n\n(i) s’il y a eu au moins un accident,\n(ii) s’il y a eu au moins un accident mortel.\n\nValider pour obtenir les tableaux de statistiques et, si souhaité, les graphes par modalité (Graph type → Categorical graph).\n\nInterprétation : Comparer les statistiques (moyenne, médiane, etc.) et les graphiques permet de voir si le nombre de passagers transportés est distribué différemment selon qu’il y a eu un accident ou un accident mortel.\n\nOn observe généralement une différence nette des moyennes : les compagnies ayant connu un (ou un accident mortel) présentent en moyenne un volume de passagers plus élevé, ce qui suggère qu’elles sont plus grandes et donc exposées à un risque absolu d’accident plus important.\n\n\n\n\n\n\n\nAfficher la réponse\n\nCréation de l’âge : genr age = 2013 - annee\nCorrélation : sélectionner les deux variables en Group → View → Covariance analysis → Statistics = Correlation.\nOn a un coefficient de corrélation de -0,1709 qui indique une faible corrélation positive entre les deux variables étudiées (relation faible, peut ne pas être significative).\nNuage de points : sélectionner les deux variables → View → Graph → Scatter. Les points montent de gauche à droite (tendance conjointe) et des points qui s’écartent du nuage principal peuvent indiquer des valeurs aberrantes."
  },
  {
    "objectID": "td2/td2-correction.html",
    "href": "td2/td2-correction.html",
    "title": "TD 2 — Correction & rappels théoriques",
    "section": "",
    "text": "Accidents = fatal + non_fatal\n\nAcc_pass = Accidents / passagers ; Dummy_acc = (Accidents &gt;= 1)\n\nDummies séparées : Dummy_fatal, Dummy_non_fatal\n\nDistribution de passagers : histogramme (souvent asymétrie à droite)"
  },
  {
    "objectID": "td2/td2-correction.html#préparation",
    "href": "td2/td2-correction.html#préparation",
    "title": "TD 2 — Correction & rappels théoriques",
    "section": "",
    "text": "Accidents = fatal + non_fatal\n\nAcc_pass = Accidents / passagers ; Dummy_acc = (Accidents &gt;= 1)\n\nDummies séparées : Dummy_fatal, Dummy_non_fatal\n\nDistribution de passagers : histogramme (souvent asymétrie à droite)"
  },
  {
    "objectID": "td2/td2-correction.html#estimation-mco",
    "href": "td2/td2-correction.html#estimation-mco",
    "title": "TD 2 — Correction & rappels théoriques",
    "section": "Estimation MCO",
    "text": "Estimation MCO\n\nModèle log-linéaire : logpassagers ~ (ratio / fatal/passagers / non_fatal/passagers) + contrôles\n\nInterprétation : coefficients ⇒ variations % de passagers"
  },
  {
    "objectID": "td2/td2-correction.html#tests",
    "href": "td2/td2-correction.html#tests",
    "title": "TD 2 — Correction & rappels théoriques",
    "section": "Tests",
    "text": "Tests\n\nStudent (t) : H0: coefficient = 0 → décision via |t| vs t_critique (table)\n\nFisher (F) : significativité conjointe de plusieurs coefficients (ddl: q, N−p)\n\nR² / R² ajusté : pouvoir explicatif (attention à l’ajout mécanique de variables)"
  },
  {
    "objectID": "td2/td2-correction.html#importance-économique",
    "href": "td2/td2-correction.html#importance-économique",
    "title": "TD 2 — Correction & rappels théoriques",
    "section": "Importance économique",
    "text": "Importance économique\n\nCoefficients standardisés (View → Coefficients diagnostics → Scaled)\n\nVariable saillante (souvent intercontinental) : interprétation en % si Y en log\n\n\n\n\n\n\n\nImportant\n\n\n\nTables statistiques : utiliser tables de Student & Fisher (pas de p-values en TD)."
  },
  {
    "objectID": "td1/td1-slides.html#corrélation-et-causalité",
    "href": "td1/td1-slides.html#corrélation-et-causalité",
    "title": "Économétrie — TD 1",
    "section": "2.1 Corrélation et causalité",
    "text": "2.1 Corrélation et causalité\nCorrélation n’est pas synonyme de causalité, or l’économétrie ne mesure que des corrélations!\n\n\n\n\n\n\nNote\n\n\nPreuve, ce site web (cliquer si temps disponible)"
  },
  {
    "objectID": "td1/td1-slides.html#principe-de-léconométrie",
    "href": "td1/td1-slides.html#principe-de-léconométrie",
    "title": "Économétrie — TD 1",
    "section": "2.2 Principe de l’économétrie",
    "text": "2.2 Principe de l’économétrie\nPrincipe : Vous disposez d’une variable à expliquer (le nombre de buts) et d’une [ou plusieurs] variable[s] explicative[s] (poste du joueur, taille, club) et vous essayez de savoir s’il existe une relation entre celles-ci.\n\n\n\n\n\n\nTip\n\n\nAvec un apport théorique préalable, une corrélation peut être suspectée de causale.\n\n\n\nCours:\n▶ Présentation des concepts en CM (M. Brun)\n▶ Mise en pratique sur EViews en TD"
  },
  {
    "objectID": "td1/td1-slides.html#plan-du-cours",
    "href": "td1/td1-slides.html#plan-du-cours",
    "title": "Économétrie — TD 1",
    "section": "2.3 Plan du cours",
    "text": "2.3 Plan du cours\nNos séances de TD :\n▶ TD 1 : Présentation et prise en main d’EViews\n▶ TD 2 : Gestion et explorations de la base de données\n▶ TD 3 : Modèle linéaire (MCO) et conditions de validité.\n▶ TD 4 : Tests d’hypothèses économétriques : homoscédasticité (Goldfeld–Quandt, Breusch–Pagan, White) et corrections pour l’hétéroscédasticité (White).\n▶ TD 5 : Tests d’hypothèses économiques : stabilité des coefficients et pertinence de l’estimation & autocorrélation.\n▶ TD 6 : Variables instrumentales (2SLS) : identification, exogénéité et instrumentation (test de Hausman — principe Nakamura & Nakamura).\n▶ TD 7: Variables instrumentales (2SLS) : avancé.\n▶ TD 8 : Normalité des erreurs : normalité (Jarque–Bera).\n▶ TD 9: Simulation de Monte Carlo."
  },
  {
    "objectID": "td1/td1-slides.html#les-données-utilisées-en-économétrie",
    "href": "td1/td1-slides.html#les-données-utilisées-en-économétrie",
    "title": "Économétrie — TD 1",
    "section": "2.4 Les données utilisées en économétrie",
    "text": "2.4 Les données utilisées en économétrie\n\n\nLes données utilisées en économétrie sont de trois types :\n1. Données transversales :\nDonnées sur plusieurs individus à un instant donné\n2. Données temporelles :\nDonnées sur un seul individu à des périodes différentes\n3. Données de panel :\nDonnées enregistrées pour différents individus à différentes périodes\n\n\n\n\n\n\n\n\nImportant\n\n\nDans le cadre de ce cours, nous travaillerons uniquement sur des données transversales."
  },
  {
    "objectID": "td1/td1-slides.html#eviews-environnement",
    "href": "td1/td1-slides.html#eviews-environnement",
    "title": "Économétrie — TD 1",
    "section": "3.1 EViews — Environnement",
    "text": "3.1 EViews — Environnement\nEViews est un logiciel développé par Quantitative Micro Software\nIl existe de nombreux autres logiciels d’économétrie.\n\nLes plus utilisés sont stata ou R\n\nAvantages d’EViews :\n▶ Simple d’utilisation (fonctionnement avec une interface)\n▶ Performant pour les séries temporelles\nInconvénients :\n▶ Il s’agit uniquement d’un logiciel d’économétrie\nLa traitement de données doit être fait au préalable\n▶ Peu flexible"
  },
  {
    "objectID": "td1/td1-slides.html#environnement-et-logique-de-fonctionnement",
    "href": "td1/td1-slides.html#environnement-et-logique-de-fonctionnement",
    "title": "Économétrie — TD 1",
    "section": "3.2 Environnement et logique de fonctionnement",
    "text": "3.2 Environnement et logique de fonctionnement"
  },
  {
    "objectID": "td1/td1-slides.html#environnement-et-logique-de-fonctionnement-1",
    "href": "td1/td1-slides.html#environnement-et-logique-de-fonctionnement-1",
    "title": "Économétrie — TD 1",
    "section": "3.3 Environnement et logique de fonctionnement",
    "text": "3.3 Environnement et logique de fonctionnement\nTrois manières de travailler sous EViews :\n\n1. Par l’interface graphique\n2. En rentrant le nom de la commande dans la fenêtre de commande\n3. En regroupant les commandes dans un programme\n\n\n\n\n\n\n\nImportant\n\n\nDans le cadre de ce cours, nous utiliserons les deux premières méthodes"
  },
  {
    "objectID": "td1/td1-slides.html#les-différents-types-de-fichiers",
    "href": "td1/td1-slides.html#les-différents-types-de-fichiers",
    "title": "Économétrie — TD 1",
    "section": "3.4 Les différents types de fichiers",
    "text": "3.4 Les différents types de fichiers\n\nFichier texte (.txt) ou Excel (.xls) : contient la base de données\nFichier workfile (.wf1) : enregistre le travail\nFichier programme (.prg) : enregistre le programme (non utilisé ici)"
  },
  {
    "objectID": "td1/td1-slides.html#les-différents-types-dobjets",
    "href": "td1/td1-slides.html#les-différents-types-dobjets",
    "title": "Économétrie — TD 1",
    "section": "3.5 Les différents types d’objets",
    "text": "3.5 Les différents types d’objets\nUn objet est un élément stockant différents types d’informations, rassemblés dans le workfile.\nDouble-cliquer sur l’icône pour l’ouvrir.\n\nObjets les plus fréquents :\n\nVariables numériques\nListe d’éléments en texte\nÉquation\nGraphique\nCoefficients et résidus estimés\nScalaire et matrices"
  },
  {
    "objectID": "td1/td1-slides.html#création-du-workfile-.wf1",
    "href": "td1/td1-slides.html#création-du-workfile-.wf1",
    "title": "Économétrie — TD 1",
    "section": "3.6 Création du workfile (.wf1)",
    "text": "3.6 Création du workfile (.wf1)\nPremière étape avant d’importer une base de données.\nMenu : File → New → Workfile\n\nTrois structures possibles :\n\nUnstructured/Undated (données transversales)\nDated–regular frequency (données temporelles)\nBalanced Panel (données de panel)\n\nNoms des paramètres:\n\nData Range : nombre d’observations (ex. nombre de pays) - Frequency : fréquence des données (annuelle, …)\nStart date : date initiale (ex. 1970)\nEnd date : date de fin (ex. 2008)\nFrequency, Start date, End date : cf. ci-dessus\nNumber of Cross-section : nombre d’individus"
  },
  {
    "objectID": "td1/td1-slides.html#création-du-workfile-.wf1-1",
    "href": "td1/td1-slides.html#création-du-workfile-.wf1-1",
    "title": "Économétrie — TD 1",
    "section": "3.7 Création du workfile (.wf1)",
    "text": "3.7 Création du workfile (.wf1)\nModules optionnels :\n\nName : nom du workfile\nPage : numéro de page\n\nSauvegarde :\n\nPremière sauvegarde :\nFile → Save as - Ensuite : File → Save ou Ctrl+S\nOuvrir un workfile existant :\nFile → Open → Workfile →Choisir le fichier à ouvrir"
  },
  {
    "objectID": "td1/td1-slides.html#importation-de-données",
    "href": "td1/td1-slides.html#importation-de-données",
    "title": "Économétrie — TD 1",
    "section": "3.8 Importation de données",
    "text": "3.8 Importation de données\n\n\n\n\n\n\nCaution\n\n\nPréalable : Seules les données sont acceptées (le fichier Excel ne doit pas contenir de formules).\n\nProcédure:\n\nFermer la feuille Excel\nFile → Import → Import from file\nSélectionner le fichier (base de données)\n\nUne première fenêtre s’ouvre :\n\nPredefined Range : aucun changement\nCustom range : pour modifier la feuille, la première et la dernière cellule\n\n\nPuis une deuxième fenêtre permet de modifier :\n\nNb de lignes définissant le statut (Column headers)\nNom et type des variables et leurs labels (Column info)\n\nUne troisième fenêtre offre des opérations plus complexes (lier différentes bases de données).\nTerminer puis sauvegarder le workfile (File → Save ou Ctrl+S)."
  },
  {
    "objectID": "td1/td1-slides.html#création-du-workfile-et-importation-en-une-étape",
    "href": "td1/td1-slides.html#création-du-workfile-et-importation-en-une-étape",
    "title": "Économétrie — TD 1",
    "section": "3.9 Création du workfile et importation en une étape",
    "text": "3.9 Création du workfile et importation en une étape\nPossible via : File → Open → Foreign Data as Workfile\nAvantage :\n\nGain de temps\n\nInconvénient :\n\nLa base doit être parfaitement préparée."
  },
  {
    "objectID": "td1/td1-slides.html#q.0.1-types-de-données-en-économétrie",
    "href": "td1/td1-slides.html#q.0.1-types-de-données-en-économétrie",
    "title": "Économétrie — TD 1",
    "section": "4.1 Q.0.1 — Types de données en économétrie",
    "text": "4.1 Q.0.1 — Types de données en économétrie\nQuestion : Quelles sont les trois grandes catégories de données ?\n\n\nAfficher la réponse\n\n\nTransversales : plusieurs individus, une date donnée.\nTemporelles : une unité observée sur plusieurs dates.\nPanel : plusieurs individus suivis sur plusieurs dates."
  },
  {
    "objectID": "td1/td1-slides.html#q.0.2-corrélation-et-causalité",
    "href": "td1/td1-slides.html#q.0.2-corrélation-et-causalité",
    "title": "Économétrie — TD 1",
    "section": "4.2 Q.0.2 — Corrélation et causalité",
    "text": "4.2 Q.0.2 — Corrélation et causalité\nQuestion : La corrélation implique-t-elle une causalité ?\n\n\nAfficher la réponse\n\nNon.\n- Corrélation : deux variables évoluent ensemble.\n- Causalité : une variable provoque l’évolution de l’autre.\nExemple : Fumer ↦ augmentation du risque de cancer du poumon."
  },
  {
    "objectID": "td1/td1-slides.html#q1-création-du-workfile",
    "href": "td1/td1-slides.html#q1-création-du-workfile",
    "title": "Économétrie — TD 1",
    "section": "4.3 Q1 — Création du Workfile",
    "text": "4.3 Q1 — Création du Workfile\nQuestion : Comment créer un workfile pour accueillir des données transversales dans EViews ?\n\n\nAfficher la réponse\n\n\nMenu File → New → Workfile\n\nChoisir Unstructured / Undated\n\nIndiquer le nombre d’observations (ex. 94)\n\nFile → Save as pour enregistrer."
  },
  {
    "objectID": "td1/td1-slides.html#q2-importation-de-données-excel",
    "href": "td1/td1-slides.html#q2-importation-de-données-excel",
    "title": "Économétrie — TD 1",
    "section": "4.4 Q2 — Importation de données Excel",
    "text": "4.4 Q2 — Importation de données Excel\nQuestion : Quelle est la procédure pour importer un fichier Excel dans EViews ?\n\n\nAfficher la réponse\n\n\nFermer le fichier Excel.\n\nDans EViews : File → Import → Import from file.\n\nSélectionner le fichier TD1.xls.\n\nVérifier la plage de données puis valider.\n\nSauvegarder le workfile."
  },
  {
    "objectID": "td1/td1-slides.html#q3-nature-des-variables",
    "href": "td1/td1-slides.html#q3-nature-des-variables",
    "title": "Économétrie — TD 1",
    "section": "4.5 Q3 — Nature des variables",
    "text": "4.5 Q3 — Nature des variables\nQuestion : Pourquoi la variable Compagnie apparaît en texte? La variable Public ?\n\n\nAfficher la réponse\n\n\nCompagnie : variable qualitative nominale (noms de compagnies).\nPublic : variable binaire (oui/non)"
  },
  {
    "objectID": "td1/td1-slides.html#q4-modifier-la-base",
    "href": "td1/td1-slides.html#q4-modifier-la-base",
    "title": "Économétrie — TD 1",
    "section": "4.6 Q4 — Modifier la base",
    "text": "4.6 Q4 — Modifier la base\nQuestion : Faites les modifications nécessaires afin de rendre la base de données exploitable.\n\n\nAfficher la réponse\n\n\nPublic : variable binaire (oui/non) ⇒ à recoder en 0/1 si nécessaire.\n\ngenr dummy_public = @recode(public=\"yes\", 1, 0)\n\nIndice : Regarder la variable intercontinental."
  },
  {
    "objectID": "guidance.html",
    "href": "guidance.html",
    "title": "Syllabus — Introduction à l’économétrie appliquée",
    "section": "",
    "text": "1 Pour les enseignants\nCe document présente l’organisation et les objectifs du cours Introduction à l’économétrie appliquée (niveau Licence 3 – École d’Économie, Université Clermont Auvergne). Il peut servir de guide à tout enseignant souhaitant reprendre ou adapter ce cours.\nNiveau et volume horaire\n- Public : étudiants de 3ᵉ année de licence d’économie (L3)\n- Volume : 30 heures d’enseignement (cours + TD)\nObjectifs pédagogiques\n- Introduire les principaux outils de l’économétrie moderne pour l’analyse de données économiques.\n- Familiariser les étudiants avec l’estimation et la validation de modèles économétriques simples.\n- Préparer à des applications concrètes en recherche ou en analyse de politiques publiques.\nPlan indicatif\n1. Rôle de l’économétrie dans la science économique et rappel sur les estimateurs statistiques.\n2. Manipulation de données et statistiques descriptives\n3. Modèle linéaire (MCO) et conditions de validité.\n4. Tests usuels : homoscédasticité (Goldfeld–Quandt, Breusch–Pagan, White) et corrections pour l’hétéroscédasticité (White).\n5. Séries temporelles : autocorrélation (Durbin–Watson, Breusch–Godfrey) et sa correction (Cochrane–Orcutt), test COMFAC.\n6. Variables instrumentales (2SLS) : identification, exogénéité et instrumentation (test de Hausman — principe Nakamura & Nakamura).\n7. Variables instrumentales (2SLS) : suite et sur-identification (test de Sargan)\n8. Normalité des erreurs : normalité (Jarque–Bera).\n9. Simulation de Monte Carlo.\nRéférences principales\n- Araujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\n- Wooldridge (2009), Introductory Econometrics.\n- Greene (2008), Econometric Analysis.\n\n\n\n2 Pour les étudiants\nCe cours de 30 heures constitue une introduction pratique à l’économétrie, c’est-à-dire l’ensemble des outils statistiques permettant de tester des théories économiques ou d’analyser des données réelles.\n\nCe que vous apprendrez\n\nComprendre le rôle de l’économétrie dans la démarche scientifique économique.\nEstimer un modèle linéaire à l’aide de la méthode des moindres carrés ordinaires (MCO).\nVérifier les hypothèses de validité d’un modèle à l’aide de différents tests statistiques : normalité, autocorrélation, homoscédasticité, exogénéité\nUtiliser des méthodes plus avancées si les hypothèses de base sont violées : Moindres Carrés Généralisés, corrections de White ou Cochrane–Orcutt.\nMettre en œuvre des variables instrumentales (2SLS) et interpréter les tests de sur-identification (Sargan).\nIntroduire des variables muettes et des termes polynomiaux pour modéliser des effets non linéaires.\nDécouvrir les simulations de Monte Carlo comme outil d’évaluation de méthodes économétriques.\n\nOrganisation type\n\nCours magistraux complétés de travaux dirigés où vous manipulerez de vraies données.\nLectures recommandées :\n\n\nAraujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\nWooldridge (2009), Introductory Econometrics.\nGreene (2008), Econometric Analysis.\n\n\n\n\nEn suivant ce cours, vous acquerrez les bases théoriques et pratiques pour appliquer l’économétrie dans vos futurs projets d’études ou de recherche."
  },
  {
    "objectID": "site.html",
    "href": "site.html",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Bienvenue sur le site du cours Introduction à l’économétrie appliquée dispensé en Licence 3 – École d’Économie (Université Clermont Auvergne).\nCe site rassemble toutes les ressources nécessaires pour suivre le cours : syllabus, supports de TD, corrigés, jeux de données et références bibliographiques.\n\n\n\nCe cours initie les étudiants aux méthodes économétriques de base utilisées en analyse économique.\nÀ l’issue de la formation, vous serez capable de :\n\nEstimer un modèle de régression linéaire et en interpréter les résultats ;\nVérifier les hypothèses classiques (normalité, homoscédasticité, autocorrélation, exogénéité) à l’aide de tests statistiques (t, F, Jarque–Bera, Durbin–Watson, Breusch–Godfrey, Breusch–Pagan, White, Hausman) ;\nCorriger les problèmes rencontrés (Moindres Carrés Généralisés, corrections de White, Cochrane–Orcutt) ;\nMettre en œuvre les variables instrumentales (2SLS) et interpréter les tests de sur-identification (Sargan) .\n\n\n\n\n\n\nVolume horaire : 30 heures (cours + TD)\nPrérequis : bases de statistique (estimateurs, intervalles de confiance)\nModalités :\n\nCours magistraux.\nTravaux dirigés en salle informatique avec manipulation de données réelles.\nÉvaluation : examen final.\n\n\n\n\n\n\n\nSyllabus complet\nNotes de cours et diapositives disponibles après chaque séance.\nSlides de rappel de cours et réponses aux questions dans la section TD.\n\n\n\n\n\n\nAraujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\nWooldridge (2009), Introductory Econometrics.\nGreene (2008), Econometric Analysis.\n\n\n\n\n\n\nInstallez EViews (ou un logiciel équivalent) pour pouvoir reproduire les exemples.\nTéléchargez les fichiers de données sur l’ent.\nParcourez le syllabus pour connaître les objectifs, le plan du cours et les lectures recommandées."
  },
  {
    "objectID": "site.html#objectif-du-cours",
    "href": "site.html#objectif-du-cours",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Ce cours initie les étudiants aux méthodes économétriques de base utilisées en analyse économique.\nÀ l’issue de la formation, vous serez capable de :\n\nEstimer un modèle de régression linéaire et en interpréter les résultats ;\nVérifier les hypothèses classiques (normalité, homoscédasticité, autocorrélation, exogénéité) à l’aide de tests statistiques (t, F, Jarque–Bera, Durbin–Watson, Breusch–Godfrey, Breusch–Pagan, White, Hausman) ;\nCorriger les problèmes rencontrés (Moindres Carrés Généralisés, corrections de White, Cochrane–Orcutt) ;\nMettre en œuvre les variables instrumentales (2SLS) et interpréter les tests de sur-identification (Sargan) ."
  },
  {
    "objectID": "site.html#organisation",
    "href": "site.html#organisation",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Volume horaire : 30 heures (cours + TD)\nPrérequis : bases de statistique (estimateurs, intervalles de confiance)\nModalités :\n\nCours magistraux.\nTravaux dirigés en salle informatique avec manipulation de données réelles.\nÉvaluation : examen final."
  },
  {
    "objectID": "site.html#ressources",
    "href": "site.html#ressources",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Syllabus complet\nNotes de cours et diapositives disponibles après chaque séance.\nSlides de rappel de cours et réponses aux questions dans la section TD."
  },
  {
    "objectID": "site.html#références-principales",
    "href": "site.html#références-principales",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Araujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\nWooldridge (2009), Introductory Econometrics.\nGreene (2008), Econometric Analysis."
  },
  {
    "objectID": "site.html#pour-bien-démarrer",
    "href": "site.html#pour-bien-démarrer",
    "title": "Introduction à l’économétrie appliquée — Accueil",
    "section": "",
    "text": "Installez EViews (ou un logiciel équivalent) pour pouvoir reproduire les exemples.\nTéléchargez les fichiers de données sur l’ent.\nParcourez le syllabus pour connaître les objectifs, le plan du cours et les lectures recommandées."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus — Introduction à l’économétrie appliquée",
    "section": "",
    "text": "1 Pour les enseignants\nCe document présente l’organisation et les objectifs du cours Introduction à l’économétrie appliquée (niveau Licence 3 – École d’Économie, Université Clermont Auvergne). Il peut servir de guide à tout enseignant souhaitant reprendre ou adapter ce cours.\nNiveau et volume horaire\n- Public : étudiants de 3ᵉ année de licence d’économie (L3)\n- Volume : 30 heures d’enseignement (cours + TD)\nObjectifs pédagogiques\n- Introduire les principaux outils de l’économétrie moderne pour l’analyse de données économiques.\n- Familiariser les étudiants avec l’estimation et la validation de modèles économétriques simples.\n- Préparer à des applications concrètes en recherche ou en analyse de politiques publiques.\nPlan indicatif\n▶ TD 1 : Présentation et prise en main d’EViews\n▶ TD 2 : Gestion et explorations de la base de données\n▶ TD 3 : Modèle linéaire (MCO) et conditions de validité.\n▶ TD 4 : Tests d’hypothèses économétriques : homoscédasticité (Goldfeld–Quandt, Breusch–Pagan, White) et corrections pour l’hétéroscédasticité (White).\n▶ TD 5 : Tests d’hypothèses économiques : stabilité des coefficients et pertinence de l’estimation & autocorrélation.\n▶ TD 6 : Variables instrumentales (2SLS) : identification, exogénéité et instrumentation (test de Hausman — principe Nakamura & Nakamura).\n▶ TD 7: Variables instrumentales (2SLS) : avancé.\n▶ TD 8 : Normalité des erreurs : normalité (Jarque–Bera).\n▶ TD 9: Simulation de Monte Carlo.\nRéférences principales\n- Araujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\n- Wooldridge (2009), Introductory Econometrics.\n- Greene (2008), Econometric Analysis.\n\n\n\n2 Pour les étudiants\nCe cours de 30 heures constitue une introduction pratique à l’économétrie, c’est-à-dire l’ensemble des outils statistiques permettant de tester des théories économiques ou d’analyser des données réelles.\n\nCe que vous apprendrez\n\nComprendre le rôle de l’économétrie dans la démarche scientifique économique.\nEstimer un modèle linéaire à l’aide de la méthode des moindres carrés ordinaires (MCO).\nVérifier les hypothèses de validité d’un modèle à l’aide de différents tests statistiques : normalité, autocorrélation, homoscédasticité, exogénéité\nUtiliser des méthodes plus avancées si les hypothèses de base sont violées : Moindres Carrés Généralisés, corrections de White ou Cochrane–Orcutt.\nMettre en œuvre des variables instrumentales (2SLS) et interpréter les tests de sur-identification (Sargan).\nIntroduire des variables muettes et des termes polynomiaux pour modéliser des effets non linéaires.\nDécouvrir les simulations de Monte Carlo comme outil d’évaluation de méthodes économétriques.\n\nOrganisation type\n\nCours magistraux complétés de travaux dirigés où vous manipulerez de vraies données.\nLectures recommandées :\n\n\nAraujo, Brun & Combes (2008), Économétrie, Bréal — chapitres 1–2.\nWooldridge (2009), Introductory Econometrics.\nGreene (2008), Econometric Analysis.\n\n\n\n\nEn suivant ce cours, vous acquerrez les bases théoriques et pratiques pour appliquer l’économétrie dans vos futurs projets d’études ou de recherche."
  },
  {
    "objectID": "td1/td1-correction.html",
    "href": "td1/td1-correction.html",
    "title": "TD 1 — Correction & explications",
    "section": "",
    "text": "Formuler une hypothèse → modéliser → tester sur données."
  },
  {
    "objectID": "td1/td1-correction.html#méthode-hypothéticodéductive",
    "href": "td1/td1-correction.html#méthode-hypothéticodéductive",
    "title": "TD 1 — Correction & explications",
    "section": "",
    "text": "Formuler une hypothèse → modéliser → tester sur données."
  },
  {
    "objectID": "td1/td1-correction.html#rappels-utiles",
    "href": "td1/td1-correction.html#rappels-utiles",
    "title": "TD 1 — Correction & explications",
    "section": "Rappels utiles",
    "text": "Rappels utiles\n\nCorrélation ≠ causalité\nVariables : quantitatives (continues/discrètes), qualitatives (nominales/ordinaires), binaires\nTypes de données : transversales, temporelles, panel"
  },
  {
    "objectID": "td1/td1-correction.html#correction-synthétique",
    "href": "td1/td1-correction.html#correction-synthétique",
    "title": "TD 1 — Correction & explications",
    "section": "Correction synthétique",
    "text": "Correction synthétique\n\nWorkfile (94 obs.) → File → New → Workfile ; enregistrer tôt (Save as).\n\nImport TD1.xls → File → Import → Import from file (Excel fermé).\n\nNettoyage / recodage\n\nCompagnie est texte (nominale) → OK\nPublic (yes/no) → créer dummy_public = @recode(public=\"yes\",1,0)\nAutres corrections mineures selon la base (ex. Intercontinental)\n\n\n\n\n\n\n\n\nNote\n\n\n\nAstuce : File → Open → Foreign Data as Workfile (création + import en 1 étape) si la base est propre."
  },
  {
    "objectID": "td1/td1.html",
    "href": "td1/td1.html",
    "title": "Économétrie — TD 1",
    "section": "",
    "text": "L’économétrie s’inscrit dans une démarche scientifique dite hypothético-déductive, telle que l’a définie Karl Popper.\nCette démarche comporte trois étapes :\n\nModélisation : formuler une théorie économique et la traduire sous forme de modèle.\nVérification empirique : utiliser l’économétrie pour confronter le modèle aux données.\nValidation ou révision : confirmer ou modifier la théorie selon les résultats.\n\n\nEn pratique, l’économétrie est une méthode d’analyse des données économiques qui, grâce aux outils de la statistique et des mathématiques, permet de mettre en évidence les relations entre variables.\nElle poursuit plusieurs objectifs :\n\ntester la véracité empirique d’une théorie ;\nprévoir l’évolution d’un phénomène économique ;\nestimer la valeur des paramètres d’un modèle théorique."
  },
  {
    "objectID": "td1/td1.html#organisation-des-td",
    "href": "td1/td1.html#organisation-des-td",
    "title": "Économétrie — TD 1",
    "section": "3.1 Organisation des TD",
    "text": "3.1 Organisation des TD\nLe cycle de TD se déroule en plusieurs séances :\n▶ TD 1 : Présentation et prise en main d’EViews\n▶ TD 2 : Gestion et explorations de la base de données\n▶ TD 3 : Modèle linéaire (MCO) et conditions de validité.\n▶ TD 4 : Tests d’hypothèses économétriques : homoscédasticité (Goldfeld–Quandt, Breusch–Pagan, White) et corrections pour l’hétéroscédasticité (White).\n▶ TD 5 : Tests d’hypothèses économiques : stabilité des coefficients et pertinence de l’estimation & autocorrélation.\n▶ TD 6 : Variables instrumentales (2SLS) : identification, exogénéité et instrumentation (test de Hausman — principe Nakamura & Nakamura).\n▶ TD 7: Variables instrumentales (2SLS) : avancé.\n▶ TD 8 : Normalité des erreurs : normalité (Jarque–Bera).\n▶ TD 9: Simulation de Monte Carlo."
  },
  {
    "objectID": "td1/td1.html#types-de-données-en-économétrie",
    "href": "td1/td1.html#types-de-données-en-économétrie",
    "title": "Économétrie — TD 1",
    "section": "3.2 Types de données en économétrie",
    "text": "3.2 Types de données en économétrie\nLes données utilisées peuvent être de trois grands types :\n\nDonnées transversales : observations sur plusieurs individus à un instant donné (ex. : un ensemble de pays en 2024).\nDonnées temporelles : observations sur un même individu ou pays à plusieurs dates.\nDonnées de panel : combinaison des deux précédentes, plusieurs individus observés sur plusieurs périodes.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDans le cadre de ce premier TD, nous travaillerons uniquement sur des données transversales."
  },
  {
    "objectID": "td1/td1.html#le-logiciel-eviews",
    "href": "td1/td1.html#le-logiciel-eviews",
    "title": "Économétrie — TD 1",
    "section": "3.3 Le logiciel EViews",
    "text": "3.3 Le logiciel EViews\nEViews est un logiciel d’économétrie développé par Quantitative Micro Software.\nParmi les autres logiciels largement utilisés, on peut citer Stata, R, Rats, Matlab, ou encore Limdep.\n\n3.3.1 Avantages\n\nInterface graphique simple d’utilisation ;\nPerformant pour l’analyse de séries temporelles.\n\n\n\n3.3.2 Inconvénients\n\nLogiciel spécialisé uniquement en économétrie ;\nNécessite un pré-traitement des données (peu flexible pour la manipulation de bases)."
  },
  {
    "objectID": "td1/td1.html#travailler-sous-eviews",
    "href": "td1/td1.html#travailler-sous-eviews",
    "title": "Économétrie — TD 1",
    "section": "3.4 Travailler sous EViews",
    "text": "3.4 Travailler sous EViews\n\n3.4.1 Environnement et logique de fonctionnement\nOn peut travailler sous EViews de trois manières :\n\nInterface graphique : menus et fenêtres.\nFenêtre de commande : en tapant directement les instructions.\nProgramme (.prg) : regroupement des commandes dans un script.\n\nDans ce TD, nous utiliserons surtout les deux premières méthodes, plus intuitives.\n\n\n3.4.2 Types de fichiers\n\nFichier texte (.txt) ou Excel (.xls) : contient la base de données d’origine.\nFichier workfile (.wf1) : enregistre votre travail et vos objets EViews.\nFichier programme (.prg) : stocke des commandes, non utilisé dans ce TD.\n\n\n\n3.4.3 Types d’objets\nDans un workfile, on trouve différents objets :\nvariables numériques, listes de texte, équations, graphiques, coefficients et résidus estimés, scalaires et matrices.\nPour consulter un objet, il suffit de double-cliquer sur son icône."
  },
  {
    "objectID": "td1/td1.html#création-dun-workfile",
    "href": "td1/td1.html#création-dun-workfile",
    "title": "Économétrie — TD 1",
    "section": "3.5 Création d’un workfile",
    "text": "3.5 Création d’un workfile\nAvant d’importer une base de données, il faut créer un workfile :\n\nMenu : File → New → Workfile.\n\nTrois structures sont possibles :\n\nUnstructured/Undated (pour des données transversales).\n\nData Range : nombre d’observations (ex. nombre de pays).\n\nDated–regular frequency (pour des séries temporelles).\n\nFrequency : fréquence (annuelle, mensuelle, …).\nStart date et End date : période couverte.\n\nBalanced Panel (pour des données de panel).\n\nmême principe que pour les séries temporelles, en précisant le nombre d’individus.\n\n\nOptions complémentaires : - Name : nom du workfile ; - Page : numéro de page.\nSauvegarder le workfile :\n- première fois via File → Save as,\n- ensuite File → Save ou Ctrl + S.\nPour rouvrir un workfile existant : File → Open → Workfile."
  },
  {
    "objectID": "td1/td1.html#importation-de-données",
    "href": "td1/td1.html#importation-de-données",
    "title": "Économétrie — TD 1",
    "section": "3.6 Importation de données",
    "text": "3.6 Importation de données\nAvant l’importation, assurez-vous que le fichier Excel ne contient aucune formule.\nEnsuite :\n\nFermez la feuille Excel.\nMenu : File → Import → Import from file.\nSélectionnez la base de données.\n\nUne première fenêtre permet de choisir la plage de données : - Predefined Range si aucun changement n’est nécessaire ; - Custom Range pour définir précisément les cellules.\nUne seconde fenêtre permet de : - indiquer le nombre de lignes d’en-tête (Column headers) ; - modifier le nom, le type et le label des variables (Column info).\nUne troisième fenêtre offre des opérations plus avancées, par exemple lier plusieurs bases de données.\nUne fois l’importation terminée, sauvegardez le workfile.\n\n3.6.1 Création du workfile et importation en une seule étape\nIl est aussi possible de créer le workfile et d’importer les données directement : - Menu : File → Open → Foreign Data as Workfile.\nAvantage : gain de temps.\nInconvénient : la base doit être parfaitement préparée en amont."
  },
  {
    "objectID": "td2/td2-slides.html#commandes-de-base",
    "href": "td2/td2-slides.html#commandes-de-base",
    "title": "Économétrie — TD 2",
    "section": "1.1 Commandes de base",
    "text": "1.1 Commandes de base\nCes commandes se tapent dans la fenêtre de commande d’EViews.\n\n\n\n\n\n\n\n\nCommande\nDescription\nExemple\n\n\n\n\ngroup\nCréer un groupe de variables\ngroup nom x y\n\n\nscalar\nCréer un scalaire et faire des calculs\nscalar k = 3*6\n\n\nmatrix\nCréer une matrice et faire des calculs (matriciels)\n(cf. Help)\n\n\ngenr\nGénérer une variable\n(cf. plus bas)\n\n\nrename\nRenommer une variable\nrename x y (renomme x en y)\n\n\ndelete\nEffacer un ou plusieurs objets\ndelete x y\n\n\nsmpl\nSélectionner un sous-échantillon\nsmpl if x&lt;10"
  },
  {
    "objectID": "td2/td2-slides.html#type-de-variables",
    "href": "td2/td2-slides.html#type-de-variables",
    "title": "Économétrie — TD 2",
    "section": "1.2 Type de variables",
    "text": "1.2 Type de variables\nVous êtes souvent amenés à créer de nouvelles variables ou à en changer l’échelle.\nIl existe deux types de variables :\n\nVariable continue\nprend n’importe quelle valeur sur un intervalle donné.\nVariable discrète\nne prend qu’un nombre fini de valeurs.\n\n\n\n\n\n\nNote\n\n\nNota : les variables binaires (0/1) sont un cas particulier."
  },
  {
    "objectID": "td2/td2-slides.html#création-de-variables-continues",
    "href": "td2/td2-slides.html#création-de-variables-continues",
    "title": "Économétrie — TD 2",
    "section": "1.3 Création de variables continues",
    "text": "1.3 Création de variables continues\nCommande générale :\n\ngenr nouveau_nom = opération\nEx. genr lnx = log(x)\n\n\n\n\n\n\n\nWarning\n\n\nAttention : saisir la ligne de commande dans la fenêtre de commande."
  },
  {
    "objectID": "td2/td2-slides.html#opérateurs-utiles-eviews",
    "href": "td2/td2-slides.html#opérateurs-utiles-eviews",
    "title": "Économétrie — TD 2",
    "section": "1.4 Opérateurs utiles (EViews)",
    "text": "1.4 Opérateurs utiles (EViews)\n\n\n\nFormule mathématique\nEViews\n\n\n\n\n\\(x + a\\)\nx+a\n\n\n\\(x - a\\)\nx-a\n\n\n\\(x \\cdot a\\)\nx*a\n\n\n\\(x / a\\)\nx/a\n\n\n\\(x^a\\)\nx^a\n\n\n\\(\\ln(x)\\)\nlog(x)\n\n\n\\(e^x\\)\nexp(x)"
  },
  {
    "objectID": "td2/td2-slides.html#création-de-variables-muettes-dummies",
    "href": "td2/td2-slides.html#création-de-variables-muettes-dummies",
    "title": "Économétrie — TD 2",
    "section": "1.5 Création de variables muettes (dummies)",
    "text": "1.5 Création de variables muettes (dummies)\nUne variable muette est discrète 0/1 (binaire).\nExemples : - (=1) si l’individu est une femme, (0) sinon. - (=1) si le pays est OCDE, (0) sinon.\nDeux méthodes :"
  },
  {
    "objectID": "td2/td2-slides.html#création-de-variables-discrètes",
    "href": "td2/td2-slides.html#création-de-variables-discrètes",
    "title": "Économétrie — TD 2",
    "section": "1.6 Création de variables discrètes",
    "text": "1.6 Création de variables discrètes\nUne variable discrète prend un nombre limité de valeurs (0, 1, …, n).\n- Peut venir d’un classement (ex. classes de revenus).\n- Peut coder un choix limité (pays d’immigration, parti politique, notes…).\n\n\n\n\n\n\nNote\n\n\nRemarque : une muette est un cas particulier de discrète.\n\n\n\nDeux méthodes :"
  },
  {
    "objectID": "td2/td2-slides.html#principe",
    "href": "td2/td2-slides.html#principe",
    "title": "Économétrie — TD 2",
    "section": "2.1 Principe",
    "text": "2.1 Principe\nLe but des statistiques descriptives est de décrire les variables.\nÉtape cruciale pour :\n- connaître sa base,\n- avoir une première idée des relations existantes.\n\n\n\n\n\n\n\nÉtude d’une variable\nÉtude d’une relation entre variables\n\n\n\n\nTableaux : statistiques descriptives\nCoefficients de corrélation\n\n\nFigures : histogramme, boîte à moustache, évolution\nNuage de points, droite de régression"
  },
  {
    "objectID": "td2/td2-slides.html#statistiques-descriptives-une-variable",
    "href": "td2/td2-slides.html#statistiques-descriptives-une-variable",
    "title": "Économétrie — TD 2",
    "section": "2.2 Statistiques descriptives — une variable",
    "text": "2.2 Statistiques descriptives — une variable\nOuvrir la fenêtre de la série (double-clic).\n\nTableau des principales statistiques :\nView → Descriptive statistics & Tests → Stats Table\nGraphiques : View → Graph\n\nHistogramme : distribution\nLine : courbe temporelle\nBoxplot : boîte à moustache"
  },
  {
    "objectID": "td2/td2-slides.html#comparer-par-modalité-une-variable",
    "href": "td2/td2-slides.html#comparer-par-modalité-une-variable",
    "title": "Économétrie — TD 2",
    "section": "2.3 Comparer par modalité (une variable)",
    "text": "2.3 Comparer par modalité (une variable)\nTest d’égalité de moyennes :\nView → Descriptive statistics & Tests → Stats by classification\n- Choisir la modalité via Series/Group for classify.\nGraphiques par modalité :\n- Option Categorical graph dans Graph type.\n- Renseigner la modalité dans factors — series defining categories."
  },
  {
    "objectID": "td2/td2-slides.html#statistiques-descriptives-plusieurs-variables",
    "href": "td2/td2-slides.html#statistiques-descriptives-plusieurs-variables",
    "title": "Économétrie — TD 2",
    "section": "2.4 Statistiques descriptives — plusieurs variables",
    "text": "2.4 Statistiques descriptives — plusieurs variables\nOuvrir les séries ensemble : sélectionner les variables → Open → as Group.\n\nCoefficients de corrélation :\n\nView → Covariance analysis\nDans Statistics, choisir Correlation\n\nNuage de points :\nView → Graph → Scatter\n\nUtile : Fit Line → Regression line (droite de régression)"
  },
  {
    "objectID": "td2/td2-slides.html#graphiques-plusieurs-variables",
    "href": "td2/td2-slides.html#graphiques-plusieurs-variables",
    "title": "Économétrie — TD 2",
    "section": "2.5 Graphiques (plusieurs variables)",
    "text": "2.5 Graphiques (plusieurs variables)\nExplorer les différents graphiques et choisir celui qui illustre le mieux votre propos.\n\nPour modifier le graphique : bouton Options (fenêtre du graphique)\n\nPour restreindre à un sous-échantillon : onglet Sample"
  },
  {
    "objectID": "td2/td2-slides.html#enregistrer-et-extraire-les-objets-créés",
    "href": "td2/td2-slides.html#enregistrer-et-extraire-les-objets-créés",
    "title": "Économétrie — TD 2",
    "section": "2.6 Enregistrer et extraire les objets créés",
    "text": "2.6 Enregistrer et extraire les objets créés\nPour enregistrer les objets : Freeze et nommer (Name).\n\nTableaux : le plus simple → Copy (Ctrl+C) et coller dans Excel.\n\nGraphiques :\nProc → Copy to Clipboard (ou Ctrl+C)\nou Object → View Options → Copy to Clipboard\npuis coller dans un document Word (.doc)."
  },
  {
    "objectID": "td2/td2-slides.html#questions-réponses-td2",
    "href": "td2/td2-slides.html#questions-réponses-td2",
    "title": "Économétrie — TD 2",
    "section": "2.7 Questions – Réponses (TD2)",
    "text": "2.7 Questions – Réponses (TD2)"
  },
  {
    "objectID": "td3/td3-correction.html",
    "href": "td3/td3-correction.html",
    "title": "TD 3 — Correction & explications",
    "section": "",
    "text": "Importer le workfile et estimer l’équation MCO.\n\nTester l’homoscédasticité :\n\nBreusch–Pagan–Godfrey (BP) : ( BP = N R^2 ^2(K-1) )\n\nWhite : ( W ^2 ) avec carrés & interactions des X\n\nGoldfeld–Quandt : test de ratio de variances (F)\n\nConclure (H0: homoscédasticité).\n\nCorriger si nécessaire :\n\nMatrice de covariance robuste de White (erreurs robustes)\n\nou Moindres Carrés Généralisés (MCG) si une forme de variance est modélisable."
  },
  {
    "objectID": "td3/td3-correction.html#étapes",
    "href": "td3/td3-correction.html#étapes",
    "title": "TD 3 — Correction & explications",
    "section": "",
    "text": "Importer le workfile et estimer l’équation MCO.\n\nTester l’homoscédasticité :\n\nBreusch–Pagan–Godfrey (BP) : ( BP = N R^2 ^2(K-1) )\n\nWhite : ( W ^2 ) avec carrés & interactions des X\n\nGoldfeld–Quandt : test de ratio de variances (F)\n\nConclure (H0: homoscédasticité).\n\nCorriger si nécessaire :\n\nMatrice de covariance robuste de White (erreurs robustes)\n\nou Moindres Carrés Généralisés (MCG) si une forme de variance est modélisable."
  },
  {
    "objectID": "td3/td3-correction.html#interprétation-type",
    "href": "td3/td3-correction.html#interprétation-type",
    "title": "TD 3 — Correction & explications",
    "section": "Interprétation type",
    "text": "Interprétation type\n\nSi BP &lt; χ²_{K-1} et White &lt; χ²_{ddl} aux seuils usuels → ne pas rejeter H0 → homoscédasticité.\n\nSinon → hétéroscédasticité : préférer erreurs robustes (White) pour les tests t/F, ou MCG."
  },
  {
    "objectID": "td3/td3-correction.html#procédure-eviews-rappel",
    "href": "td3/td3-correction.html#procédure-eviews-rappel",
    "title": "TD 3 — Correction & explications",
    "section": "Procédure EViews (rappel)",
    "text": "Procédure EViews (rappel)\n\nView → Residual Diagnostics → Heteroskedasticity Tests\n(choisir Breusch–Pagan–Godfrey ou White)\n\nView → Coefficients Diagnostics → Scaled coefficients pour l’importance économique\n\nPour un Wald/F-test conjoint :\n\nView → Coefficient Diagnostics → Wald test (ex. c(3)=0, c(5)=0)\n\nou calcul manuel : \\(( F = \\frac{SCR_r - SCR_{nr}}{SCR_{nr}}\\times\\frac{N - p}{q} )\\)"
  },
  {
    "objectID": "td3/td3-correction.html#notes-pédagogiques",
    "href": "td3/td3-correction.html#notes-pédagogiques",
    "title": "TD 3 — Correction & explications",
    "section": "Notes pédagogiques",
    "text": "Notes pédagogiques\n\nNormalité des résidus, espérance nulle, indépendance sérielle, orthogonalité aux X sont des hypothèses classiques utiles pour l’inférence.\n\nUne significativité statistique n’implique pas forcément une importance économique : interpréter les ordres de grandeur (forme linéaire, log-linéaire, log-log)."
  },
  {
    "objectID": "td3/td3-correction.html#conclusion-type",
    "href": "td3/td3-correction.html#conclusion-type",
    "title": "TD 3 — Correction & explications",
    "section": "Conclusion type",
    "text": "Conclusion type\nDans l’exemple fourni, les statistiques Breusch–Pagan et White sont inférieures aux valeurs tabulées à 5% → homoscédasticité. Aucune correction nécessaire ; à défaut, choisir des erreurs robustes (White) pour préserver la validité des tests."
  },
  {
    "objectID": "td3/td3.html",
    "href": "td3/td3.html",
    "title": "Économétrie — TD 3",
    "section": "",
    "text": "Ce document reprend le contenu de TD 3 sous forme de cours. On revoit les éléments fondamentaux de la régression linéaire, la décomposition ANOVA, les indicateurs de qualité d’ajustement ( \\(R^2\\), \\(\\bar R^2\\) ), puis les tests t et F. Une section explique l’importance économique des variables et la lecture des coefficients standardisés. Les questions / réponses du TD sont fournies à la fin."
  },
  {
    "objectID": "td3/td3.html#modèle-simple-et-interprétation-de-beta_0-et-beta_1",
    "href": "td3/td3.html#modèle-simple-et-interprétation-de-beta_0-et-beta_1",
    "title": "Économétrie — TD 3",
    "section": "2.1 Modèle simple et interprétation de \\(\\beta_0\\) et \\(\\beta_1\\)",
    "text": "2.1 Modèle simple et interprétation de \\(\\beta_0\\) et \\(\\beta_1\\)\nOn suppose : \\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\quad i=1,\\dots,N,\\) où \\(\\varepsilon_i\\) est centré et non corrélé aux régresseurs.\nObjectif MCO (OLS) : minimiser \\(\\sum_i (Y_i - \\beta_0 - \\beta_1 X_i)^2\\) .\nInterprétation :\n- \\(\\beta_0\\) est l’ordonnée à l’origine (valeur de (Y) quand (X=0)).\n- \\(\\beta_1\\) est la pente (variation moyenne de (Y) quand (X) augmente d’une unité).\n\n2.1.1 Illustration graphique\n\n\n\n\n\n\n\n\nFigure 1: β₀ (interception) et pente β₁ illustrée par un triangle rectangle (Δx = 1, Δy = β₁)."
  },
  {
    "objectID": "td3/td3.html#forme-matricielle-et-estimateur-ols",
    "href": "td3/td3.html#forme-matricielle-et-estimateur-ols",
    "title": "Économétrie — TD 3",
    "section": "2.2 Forme matricielle et estimateur OLS",
    "text": "2.2 Forme matricielle et estimateur OLS\nEn multiple : \\(Y = X\\beta + \\varepsilon\\) et \\(\\hat\\beta = (X'X)^{-1}X'Y\\) .\nLes valeurs ajustées sont \\(\\hat Y = X\\hat\\beta\\) et les résidus \\(\\hat\\varepsilon = Y - \\hat Y\\) .\nLa forme matricielle de la régression linéaire : \\(Y = X\\beta + \\varepsilon\\) n’est pas juste un “raccourci d’écriture”, elle a plusieurs implications importantes :\n\n2.2.1 Écriture compacte et générale\n\nElle englobe en une seule équation le modèle avec plusieurs variables explicatives et plusieurs observations.\nQue l’on ait 2 ou 200 régresseurs, la notation reste la même.\nLe vecteur \\(Y\\) contient toutes les observations de la variable dépendante, la matrice \\(X\\) toutes les observations de toutes les variables explicatives (y compris une colonne de 1 pour l’intercept).\n2.2.2 Estimation par l’algèbre linéaire\nL’estimateur OLS \\(\\hat\\beta = (X'X)^{-1} X'Y\\) se déduit directement des règles de dérivation matricielle (minimisation de la somme des carrés).\nCette formule montre les conditions d’existence : la matrice \\(X'X\\) doit être inversible → donc les colonnes de \\(X\\) (les variables explicatives) doivent être linéairement indépendantes (pas de multicolinéarité parfaite).\n2.2.3 Propriétés géométriques\nLe vecteur des valeurs ajustées \\(\\hat Y = X \\hat\\beta\\) ​ est la projection orthogonale de \\(Y\\) sur l’espace engendré par les colonnes de \\(X\\).\nLes résidus \\(\\hat\\varepsilon = Y - \\hat Y\\) sont orthogonaux à cet espace :\n\n\\(X'\\hat\\varepsilon=0\\) .\n→ Les variables explicatives ne sont pas corrélées aux résidus.\n\n\n\nExtension à d’autres modèles\n\nCette écriture facilite les généralisations : régression multiple, modèles de panel, régressions pondérées, moindres carrés généralisés, etc.\nElle permet d’utiliser directement les outils de l’algèbre linéaire (décomposition en valeurs propres, moindres carrés ordinaires ou généralisés)."
  },
  {
    "objectID": "td3/td3.html#anova-textsct-textsce-textscr",
    "href": "td3/td3.html#anova-textsct-textsce-textscr",
    "title": "Économétrie — TD 3",
    "section": "3.1 ANOVA : \\(\\text{SCT} = \\text{SCE} + \\text{SCR}\\)",
    "text": "3.1 ANOVA : \\(\\text{SCT} = \\text{SCE} + \\text{SCR}\\)\nLa somme des carrés totale (SCT) se décompose en somme des carrés expliquée (SCE) et somme des carrés des résidus (SCR) : \\(\\sum_i (Y_i - \\bar Y)^2 = \\sum_i (\\hat Y_i - \\bar Y)^2 + \\sum_i (Y_i - \\hat Y_i)^2.\\)\n\n3.1.1 Schéma visuel\n\n\n\n\n\nDécomposition ANOVA : SCT = SCE + SCR."
  },
  {
    "objectID": "td3/td3.html#r2-et-bar-r2",
    "href": "td3/td3.html#r2-et-bar-r2",
    "title": "Économétrie — TD 3",
    "section": "3.2 \\(R^2\\) et \\(\\bar R^2\\)",
    "text": "3.2 \\(R^2\\) et \\(\\bar R^2\\)\n\\(R^2 = \\frac{\\text{SCE}}{\\text{SCT}} = 1 - \\frac{\\text{SCR}}{\\text{SCT}},\\quad \\bar R^2 = 1 - (1 - R^2)\\frac{N-1}{N-p}\\) .\n\n\\(R^2\\) mesure la part de variance expliquée.\n\n\\(\\bar R^2\\) pénalise l’ajout de régresseurs superflus.\n\nAttention : on ne cherche pas à maximiser \\(R^2\\) en ajoutant des variables sans justification."
  },
  {
    "objectID": "td3/td3.html#utiliser-un-test-dhypothèse-avec-une-table-de-valeurs-critiques",
    "href": "td3/td3.html#utiliser-un-test-dhypothèse-avec-une-table-de-valeurs-critiques",
    "title": "Économétrie — TD 3",
    "section": "4.1 Utiliser un test d’hypothèse avec une table de valeurs critiques",
    "text": "4.1 Utiliser un test d’hypothèse avec une table de valeurs critiques\nPour utiliser un test d’hypothèse avec une table de valeurs critiques (table t de Student, table F, table du Khi-deux…), on suit toujours la même logique en 4 étapes :\n\n\n4.1.1 Formuler les hypothèses\n\nHypothèse nulle \\(H_0\\) : ce qu’on veut tester (ex. \\(\\beta = 0\\), « les moyennes sont égales »).\nHypothèse alternative \\(H_1\\) : ce qu’on conclut si \\(H_0\\) est rejetée (ex. \\(\\beta \\neq 0\\)).\n\nPréciser si le test est :\n\nbilatéral : on rejette si la statistique est trop grande en valeur absolue.\nunilatéral : on rejette seulement dans une queue.\n\n\n\n\n4.1.2 Choisir le niveau de risque\nFixer le niveau de signification \\(\\alpha\\), par exemple 5 % \\(0,05\\).\nCela correspond au risque d’erreur de type I (rejeter \\(H_0\\) alors qu’elle est vraie).\n\n\n\n4.1.3 Calculer la statistique de test\nÀ partir de vos données :\n\npour un test t : \\(t = \\frac{\\hat\\beta - \\beta_0}{\\widehat{se}(\\hat\\beta)}\\)\npour un test F : \\(F = \\frac{(\\text{SCE}/q)}{(\\text{SCR}/(N-p))}\\)\n\n… ou la statistique adaptée au test choisi.\n\n\n\n4.1.4 Comparer à la table\n\nChercher dans la table de la loi correspondante (t, F, …) la valeur critique :\n\nconnaître les degrés de liberté (ex. \\(N-p\\) pour \\(t\\), \\(q\\) et \\(N-p\\) pour \\(F\\)) ;\nchoisir la colonne de \\(\\alpha\\) (ou \\(\\alpha/2\\) pour un test bilatéral).\n\nDécision :\n\nbilatéral : rejeter \\(H_0)\\) si \\(|\\text{statistique}| &gt; t^*_{\\alpha/2}\\).\nunilatéral à droite : rejeter \\(H_0\\) si \\(\\text{statistique} &gt; t^*_{\\alpha}) ou (F &gt; F^*_{\\alpha}\\)."
  },
  {
    "objectID": "td3/td3.html#test-t-significativité-individuelle",
    "href": "td3/td3.html#test-t-significativité-individuelle",
    "title": "Économétrie — TD 3",
    "section": "4.2 Test t (significativité individuelle)",
    "text": "4.2 Test t (significativité individuelle)\nOn teste typiquement \\(H_0:\\beta_j=0\\) vs \\(H_1:\\beta_j\\neq 0\\).\nStatistique : \\(t = \\hat\\beta_j / \\widehat{se}(\\hat\\beta_j)\\) .\nDécision bilatérale au seuil \\(\\alpha\\) : rejeter (H_0) si \\(|t| &gt; t^*_{\\alpha/2, \\nu}\\).\n\n4.2.1 Visualisation du test t (bilatéral)\n\n\n\n\n\n\n\n\nFigure 2: Test bilatéral : α/2 décalés vers l’extérieur, -t* et t* en graduations de l’axe X."
  },
  {
    "objectID": "td3/td3.html#test-f-significativité-conjointe",
    "href": "td3/td3.html#test-f-significativité-conjointe",
    "title": "Économétrie — TD 3",
    "section": "4.3 Test F (significativité conjointe)",
    "text": "4.3 Test F (significativité conjointe)\nOn teste \\(H_0\\) : un ensemble de coefficients (= 0) (excluant la constante).\nSous \\(H_0\\)$, \\(F \\sim F(q, N-p)\\) (queue droite).\n\n4.3.1 Visualisation du test F\n\n\n\n\n\n\n\n\nFigure 3: Loi F(3,30) — test unilatéral (queue droite)."
  },
  {
    "objectID": "td4/td4-slides.html#les-hypothèses-des-estimations-mco",
    "href": "td4/td4-slides.html#les-hypothèses-des-estimations-mco",
    "title": "Économétrie — TD 4",
    "section": "1.1 Les hypothèses des estimations MCO",
    "text": "1.1 Les hypothèses des estimations MCO\n\nL’estimateur des Moindres Carrés Ordinaires est le meilleur estimateur linéaire sous certaines hypothèses\n\n\n\n\n\n\n\nNote\n\n\n\nOn dit qu’il est BLUE (Best Linear Unbiased Estimator)\nNéanmoins il est sensible aux observations extrêmes\n\n\n\n\n\nCes hypothèses concernent les termes d’erreurs ( \\(\\varepsilon\\) ):\n\nNormalité des résidus: \\(\\varepsilon \\leadsto N(0,\\sigma_{\\varepsilon}^2)\\)\nEspérance nulle: \\(E(\\varepsilon_{i})=0\\)\nHomoscédasticité: \\(V(\\varepsilon_{i})=\\sigma^2=\\text{constante}\\)\nIndépendance sérielle: \\(Cov(\\varepsilon_{i},\\varepsilon_{j})=0,\\quad \\forall i\\neq j\\)\n(Absence de corrélation entre les résidus)\nOrthogonalité des résidus (ou exogénéité): \\(Cov(x_{i},\\varepsilon_{i})=0\\)"
  },
  {
    "objectID": "td4/td4-slides.html#précisions-sémantiques",
    "href": "td4/td4-slides.html#précisions-sémantiques",
    "title": "Économétrie — TD 4",
    "section": "1.2 Précisions sémantiques",
    "text": "1.2 Précisions sémantiques\n\nOn distingue les propriétés sur petits échantillons et grands échantillons. Les propriétés sur petits échantillons:\n\nL’estimateur est sans biais si \\(E(\\hat{\\beta})=\\beta\\).\nL’estimateur est à variance minimale si \\(Var(\\hat{\\beta}) \\leq Var(\\tilde{\\beta})\\)\navec \\(\\tilde{\\beta}\\) un autre estimateur sans biais de \\(\\beta\\).\nL’estimateur est efficace s’il remplit ces deux propriétés\n\nSur grands échantillons:\n\nL’estimateur est convergent si la variance de \\(\\beta\\) tend vers 0 quand N tend vers l’infini:\n\\(\\lim_{N \\to \\infty} Var(\\beta)=0\\)"
  },
  {
    "objectID": "td4/td4-slides.html#hypothèse-et-propriétés-des-estimateurs",
    "href": "td4/td4-slides.html#hypothèse-et-propriétés-des-estimateurs",
    "title": "Économétrie — TD 4",
    "section": "1.3 Hypothèse et propriétés des estimateurs",
    "text": "1.3 Hypothèse et propriétés des estimateurs\n\n\n\n\n\n\n\n\n\nPropriété / Hypothèse\nProblème si non respectée\nTest(s) associé(s)\nMéthode(s) de correction\n\n\n\n\nAbsence de biais (orthogonalité)\nBiais dans les estimations ; non-convergence\n—\nInstrumentation (variables instrumentales)\n\n\nEfficience (sphéricité des erreurs)\nEstimation non efficace (mais pas de biais)\n- Homoscédasticité : tests de Breusch–Pagan, White- Absence d’autocorrélation sérielle : tests de Durbin–Watson, Breusch–Godfrey\n- Correction de White (robust std. errors)- HAC (Newey–West)\n\n\n\n\nCe TD se concentre uniquement sur le problème d’éfficience"
  },
  {
    "objectID": "td4/td4-slides.html#les-tests-dhypothèses",
    "href": "td4/td4-slides.html#les-tests-dhypothèses",
    "title": "Économétrie — TD 4",
    "section": "1.4 Les tests d’hypothèses",
    "text": "1.4 Les tests d’hypothèses\n\nObjectif :\n\nVoir si le modèle est économétriquement correct.\n\nComment ?\n\nEn vérifiant que les erreurs respectent les hypothèses des MCO et que l’estimateur est efficace (BLUE).\nEn particulier, les tests se concentrent sur cinq hypothèses :\n\nNormalité des résidus : \\(ε ~ N(0, σ²_ε)\\)\nEspérance nulle : \\(E(εᵢ) = 0\\)\nHomoscédasticité : \\(Var(εᵢ) = σ²\\) (constante)\nIndépendance sérielle : \\(Cov(εᵢ, εⱼ) = 0\\) pour tout \\(i ≠ j\\)\nOrthogonalité des résidus : \\(Cov(xᵢ, εᵢ) = 0\\)\n\n\nRemarque :\n\nH2 est respectée par construction de l’estimateur MCO.\nH5 fait l’objet d’un traitement particulier (cf. Semestre 2)."
  },
  {
    "objectID": "td4/td4-slides.html#les-tests-dhypothèses-1",
    "href": "td4/td4-slides.html#les-tests-dhypothèses-1",
    "title": "Économétrie — TD 4",
    "section": "1.5 Les tests d’hypothèses",
    "text": "1.5 Les tests d’hypothèses\n\n\n\nHypothèse\nTest(s) associé(s)\nTraité ?\n\n\n\n\nH1 : Normalité\nTest de Bera–Jarque\n✓\n\n\nH3 : Homoscédasticité\nTest de Goldfeld–Quandt\n\n\n\n\nTest de Breusch–Pagan\n✓\n\n\n\nTest de White\n✓\n\n\nH4 : Indépendance sérielle\nTest de Durbin–Watson\n✓\n\n\n\nTest de Breusch–Godfrey\n✓"
  },
  {
    "objectID": "td4/td4-slides.html#le-test-de-berajarque",
    "href": "td4/td4-slides.html#le-test-de-berajarque",
    "title": "Économétrie — TD 4",
    "section": "2.1 Le test de Bera–Jarque",
    "text": "2.1 Le test de Bera–Jarque\n\nLa normalité des écarts aléatoires est utile pour mettre en œuvre les tests de sphéricité.\nLe test utilisé est celui de Bera–Jarque.\nCe test repose sur deux indicateurs :\n\nSkewness \\(η\\) : mesure l’asymétrie de la distribution\n( \\(η\\) doit être = 0).\nKurtosis \\(υ\\) : représente l’aplatissement de la distribution\n( \\(υ\\) doit être = 3)."
  },
  {
    "objectID": "td4/td4-slides.html#le-test-de-berajarque-1",
    "href": "td4/td4-slides.html#le-test-de-berajarque-1",
    "title": "Économétrie — TD 4",
    "section": "2.2 Le test de Bera–Jarque",
    "text": "2.2 Le test de Bera–Jarque\n\nLa statistique BJ calculée est :\nBJ = N [ η² / 6 + (υ – 3)² / 24 ] → suit une loi χ²(2)\nHypothèses testées :\n\nH₀ : BJ = 0 → la distribution suit une loi normale\nH₁ : BJ ≠ 0 → la distribution ne suit pas une loi normale\n\nRègle de décision :\nSi BJ &gt; χ²(2)₍th₎ (≈ 6 au seuil de 5 %),\n⇒ on rejette H₀."
  },
  {
    "objectID": "td4/td4-slides.html#le-test-de-berajarque-dans-eviews",
    "href": "td4/td4-slides.html#le-test-de-berajarque-dans-eviews",
    "title": "Économétrie — TD 4",
    "section": "2.3 Le test de Bera–Jarque (dans EViews)",
    "text": "2.3 Le test de Bera–Jarque (dans EViews)\n\nPour administrer le test via l’interface graphique :\n\nOuvrir la fenêtre de l’équation.\nAller dans View → Residual Diagnostic.\nChoisir Histogram – Normality Test pour lancer le test de BJ.\nLire et interpréter les résultats.\n\n\n\n\n\n\n\nTip\n\n\nRemarque : la procédure est identique pour les autres tests de sphéricité,\nà l’exception de l’étape 3."
  },
  {
    "objectID": "td4/td4-slides.html#test-de-breuschpagan",
    "href": "td4/td4-slides.html#test-de-breuschpagan",
    "title": "Économétrie — TD 4",
    "section": "3.1 Test de Breusch–Pagan",
    "text": "3.1 Test de Breusch–Pagan\n\nLogique : vérifier si la variance des résidus dépend des variables explicatives.\nModèle estimé :\n\n\\(Yᵢ = β₀ + β₁ Xᵢ + β₂ Zᵢ + εᵢ\\)\n\\(ε̂ᵢ = Yᵢ – β̂₀ – β̂₁ Xᵢ – β̂₂ Zᵢ\\)\n\nHypothèses :\n\n\\(H₀\\) : \\(Var(ε̂ᵢ) = σ²\\) (la variance ne dépend pas des variables explicatives)\n\\(H₁\\) : \\(Var(ε̂ᵢ) = σᵢ² = θ₀ + θ₁ Xᵢ + θ₂ Zᵢ + ωᵢ\\)\n( \\(θ₁ et θ₂ ≠ 0\\) → variance liée aux variables explicatives)\n\n\n\n\n\n\n\nTip\n\n\nRemarque : la variance des erreurs est approximée par les résidus au carré : \\(Var(εᵢ) ≈ ε̂ᵢ²\\)."
  },
  {
    "objectID": "td4/td4-slides.html#test-de-breuschpagan-procédure",
    "href": "td4/td4-slides.html#test-de-breuschpagan-procédure",
    "title": "Économétrie — TD 4",
    "section": "3.2 Test de Breusch–Pagan : procédure",
    "text": "3.2 Test de Breusch–Pagan : procédure\n\nEstimer le modèle par MCO.\nCalculer les résidus au carré : \\(ε̂ᵢ²\\).\nRégression de test :\n\\(ε̂ᵢ² = θ₀ + θ₁ Xᵢ + θ₂ Zᵢ + ωᵢ.\\)\nExaminer le pouvoir explicatif via le R² de cette équation :\n\nStatistique \\(BP = N × R²\\) → suit une loi \\(χ²(K – 1)\\), K = nombre de paramètres.\nRègle : si \\(BP ≥ χ²_th\\) ⇒ rejet de \\(H₀\\).\n\n\n\n\n\n\n\n\nNote\n\n\nIntuition : sous homoscédasticité, R² → 0, donc X et Z n’expliquent pas la variance des résidus."
  },
  {
    "objectID": "td4/td4-slides.html#test-de-white",
    "href": "td4/td4-slides.html#test-de-white",
    "title": "Économétrie — TD 4",
    "section": "3.3 Test de White",
    "text": "3.3 Test de White\n\nMême logique et démarche que Breusch–Pagan, mais avec une représentation plus flexible de l’hétéroscédasticité.\nHypothèses :\n\n\\(H₀ : Var(ε̂ᵢ) = σ²\\)\n\\(H₁ : Var(ε̂ᵢ) = σᵢ² = θ₀ + θ₁ Xᵢ + θ₂ Zᵢ + θ₃ Xᵢ² + θ₄ Xᵢ Zᵢ + θ₅ Zᵢ² + ωᵢ\\)\n(les coefficients θ sont conjointement ≠ 0)\n\nÉquation de test : \\(ε̂ᵢ² = θ₀ + θ₁ Xᵢ + θ₂ Zᵢ + θ₃ Xᵢ² + θ₄ Xᵢ Zᵢ + θ₅ Zᵢ² + ωᵢ.\\)"
  },
  {
    "objectID": "td4/td4-slides.html#statistiques-du-test-de-white",
    "href": "td4/td4-slides.html#statistiques-du-test-de-white",
    "title": "Économétrie — TD 4",
    "section": "3.4 Statistiques du test de White",
    "text": "3.4 Statistiques du test de White\n\nStatistique principale :\n\n\\(W = N × R² → loi χ²(K – 1)\\), K = nombre de paramètres (ici 6).\n\nVersion petits échantillons (F-test) :\n\n\\(W = ((SCR_r – SCR_nr) / SCR_r) × (N – k) / (k – 1) → F(k – 1, N – k)\\)\n\n\\(SCR_r\\): somme des carrés des résidus en régressant ε̂ᵢ² sur constante seule.\n\\(SCR_nr\\): idem mais sur l’équation de test.\nk : nombre de paramètres sous H₀ (ici 3).\n\n\nRègle de décision : si \\(W ≥ χ²_th ⇒ rejet de H₀\\)."
  },
  {
    "objectID": "td4/td4-slides.html#mise-en-œuvre-sous-eviews",
    "href": "td4/td4-slides.html#mise-en-œuvre-sous-eviews",
    "title": "Économétrie — TD 4",
    "section": "3.5 Mise en œuvre sous EViews",
    "text": "3.5 Mise en œuvre sous EViews\n\nLes tests de Breusch–Pagan et de White sont directement programmés :\n\nView → Residual Diagnostic → Heteroskedasticity Tests\n\nBreusch–Pagan–Godfrey : test de Breusch–Pagan\nWhite : test de White"
  },
  {
    "objectID": "td4/td4-slides.html#test-de-durbinwatson",
    "href": "td4/td4-slides.html#test-de-durbinwatson",
    "title": "Économétrie — TD 4",
    "section": "4.1 Test de Durbin–Watson",
    "text": "4.1 Test de Durbin–Watson\n\nPremier test développé, avec des conditions restrictives :\n\nIl faut une constante dans le modèle.\nLe nombre d’observations doit être supérieur à 15.\nLa variable expliquée retardée ne doit pas être introduite dans le modèle.\nPas de données manquantes.\nOn ne peut tester que l’autocorrélation issue d’un processus AR(1) :\n\\(εₜ = ρ εₜ₋₁ + υₜ.\\)\n\nCe test a servi de base à de nombreux autres tests d’autocorrélation."
  },
  {
    "objectID": "td4/td4-slides.html#hypothèses-du-test",
    "href": "td4/td4-slides.html#hypothèses-du-test",
    "title": "Économétrie — TD 4",
    "section": "4.2 Hypothèses du test",
    "text": "4.2 Hypothèses du test\n\n\\(H₀ : Yₜ = β₀ + β₁ Xₜ + β₂ Zₜ + εₜ\\)\n\\(H₁ : Yₜ = β₀ + β₁ Xₜ + β₂ Zₜ + εₜ\\)\navec \\(εₜ = ρ εₜ₋₁ + υₜ.\\)\nSous H₁, l’écart aléatoire est corrélé dans le temps.\nStatistique de Durbin–Watson :\n\\(DW = Σₜ₌₂ᵀ (ε̂ₜ – ε̂ₜ₋₁)² / Σₜ₌₁ᵀ ε̂ₜ² ≈ 2 (1 – ρ̂)\\)\nCette statistique est directement fournie par EViews dans le tableau de régression."
  },
  {
    "objectID": "td4/td4-slides.html#interprétation",
    "href": "td4/td4-slides.html#interprétation",
    "title": "Économétrie — TD 4",
    "section": "4.3 Interprétation",
    "text": "4.3 Interprétation\n\nLa statistique DW ne suit pas une loi standard : \\(0 ≤ DW ≤ 4\\).\nLes auteurs ont tabulé des valeurs critiques : \\(D_L et D_U (D_L &lt; D_U).\\)\n\nLecture :\n\n\n\nZone\nInterprétation\n\n\n\n\n[0, D_L]\nRejet H₀ : autocorrélation positive\n\n\n(D_L, D_U)\nZone d’incertitude\n\n\n[D_U, 2]\nAcceptation H₀\n\n\n[2, 4 – D_U]\nAcceptation H₀\n\n\n(4 – D_U, 4 – D_L)\nZone d’incertitude\n\n\n[4 – D_L, 4]\nRejet H₀ : autocorrélation négative\n\n\n\n\nTest imparfait en raison de la zone de doute et des conditions restrictives.\nDans la table DW, les colonnes dépendent du nombre de paramètres du modèle hors constante."
  },
  {
    "objectID": "td4/td4-slides.html#test-de-breuschgodfrey",
    "href": "td4/td4-slides.html#test-de-breuschgodfrey",
    "title": "Économétrie — TD 4",
    "section": "4.4 Test de Breusch–Godfrey",
    "text": "4.4 Test de Breusch–Godfrey\n\nBreusch et Godfrey ont développé un test de maximum de vraisemblance plus flexible :\n\npermet de tester des processus autorégressifs d’ordre ≥ 1.\n\nExemple d’un processus d’ordre 2 :\n\n\\(H₀ : Yₜ = β₀ + β₁ Xₜ + β₂ Zₜ + εₜ\\)\n\\(H₁ : Yₜ = β₀ + β₁ Xₜ + β₂ Zₜ + εₜ\\)\navec \\(εₜ = ρ₁ εₜ₋₁ + ρ₂ εₜ₋₂ + υₜ.\\)\n\nÉquation de test : \\(ε̂ₜ = ρ₁ ε̂ₜ₋₁ + ρ₂ ε̂ₜ₋₂ + θ₁ Xₜ + θ₂ Zₜ + ωₜ.\\)\nStatistique : \\(BG = T × R²\\) → suit une loi \\(χ²(t)\\), où t est l’ordre du processus autorégressif (ici 2).\nRègle de décision :\nRejeter \\(H₀\\) si \\(BG ≥ χ²_th\\).\nProcédure sous EViews :\n\nView → Residual Diagnostic → Serial correlation LM test.\nChoisir le nombre de retards (lags) à tester."
  },
  {
    "objectID": "td4/td4-slides.html#importez-le-fichier-de-travail-sur-les-compagnies-aériennes.",
    "href": "td4/td4-slides.html#importez-le-fichier-de-travail-sur-les-compagnies-aériennes.",
    "title": "Économétrie — TD 4",
    "section": "6.1 Importez le fichier de travail sur les compagnies aériennes.",
    "text": "6.1 Importez le fichier de travail sur les compagnies aériennes."
  },
  {
    "objectID": "td4/td4-slides.html#estimez-léquation-suivante-par-les-mco",
    "href": "td4/td4-slides.html#estimez-léquation-suivante-par-les-mco",
    "title": "Économétrie — TD 4",
    "section": "6.2 Estimez l’équation suivante par les MCO :",
    "text": "6.2 Estimez l’équation suivante par les MCO :\n\\(log(Pass_i) =\\beta_0 + \\beta_1 Fatal_Passagers_i + \\beta_2 NonFatal_Passagers_i + \\beta_3 Low_cost_i \\ + \\beta_4 Public_i + \\beta_5 Inter_i + \\beta_6 Age_i + \\beta_7 Trafic_nat_i + \\beta_8 Trafic_dest_i +\\varepsilon_i\\)"
  },
  {
    "objectID": "td4/td4-slides.html#homoscédasticité-1",
    "href": "td4/td4-slides.html#homoscédasticité-1",
    "title": "Économétrie — TD 4",
    "section": "6.3 Homoscédasticité",
    "text": "6.3 Homoscédasticité\n· Qu’est-ce que l’homoscédasticité et quel problème induit son non-respect pour les MCO ?\n\n\nAfficher la réponse\n\nHomoscédasticité = la variance de l’erreur est constante pour toutes les valeurs des régressseurs :\n\n\\(\\mathrm{Var}(u_i\\mid X)=\\sigma^2\\) pour tout \\(i\\).\nSi cette hypothèse est violée (hétéroscédasticité) :\n\nLes estimateurs MCO \\(\\hat\\beta\\)​ restent sans biais et consistants si \\(E[u\\mid X]=0\\) tient, mais ils ne sont plus efficaces (plus BLUE) : il existe de meilleurs estimateurs (GLS/WLS).\nLes écarts-types MCO “classiques” sont faussés ⇒ tests t/F et IC peuvent être trompeurs (trop optimistes ou trop prudents).\nConséquence pratique majeure : mauvaise inférence.\n\nQue faire ?\n\nUtiliser des erreurs-types robustes à l’hétéroscédasticité (HC0–HC3/“White”)."
  },
  {
    "objectID": "td4/td4-slides.html#homoscédasticité-2",
    "href": "td4/td4-slides.html#homoscédasticité-2",
    "title": "Économétrie — TD 4",
    "section": "6.4 Homoscédasticité",
    "text": "6.4 Homoscédasticité\n· A l’aide des tests de Goldfeld et Quandt, de Breusch-Pagan-Koenker et de White, que peut-on conclure quant à l’homoscédasticité du terme d’erreurs ?\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td4/td4-slides.html#corrections",
    "href": "td4/td4-slides.html#corrections",
    "title": "Économétrie — TD 4",
    "section": "6.5 Correction(s)",
    "text": "6.5 Correction(s)\n· En fonction des résultats des divers tests, proposez une correction le cas échéant.\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td4/td4-slides.html#corrections-1",
    "href": "td4/td4-slides.html#corrections-1",
    "title": "Économétrie — TD 4",
    "section": "6.6 Correction(s)",
    "text": "6.6 Correction(s)\n· Vos conclusions quant à l’effet des accidents mortels et non mortels sont-elles modifiées ?\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td5/td5-correction.html",
    "href": "td5/td5-correction.html",
    "title": "TD 5 — Correction & explications",
    "section": "",
    "text": "Si cov(X, ε) ≠ 0 (biais de simultanéité, omission d’une variable, erreur de mesure), l’estimateur MCO est biaisé et non convergent.\nIl faut recourir à la MVI / 2SLS avec des instruments : variables corrélées à X endogène mais orthogonales à ε."
  },
  {
    "objectID": "td5/td5-correction.html#pourquoi-lendogénéité-pose-problème",
    "href": "td5/td5-correction.html#pourquoi-lendogénéité-pose-problème",
    "title": "TD 5 — Correction & explications",
    "section": "",
    "text": "Si cov(X, ε) ≠ 0 (biais de simultanéité, omission d’une variable, erreur de mesure), l’estimateur MCO est biaisé et non convergent.\nIl faut recourir à la MVI / 2SLS avec des instruments : variables corrélées à X endogène mais orthogonales à ε."
  },
  {
    "objectID": "td5/td5-correction.html#test-de-nakamura-nakamura-exogénéité-dune-variable-explicative",
    "href": "td5/td5-correction.html#test-de-nakamura-nakamura-exogénéité-dune-variable-explicative",
    "title": "TD 5 — Correction & explications",
    "section": "2) Test de Nakamura & Nakamura (exogénéité d’une variable explicative)",
    "text": "2) Test de Nakamura & Nakamura (exogénéité d’une variable explicative)\nSoit Yi = β1 Xi + β2 Zi + εi avec Xi suspectée endogène, instruments Ii.\n\nPremière étape (auxiliaire) : Xi = γ0 + γ1 Ii + γ2 Zi + ωi\n\nRésidus : extraire ω̂i.\n\nÉquation augmentée : Yi = β1 Xi + β2 Zi + φ ω̂i + εi.\n\nTest : H0: φ = 0 (Xi exogène) vs H1: φ ≠ 0 (Xi endogène). Décision via t de Student (ou F si plusieurs instruments)."
  },
  {
    "objectID": "td5/td5-correction.html#application-aux-4-fonctions-doffre",
    "href": "td5/td5-correction.html#application-aux-4-fonctions-doffre",
    "title": "TD 5 — Correction & explications",
    "section": "3) Application aux 4 fonctions d’offre",
    "text": "3) Application aux 4 fonctions d’offre\n\noffre1…offre4 : instrument principal Y (revenu) ; pour offre4, ajouter aussi W (salaire) côté explicatives.\n\nDécisions types (exemple) :\n\noffre1 : |t(ω̂1)| = 0.31 &lt; tα → prix exogène (non rejet H0).\n\noffre2 : |t(ω̂2)| = 0.52 &lt; tα → prix exogène.\n\noffre3 : |t(ω̂3)| = 1.76 &lt; tα → prix exogène (au seuil 5%).\n\noffre4 : |t(ω̂4)| = 2.99 ≥ tα → prix endogène ⇒ 2SLS requis."
  },
  {
    "objectID": "td5/td5-correction.html#estimation-par-2sls-si-endogénéité",
    "href": "td5/td5-correction.html#estimation-par-2sls-si-endogénéité",
    "title": "TD 5 — Correction & explications",
    "section": "4) Estimation par 2SLS (si endogénéité)",
    "text": "4) Estimation par 2SLS (si endogénéité)\n\nPrincipe : remplacer la variable endogène par sa valeur prédite (ou spécifier TSLS dans EViews).\n\nEViews : Method = TSLS ; liste d’instruments : Y (et W si pertinent) + exogènes du modèle."
  },
  {
    "objectID": "td5/td5-correction.html#qualité-des-instruments",
    "href": "td5/td5-correction.html#qualité-des-instruments",
    "title": "TD 5 — Correction & explications",
    "section": "5) Qualité des instruments",
    "text": "5) Qualité des instruments\n\nPertinence : F de première étape &gt; 10 (diagnostics Weak Instruments).\n\nExogénéité (sur-identification) : Sargan S = N·R² ~ χ²(k−p)."
  },
  {
    "objectID": "td5/td5-correction.html#conclusion",
    "href": "td5/td5-correction.html#conclusion",
    "title": "TD 5 — Correction & explications",
    "section": "6) Conclusion",
    "text": "6) Conclusion\n\nLa plupart des prix apparaissent exogènes, sauf P4 dans offre4 → 2SLS.\n\nInterpréter à la fin l’effet économique (ordres de grandeur) et la robustesse (tests sur instruments)."
  },
  {
    "objectID": "td5/td5.html",
    "href": "td5/td5.html",
    "title": "Économétrie — TD 5",
    "section": "",
    "text": "Avant de conclure sur la validité d’un modèle économétrique, il faut toujours se demander si le modèle spécifié est bien correct :\n\nLa relation entre variables est-elle commune à tout l’échantillon ?\nLa forme fonctionnelle choisie est-elle la plus appropriée ?\nA-t-on omis une variable explicative importante ?\n\nCe TD présente les principaux tests de stabilité des coefficients et les outils permettant de vérifier la bonne spécification d’un modèle."
  },
  {
    "objectID": "td5/td5.html#illustration",
    "href": "td5/td5.html#illustration",
    "title": "Économétrie — TD 5",
    "section": "2.1 Illustration",
    "text": "2.1 Illustration\n\n\n\n\n\n\n\n\nFigure 1: Rupture structurelle marquée en 1974 : saut de niveau + changement de pente.\n\n\n\n\n\nDans la figure ci-dessus, on observe un changement brutal de tendance en 1974, typique d’une rupture structurelle.\n\n\n\n\n\n\n\n\nFigure 2: Hétérogénéité des coefficients par groupe (pays en guerre vs autres).\n\n\n\n\n\nDans la Figure Figure 2, on voit que les estimations sont différentes si on sépare en deux groupes l’échantillon (guerre vs en paix).\n\n\n\n\n\n\n\n\nFigure 3: Inverted-U dataset: linear fit misses curvature; quadratic and smoother capture it.\n\n\n\n\n\nDans le Figure Figure 3, on remarque que l’estimation linéaire est une hypothèse forte à la vue de la dispersion des données."
  },
  {
    "objectID": "td5/td5.html#test-de-chow-rupture-connue",
    "href": "td5/td5.html#test-de-chow-rupture-connue",
    "title": "Économétrie — TD 5",
    "section": "2.2 1.1 Test de Chow : rupture connue",
    "text": "2.2 1.1 Test de Chow : rupture connue\nIdée : comparer deux sous-échantillons (avant / après la date derupture).\n\nSi la stabilité est vérifiée, la somme des SCR (sommes des carrés des résidus) des deux sous-échantillons est égale à celle de l’échantillon complet.\nStatistique : \\(CH=\\frac{SCR_{t}-(SCR_{1}+SCR_{2})}{SCR_{1}+SCR_{2}}\\frac{N-2K}{K} \\sim F(K,N-2K)\\)\n\n\\(K\\) : nombre de coefficients estimés (constante incluse)\n\\(N\\) : taille d’échantillon totale\n\n⚠️ Hypothèse d’homoscédasticité indispensable.\nDans EViews :\n\nView → Stability Diagnostics → Chow Breakpoint Test.\nSur petits échantillons, utiliser le Chow prédictif : \\(CH_{p}=\\frac{SCR_{t}-SCR_{1}}{SCR_{1}}\\frac{N_{1}-K}{N-N_{1}}\\sim F(N-N_{1},N_{1}-K)\\)\n(Chow Forecast Test dans EViews)."
  },
  {
    "objectID": "td5/td5.html#test-de-quandt-andrews-rupture-inconnue",
    "href": "td5/td5.html#test-de-quandt-andrews-rupture-inconnue",
    "title": "Économétrie — TD 5",
    "section": "2.3 1.2 Test de Quandt-Andrews : rupture inconnue",
    "text": "2.3 1.2 Test de Quandt-Andrews : rupture inconnue\nQuand la date de rupture est inconnue, on calcule la statistique de Chow pour toutes les observations possibles et l’on retient la date qui minimise l’hypothèse nulle.\n\nEViews :\nView → Stability Diagnostics → Quandt-Andrews Breakpoint Test."
  },
  {
    "objectID": "td5/td5.html#autres-remarques",
    "href": "td5/td5.html#autres-remarques",
    "title": "Économétrie — TD 5",
    "section": "2.4 1.3 Autres remarques",
    "text": "2.4 1.3 Autres remarques\nAvant tout test, trier les données par la variable susceptible d’être à l’origine de la rupture (Proc → Sort Current Page dans EViews).\nSi non-stabilité :\n\nEstimer sur des sous-échantillons,\n\n\n\nIntroduire des variables muettes additives ou interactives,\nExclure éventuellement des points aberrants.\n\n\n\n\n\n\n\n\n\nFigure 4: Organigramme : familles de tests de stabilité (point connu vs inconnu)."
  },
  {
    "objectID": "td6/td6-slides.html#objectif-du-td",
    "href": "td6/td6-slides.html#objectif-du-td",
    "title": "Économétrie — TD 6",
    "section": "1.1 Objectif du TD",
    "text": "1.1 Objectif du TD\n\nRappeler les hypothèses des MCO et la notion d’exogénéité.\nIdentifier trois sources d’endogénéité (omission, causalité inverse, erreur de mesure).\nIntroduire la méthode des variables instrumentales (2SLS/DMC) : pertinence, exogénéité des instruments, et tests associés."
  },
  {
    "objectID": "td6/td6-slides.html#hypothèses-clés-linéaire-mco",
    "href": "td6/td6-slides.html#hypothèses-clés-linéaire-mco",
    "title": "Économétrie — TD 6",
    "section": "2.1 Hypothèses clés (linéaire, MCO)",
    "text": "2.1 Hypothèses clés (linéaire, MCO)\n\n\\(\\mathbb{E}[u_i]=0\\)\n\\(\\mathrm{Var}(u_i)=\\sigma^2\\) (homoscédasticité)\n\\(\\mathrm{Cov}(u_i,u_j)=0\\) (pas d’autocorrélation)\n\\(\\mathrm{Cov}(X,\\varepsilon)=0\\) (exogénéité)\n\n\n\n\n\n\n\nNote\n\n\nSi \\(\\mathrm{Cov}(X,\\varepsilon)\\neq 0\\), l’estimateur MCO est biaisé et non convergent : il ne mesure pas l’effet causal de \\(X\\) sur \\(Y\\)."
  },
  {
    "objectID": "td6/td6-slides.html#omission-dune-variable-pertinente",
    "href": "td6/td6-slides.html#omission-dune-variable-pertinente",
    "title": "Économétrie — TD 6",
    "section": "3.1 (1) Omission d’une variable pertinente",
    "text": "3.1 (1) Omission d’une variable pertinente\nVrai modèle : \\(Y_i=\\beta_0+\\beta_1 X_{1i}+\\beta_2 X_{2i}+\\varepsilon_i\\).\nMais on estime : \\(Y_i=\\beta_0+\\beta_1 X_{1i}+\\varepsilon_i\\) avec \\(X_{1}\\) corrélé à \\(X_{2}\\).\nSens du biais sur \\(\\hat\\beta_1\\) :\n\n\n\n\n\n\n\n\n\n\\(\\mathrm{corr}(X_1,X_2)&gt;0\\)\n\\(\\mathrm{corr}(X_1,X_2)&lt;0\\)\n\n\n\n\n\\(\\beta_2&gt;0\\)\n+ (vers le haut)\n− (vers le bas)\n\n\n\\(\\beta_2&lt;0\\)\n−\n+\n\n\n\nL’omission « pousse » \\(\\hat\\beta_1\\) dans le sens de la corrélation entre \\(X_1\\) et la variable manquante \\(X_2\\)."
  },
  {
    "objectID": "td6/td6-slides.html#causalité-inverse",
    "href": "td6/td6-slides.html#causalité-inverse",
    "title": "Économétrie — TD 6",
    "section": "3.2 (2) Causalité inverse",
    "text": "3.2 (2) Causalité inverse\nOn estime \\(Y_i=\\beta_0+\\beta_1 X_i+\\varepsilon_i\\) alors qu’en réalité \\(X_i=\\gamma_0+\\gamma_1 Y_i+\\gamma_2 Z_i+\\nu_i\\) (boucle de rétroaction).\nExemple : croissance du PIB \\(\\leftrightarrow\\) dette publique.\nSens du biais (sur \\(\\hat\\beta_1\\)) :\n\n\n\n\n\\(\\gamma_1&gt;0\\)\n\\(\\gamma_1&lt;0\\)\n\n\n\n\n\\(\\beta_1&gt;0\\)\n+\n−\n\n\n\\(\\beta_1&lt;0\\)\n−\n+\n\n\n\nL’effet estimé « récupère » une partie du retour \\(Y\\to X\\)."
  },
  {
    "objectID": "td6/td6-slides.html#erreur-de-mesure-sur-x",
    "href": "td6/td6-slides.html#erreur-de-mesure-sur-x",
    "title": "Économétrie — TD 6",
    "section": "3.3 (3) Erreur de mesure sur \\(X\\)",
    "text": "3.3 (3) Erreur de mesure sur \\(X\\)\nOn souhaite \\(Y_i=\\beta_0+\\beta_1 X_i+\\varepsilon_i\\), mais on observe \\(\\tilde X_i=X_i+\\nu_i\\).\nAlors : \\(Y_i=\\beta_0+\\beta_1 \\tilde X_i +(\\varepsilon_i-\\beta_1\\nu_i)\\), d’où \\(\\tilde X\\) corrélée à l’erreur composite.\nConséquence : biais d’atténuation (vers 0) sur \\(\\hat\\beta_1\\)."
  },
  {
    "objectID": "td6/td6-slides.html#principe-2sls-dmc",
    "href": "td6/td6-slides.html#principe-2sls-dmc",
    "title": "Économétrie — TD 6",
    "section": "4.1 Principe (2SLS / DMC)",
    "text": "4.1 Principe (2SLS / DMC)\nBut : isoler la variation exogène de \\(X\\) avec un instrument \\(Z\\).\n\n1ʳᵉ étape : régresser \\(X\\) sur \\(Z\\) (et autres contrôles), obtenir \\(\\hat X\\).\n2ᵉ étape : remplacer \\(X\\) par \\(\\hat X\\) dans l’équation de \\(Y\\).\nRecalculer des écarts-types adaptés (2SLS).\n\nConditions pour \\(Z\\) :\n\nPertinence : \\(\\mathrm{Cov}(Z,X)\\neq 0\\) (pouvoir explicatif).\nExogénéité exclue : \\(Z\\) n’affecte \\(Y\\) que via \\(X\\) (\\(\\mathrm{Cov}(Z,\\varepsilon)=0\\))."
  },
  {
    "objectID": "td6/td6-slides.html#pertinence-instruments-faibles",
    "href": "td6/td6-slides.html#pertinence-instruments-faibles",
    "title": "Économétrie — TD 6",
    "section": "4.2 Pertinence : instruments faibles",
    "text": "4.2 Pertinence : instruments faibles\n\nVérifier la 1ʳᵉ étape : test \\(F\\) des instruments.\nRègle pratique : \\(F&gt;10\\) \\(\\Rightarrow\\) pertinence acceptable.\nPlusieurs instruments faibles aggravent le biais.\n(EViews) View → IV Diagnostics and Tests → Weak Instrument Diagnostics."
  },
  {
    "objectID": "td6/td6-slides.html#exogénéité-de-linstrument",
    "href": "td6/td6-slides.html#exogénéité-de-linstrument",
    "title": "Économétrie — TD 6",
    "section": "4.3 Exogénéité de l’instrument",
    "text": "4.3 Exogénéité de l’instrument\n\nL’instrument ne doit pas être corrélé à \\(Y\\) autrement que via \\(X\\).\nTests de sur-identification (si \\(q&gt;p\\)) : Sargan (homoscédasticité) / Hansen-J (robuste).\nStatistique \\(\\chi^2(k)\\) avec \\(k\\) = nb de restrictions (sur-id).\n(EViews) View → IV Diagnostics and Tests → Instrument Orthogonality Test.\n\n\n\n\n\n\n\nTip\n\n\nEn pratique, on dispose rarement de sur-identification « confortable »; la justification théorique de \\(Z\\) reste centrale."
  },
  {
    "objectID": "td6/td6-slides.html#faut-il-instrumenter-dwh",
    "href": "td6/td6-slides.html#faut-il-instrumenter-dwh",
    "title": "Économétrie — TD 6",
    "section": "4.4 Faut-il instrumenter ? (DWH)",
    "text": "4.4 Faut-il instrumenter ? (DWH)\n\nPerte de précision avec VI : vérifier si l’instrumentation est nécessaire.\nDurbin–Wu–Hausman (a.k.a. Nakamura–Nakamura) :\n\n\\(H_0\\) : MCO non biaisé (\\(\\beta^{\\mathrm{MCO}} \\approx \\beta^{\\mathrm{DMC}}\\))\n\\(H_A\\) : MCO biaisé (\\(\\beta^{\\mathrm{MCO}} \\ne \\beta^{\\mathrm{DMC}}\\))\n\nStatistique \\(\\chi^2(k)\\) avec \\(k\\) = nb de variables endogènes.\n(EViews) View → IV Diagnostics and Tests → Regressor Endogeneity Test."
  },
  {
    "objectID": "td6/td6-slides.html#schéma-2sls-rappel",
    "href": "td6/td6-slides.html#schéma-2sls-rappel",
    "title": "Économétrie — TD 6",
    "section": "6.1 Schéma 2SLS (rappel)",
    "text": "6.1 Schéma 2SLS (rappel)\n\n\\(X = \\pi_0 + \\pi_1 Z + W'\\pi + v\\) (1ʳᵉ étape)\n\\(Y = \\beta_0 + \\beta_1 \\hat X + W'\\gamma + u\\) (2ᵉ étape)\n\n\n\\(Z\\) : instruments ; \\(W\\) : contrôles exogènes.\nConditions : \\(\\mathrm{rank}([Z,W])\\) suffisant ; \\(\\mathrm{Cov}(Z,u)=0\\)."
  },
  {
    "objectID": "td6/td6-slides.html#tables-sens-du-biais-récapitulatif",
    "href": "td6/td6-slides.html#tables-sens-du-biais-récapitulatif",
    "title": "Économétrie — TD 6",
    "section": "6.2 Tables « sens du biais » (récapitulatif)",
    "text": "6.2 Tables « sens du biais » (récapitulatif)\n6.2.1 Omission d’une variable\n\n\n\n\n\n\n\n\n\n\\(\\mathrm{corr}(X_1,X_2)&gt;0\\)\n\\(\\mathrm{corr}(X_1,X_2)&lt;0\\)\n\n\n\n\n\\(\\beta_2&gt;0\\)\n+\n−\n\n\n\\(\\beta_2&lt;0\\)\n−\n+\n\n\n\n6.2.2 Causalité inverse\n\n\n\n\n\\(\\gamma_1&gt;0\\)\n\\(\\gamma_1&lt;0\\)\n\n\n\n\n\\(\\beta_1&gt;0\\)\n+\n−\n\n\n\\(\\beta_1&lt;0\\)\n−\n+"
  },
  {
    "objectID": "td6/td6-slides.html#références-dans-eviews",
    "href": "td6/td6-slides.html#références-dans-eviews",
    "title": "Économétrie — TD 6",
    "section": "6.3 Références « dans EViews »",
    "text": "6.3 Références « dans EViews »\n\nWeak instruments : View → IV Diagnostics and Tests → Weak Instrument Diagnostics\nOrthogonality (Sargan/Hansen) : View → IV Diagnostics and Tests → Instrument Orthogonality Test\nEndogeneity (DWH) : View → IV Diagnostics and Tests → Regressor Endogeneity Test"
  },
  {
    "objectID": "td6/td6-slides.html#q1-charger-le-workfile",
    "href": "td6/td6-slides.html#q1-charger-le-workfile",
    "title": "Économétrie — TD 6",
    "section": "7.1 Q1 — Charger le workfile",
    "text": "7.1 Q1 — Charger le workfile"
  },
  {
    "objectID": "td6/td6-slides.html#énoncé",
    "href": "td6/td6-slides.html#énoncé",
    "title": "Économétrie — TD 6",
    "section": "7.2 Énoncé",
    "text": "7.2 Énoncé\nChargez le workfile Marshall (contient offre1–offre4, p1–p4, Y, W).\n\n\nAfficher la réponse\n\n\nFile → Open → Workfile puis sélectionner Marshall.wf*.\nVérifier les séries dans l’arborescence (double-clic pour aperçu).\n(Option) View → Descriptive Statistics → Histogram and stats pour un coup d’œil rapide."
  },
  {
    "objectID": "td6/td6-slides.html#énoncé-1",
    "href": "td6/td6-slides.html#énoncé-1",
    "title": "Économétrie — TD 6",
    "section": "8.1 Énoncé",
    "text": "8.1 Énoncé\nEstimez les fonctions d’offre par MCO :\npour i = 1 à 3: offrei = α + β Pi + ε\net offre4 = α + β P4 + π W + ε, avec W exogène.\n\n\nAfficher la réponse\n\n\nQuick → Estimate Equation, puis entrer la spécification :\n\noffre1 c p1\noffre2 c p2\noffre3 c p3\noffre4 c p4 W\n\nNoter : \\(\\hat\\beta\\) (signe, magnitude), \\(R^2\\), p-values, et résidus.\n\n\n\n\n\n\n\nCaution\n\n\nRappel : si \\(\\mathrm{Cov}(P,\\varepsilon)\\neq 0\\) (ex. offre_i ⇄ p_i), MCO est biaisé. On vérifiera ensuite avec des tests d’exogénéité."
  },
  {
    "objectID": "td6/td6-slides.html#énoncé-2",
    "href": "td6/td6-slides.html#énoncé-2",
    "title": "Économétrie — TD 6",
    "section": "9.1 Énoncé",
    "text": "9.1 Énoncé\nIndiquez, à l’aide du test de Nakamura & Nakamura, le caractère exogène des variables de prix, en prenant comme instrument le revenu Y.\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td6/td6-slides.html#intuition",
    "href": "td6/td6-slides.html#intuition",
    "title": "Économétrie — TD 6",
    "section": "9.2 Intuition",
    "text": "9.2 Intuition\n\n\\(H_0\\): exogénéité du prix dans l’équation d’offre (MCO non biaisé).\n\\(H_A\\): endogénéité → préférer VI (2SLS)."
  },
  {
    "objectID": "td6/td6-slides.html#mise-en-œuvre-eviews",
    "href": "td6/td6-slides.html#mise-en-œuvre-eviews",
    "title": "Économétrie — TD 6",
    "section": "9.3 Mise en œuvre (EViews)",
    "text": "9.3 Mise en œuvre (EViews)\n\nEstime l’équation en IV/2SLS (voir Q4) pour récupérer les résidus nécessaires, ou utilise directement :\n\nQuick → Estimate Equation → Method: TSLS/IV,\nonglet View → IV Diagnostics and Tests → Regressor Endogeneity Test (Durbin–Wu–Hausman / Nakamura–Nakamura).\n\nDécision : si la stat. \\(\\chi^2\\) (ou F) est significative, rejeter \\(H_0\\) → le prix est endogène."
  },
  {
    "objectID": "td6/td6-slides.html#énoncé-3",
    "href": "td6/td6-slides.html#énoncé-3",
    "title": "Économétrie — TD 6",
    "section": "10.1 Énoncé",
    "text": "10.1 Énoncé\nEstimez, si nécessaire, les fonctions d’offre à l’aide de la méthode des variables instrumentales, en utilisant Y comme instrument.\n\n\nAfficher la réponse"
  },
  {
    "objectID": "td6/td6-slides.html#rappel-2sls-schéma",
    "href": "td6/td6-slides.html#rappel-2sls-schéma",
    "title": "Économétrie — TD 6",
    "section": "10.2 Rappel 2SLS (schéma)",
    "text": "10.2 Rappel 2SLS (schéma)\n\n1ʳᵉ étape : \\(P_i = \\pi_0 + \\pi_1 Y + v\\) ⇒ obtenir \\(\\widehat{P}_i\\).\n2ᵉ étape : \\(\\text{offre}_i = \\alpha + \\beta \\widehat{P}_i + u\\).\nÉcarts-types robustes si hétéroscédasticité (option White)."
  },
  {
    "objectID": "td6/td6-slides.html#guide-eviews",
    "href": "td6/td6-slides.html#guide-eviews",
    "title": "Économétrie — TD 6",
    "section": "10.3 Guide (EViews)",
    "text": "10.3 Guide (EViews)\n\nQuick → Estimate Equation → Method: TSLS – Two Stage Least Squares.\nList of endogenous: p1 (ou p2/p3/p4).\nInstrument list: Y (ajouter W pour offre4).\nView → IV Diagnostics and Tests :\n\nWeak Instrument Diagnostics (F 1ʳᵉ étape &gt; 10 souhaitable),\nInstrument Orthogonality Test (Hansen-J/Sargan), si sur-id."
  },
  {
    "objectID": "td7/td7-correction.html",
    "href": "td7/td7-correction.html",
    "title": "TD 7 — Correction & explications (JB, stabilité)",
    "section": "",
    "text": "Statistique : JB = N·( S²/6 + (K−3)²/24 ), où S = skewness, K = kurtosis.\n\nDécision : comparer à χ²(2) = 5.9915 (5%).\n\nExemples usuels :\n\nSous‑échantillon PNBH &lt; 1290 : JB ≈ 11.99 &gt; 5.99 ⇒ non normal.\n\nPNBH ≥ 1290 : JB ≈ 0.02 &lt; 5.99 ⇒ normal.\n\nTotal : JB ≈ 2.23 &lt; 5.99 ⇒ normal."
  },
  {
    "objectID": "td7/td7-correction.html#jarquebera",
    "href": "td7/td7-correction.html#jarquebera",
    "title": "TD 7 — Correction & explications (JB, stabilité)",
    "section": "",
    "text": "Statistique : JB = N·( S²/6 + (K−3)²/24 ), où S = skewness, K = kurtosis.\n\nDécision : comparer à χ²(2) = 5.9915 (5%).\n\nExemples usuels :\n\nSous‑échantillon PNBH &lt; 1290 : JB ≈ 11.99 &gt; 5.99 ⇒ non normal.\n\nPNBH ≥ 1290 : JB ≈ 0.02 &lt; 5.99 ⇒ normal.\n\nTotal : JB ≈ 2.23 &lt; 5.99 ⇒ normal."
  },
  {
    "objectID": "td7/td7-correction.html#stabilité-interactions",
    "href": "td7/td7-correction.html#stabilité-interactions",
    "title": "TD 7 — Correction & explications (JB, stabilité)",
    "section": "2) Stabilité (interactions)",
    "text": "2) Stabilité (interactions)\n\nCréer pnbh_dummy.\n\nTester TEP × pnbh_dummy (et/ou TXPNBH × pnbh_dummy).\n\nH0 : coefficient du terme interactif = 0 (effet identique entre groupes).\n\nRejet H0 ⇒ instabilité (effet différent selon le niveau de PNBH)."
  },
  {
    "objectID": "td7/td7-correction.html#remarques",
    "href": "td7/td7-correction.html#remarques",
    "title": "TD 7 — Correction & explications (JB, stabilité)",
    "section": "3) Remarques",
    "text": "3) Remarques\n\nVérifier homoscédasticité et spécification en complément (tests White / RESET).\n\nInterpréter l’importance économique des effets selon les sous‑échantillons."
  },
  {
    "objectID": "td7/td7.html",
    "href": "td7/td7.html",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On part d’un modèle linéaire simple :\n\\[\ny_i = \\beta x_i + \\gamma' w_i + u_i\n\\]\n\n\\(y_i\\) : variable expliquée\n\\(x_i\\) : régresseur endogène (corrélé au terme d’erreur)\n\\(w_i\\) : contrôles exogènes\n\\(u_i\\) : terme d’erreur\n\nProblème : si\n\\[\\operatorname{Cov}(x_i, u_i) \\neq 0\\]\nalors l’estimateur MCO de \\(\\beta\\) est biaisé et inconsistant.\nIdée des variables instrumentales (VI) : introduire des variables \\(z_i\\) telles que :\n\n(Pertinence) \\(\\operatorname{Cov}(z_i, x_i) \\neq 0\\)\n(Exogénéité / validité) \\(\\operatorname{Cov}(z_i, u_i) = 0\\)\n\nCes instruments permettent d’identifier \\(\\beta\\) même si \\(x_i\\) est endogène.\n\n\n\n\nOn empile les données :\n\n\\(y\\) : vecteur \\((n \\times 1)\\)\n\\(X\\) : matrice \\((n \\times K)\\) des régresseurs (dont certains endogènes)\n\\(W\\) : variables exogènes incluses dans le modèle\n\\(Z\\) : matrice \\((n \\times L)\\) des instruments (et exogènes)\n\nConditions clés pour les VI :\n\nValidité des instruments :\\[\nE[Z'u] = 0\n\\]\nPertinence / rang :\\[\n\\operatorname{rang}(E[Z'X]) = K\n\\]\n\noù \\(K\\) est le nombre de variables endogènes à instrumenter.\n\n\n\n\nOn note :\n\n\\(K\\) : nombre de variables endogènes instrumentées\n\\(L\\) : nombre d’instruments (hors exogènes inclus dans \\(X\\))\n\nCas possibles :\n\nSous-identifié : \\(L &lt; K\\)\n⟶ pas assez d’instruments, le modèle n’est pas identifié.\nExactement identifié : \\(L = K\\)\n⟶ autant d’instruments que de variables endogènes.\nSur-identifié : \\(L &gt; K\\)\n⟶ plus d’instruments que nécessaire.\n\nDans le cas sur-identifié, on a plus de conditions d’exogénéité \\(E[Z'u]=0\\) que nécessaire pour identifier les paramètres. Ces conditions supplémentaires peuvent être testées empiriquement : c’est le rôle du test de sur-identification de Sargan.\n\n\n\n\nIdée simple :\n\nOn estime le modèle par VI (typiquement 2SLS) et on obtient les résidus :\\[\n\\hat{u}_i = y_i - \\hat{y}_i\n\\]\nSi tous les instruments sont bien exogènes, alors ils doivent être orthogonaux aux erreurs vraies \\(u_i\\), et donc approximativement à \\(\\hat{u}_i\\) :\n\\[\nE[z_{ji} \\hat{u}_i] \\approx 0 \\quad \\forall j\n\\]\nSi l’on arrive à expliquer les résidus \\(\\hat{u}_i\\) par les instruments \\(Z\\), cela suggère que ces instruments sont en fait corrélés au terme d’erreur, donc invalides.\n\nLe test de Sargan mesure précisément la “force” de cette éventuelle corrélation entre \\(\\hat{u}_i\\) et \\(Z\\).\n\n\n\n\n\n\nOn estime le modèle :\n\\[\ny = X\\beta + u\n\\]\npar 2SLS en utilisant \\(Z\\) comme instruments, et on obtient l’estimateur \\(\\hat{\\beta}_{2SLS}\\) et les résidus \\(\\hat{u}\\) :\n\\[\n\\hat{u} = y - X\\hat{\\beta}_{2SLS}\n\\]\n\n\n\nOn régresse ensuite les résidus \\(\\hat{u}\\) sur l’ensemble des instruments \\(Z\\) (et, en pratique, les exogènes inclus dans \\(X\\)) :\n\\[\n\\hat{u}_i = \\delta_0 + Z_i' \\delta + v_i\n\\]\nOn note \\(R^2_{\\hat{u}\\sim Z}\\) le coefficient de détermination de cette régression.\n\n\n\nLa statistique de Sargan est définie par :\n\\[\nJ = n \\times R^2_{\\hat{u}\\sim Z}\n\\]\noù \\(n\\) est la taille de l’échantillon.\nIntuition : plus \\(R^2\\) est élevé, plus les instruments expliquent bien les résidus, donc plus il est suspect que les instruments soient corrélés à \\(u\\).\n\n\n\n\n\nSous les hypothèses suivantes :\n\ninstruments valides : \\(E[Z'u] = 0\\)\nhomoscédasticité des erreurs \\(u_i\\)\nspécification correcte du modèle (forme fonctionnelle, variables pertinentes, etc.)\n\nalors, sous l’hypothèse nulle \\(H_0\\) :\n\nTous les instruments sont exogènes\n\nla statistique de test \\(J\\) suit asymptotiquement une loi du chi-deux :\n\\[\nJ \\overset{a}{\\sim} \\chi^2_{L-K}\n\\]\n\nles degrés de liberté sont : \\(L - K\\) (nombre de restrictions sur-identifiantes)\n\n\\(L\\) : nombre d’instruments\n\\(K\\) : nombre de variables endogènes\n\n\nOn peut donc calculer une p-value à partir de cette loi \\(\\chi^2_{L-K}\\).\n\n\n\n\n\nHypothèse nulle \\(H_0\\) : Tous les instruments sont valides (exogènes)\n\\(E[Z'u] = 0\\)\nHypothèse alternative \\(H_1\\) : Au moins un instrument est invalide\n⟶ instruments corrélés au terme d’erreur, ou mauvaise spécification globale.\n\n\n\n\n\nOn calcule la p-value associée à \\(J\\) sous la loi \\(\\chi^2_{L-K}\\) :\n\nSi la p-value est élevée (par ex. &gt; 5 %) :\n\non ne rejette pas \\(H_0\\) ;\non ne trouve pas de preuve statistique contre la validité globale des instruments ;\nattention : cela ne prouve pas que les instruments sont parfaits, seulement qu’on ne détecte pas de violation.\n\nSi la p-value est faible (par ex. &lt; 5 %) :\n\non rejette \\(H_0\\) ;\nil est probable qu’au moins un (ou plusieurs) instrument(s) soit(ent) corrélé(s) au terme d’erreur ;\ncela peut aussi refléter une mauvaise spécification du modèle (variables omises, non-linéarités, etc.).\n\n\nImportant : le test ne dit pas quel instrument est problématique. Il teste seulement la validité conjointe de tous les instruments.\n\n\n\n\nLe test de Sargan repose sur l’hypothèse d’homoscédasticité.\nEn présence d’hétéroscédasticité, la loi de \\(J = nR^2\\) n’est plus une bonne approximation.\nDans le cadre plus général du GMM (Generalized Method of Moments), on peut construire un test de sur-identification robuste à l’hétéroscédasticité :\n\nTest de Hansen J (ou Sargan–Hansen) :\n\nmême hypothèse nulle : validité globale des instruments ;\nmême loi asymptotique : \\(\\chi^2_{L-K}\\) ;\nmais la statistique est calculée à partir d’une matrice de pondération robuste (type “sandwich”).\n\n\nEn pratique :\n\nSargan : adapté si l’on suppose l’homoscédasticité.\nHansen J : à privilégier lorsque l’on utilise des estimateurs GMM ou des variances robustes.\n\n\n\n\n\nConsidérons le modèle :\n\\[\ny_i = \\beta x_i + \\gamma' w_i + u_i\n\\]\n\n\\(x_i\\) est endogène\n\\(w_i\\) est exogène et inclus dans le modèle\non dispose de deux instruments \\(z_{1i}, z_{2i}\\) pour \\(x_i\\)\n\nOn a :\n\n\\(K = 1\\) (une variable endogène à instrumenter)\n\\(L = 2\\) (deux instruments)\n\n⟶ Le modèle est sur-identifié avec \\(L - K = 1\\) restriction sur-identifiante.\nÉtapes :\n\nEstimer le modèle par 2SLS en utilisant \\(z_{1i}, z_{2i}\\) (et \\(w_i\\)) comme instruments.\nRécupérer les résidus \\(\\hat{u}_i\\).\nRégresser \\(\\hat{u}_i\\) sur \\(z_{1i}, z_{2i}\\) (et \\(w_i\\)), récupérer le \\(R^2\\).\nCalculer \\(J = nR^2\\) et comparer à la loi \\(\\chi^2\\) à 1 ddl."
  },
  {
    "objectID": "td7/td7.html#contexte-endogénéité-et-variables-instrumentales",
    "href": "td7/td7.html#contexte-endogénéité-et-variables-instrumentales",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On part d’un modèle linéaire simple :\n\\[\ny_i = \\beta x_i + \\gamma' w_i + u_i\n\\]\n\n\\(y_i\\) : variable expliquée\n\\(x_i\\) : régresseur endogène (corrélé au terme d’erreur)\n\\(w_i\\) : contrôles exogènes\n\\(u_i\\) : terme d’erreur\n\nProblème : si\n\\[\\operatorname{Cov}(x_i, u_i) \\neq 0\\]\nalors l’estimateur MCO de \\(\\beta\\) est biaisé et inconsistant.\nIdée des variables instrumentales (VI) : introduire des variables \\(z_i\\) telles que :\n\n(Pertinence) \\(\\operatorname{Cov}(z_i, x_i) \\neq 0\\)\n(Exogénéité / validité) \\(\\operatorname{Cov}(z_i, u_i) = 0\\)\n\nCes instruments permettent d’identifier \\(\\beta\\) même si \\(x_i\\) est endogène."
  },
  {
    "objectID": "td7/td7.html#notation-matricielle-et-identification",
    "href": "td7/td7.html#notation-matricielle-et-identification",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On empile les données :\n\n\\(y\\) : vecteur \\((n \\times 1)\\)\n\\(X\\) : matrice \\((n \\times K)\\) des régresseurs (dont certains endogènes)\n\\(W\\) : variables exogènes incluses dans le modèle\n\\(Z\\) : matrice \\((n \\times L)\\) des instruments (et exogènes)\n\nConditions clés pour les VI :\n\nValidité des instruments :\\[\nE[Z'u] = 0\n\\]\nPertinence / rang :\\[\n\\operatorname{rang}(E[Z'X]) = K\n\\]\n\noù \\(K\\) est le nombre de variables endogènes à instrumenter."
  },
  {
    "objectID": "td7/td7.html#exact-identification-vs-sur-identification",
    "href": "td7/td7.html#exact-identification-vs-sur-identification",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On note :\n\n\\(K\\) : nombre de variables endogènes instrumentées\n\\(L\\) : nombre d’instruments (hors exogènes inclus dans \\(X\\))\n\nCas possibles :\n\nSous-identifié : \\(L &lt; K\\)\n⟶ pas assez d’instruments, le modèle n’est pas identifié.\nExactement identifié : \\(L = K\\)\n⟶ autant d’instruments que de variables endogènes.\nSur-identifié : \\(L &gt; K\\)\n⟶ plus d’instruments que nécessaire.\n\nDans le cas sur-identifié, on a plus de conditions d’exogénéité \\(E[Z'u]=0\\) que nécessaire pour identifier les paramètres. Ces conditions supplémentaires peuvent être testées empiriquement : c’est le rôle du test de sur-identification de Sargan."
  },
  {
    "objectID": "td7/td7.html#intuition-du-test-de-sur-identification",
    "href": "td7/td7.html#intuition-du-test-de-sur-identification",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "Idée simple :\n\nOn estime le modèle par VI (typiquement 2SLS) et on obtient les résidus :\\[\n\\hat{u}_i = y_i - \\hat{y}_i\n\\]\nSi tous les instruments sont bien exogènes, alors ils doivent être orthogonaux aux erreurs vraies \\(u_i\\), et donc approximativement à \\(\\hat{u}_i\\) :\n\\[\nE[z_{ji} \\hat{u}_i] \\approx 0 \\quad \\forall j\n\\]\nSi l’on arrive à expliquer les résidus \\(\\hat{u}_i\\) par les instruments \\(Z\\), cela suggère que ces instruments sont en fait corrélés au terme d’erreur, donc invalides.\n\nLe test de Sargan mesure précisément la “force” de cette éventuelle corrélation entre \\(\\hat{u}_i\\) et \\(Z\\)."
  },
  {
    "objectID": "td7/td7.html#construction-de-la-statistique-de-sargan-cas-homoscédastique",
    "href": "td7/td7.html#construction-de-la-statistique-de-sargan-cas-homoscédastique",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On estime le modèle :\n\\[\ny = X\\beta + u\n\\]\npar 2SLS en utilisant \\(Z\\) comme instruments, et on obtient l’estimateur \\(\\hat{\\beta}_{2SLS}\\) et les résidus \\(\\hat{u}\\) :\n\\[\n\\hat{u} = y - X\\hat{\\beta}_{2SLS}\n\\]\n\n\n\nOn régresse ensuite les résidus \\(\\hat{u}\\) sur l’ensemble des instruments \\(Z\\) (et, en pratique, les exogènes inclus dans \\(X\\)) :\n\\[\n\\hat{u}_i = \\delta_0 + Z_i' \\delta + v_i\n\\]\nOn note \\(R^2_{\\hat{u}\\sim Z}\\) le coefficient de détermination de cette régression.\n\n\n\nLa statistique de Sargan est définie par :\n\\[\nJ = n \\times R^2_{\\hat{u}\\sim Z}\n\\]\noù \\(n\\) est la taille de l’échantillon.\nIntuition : plus \\(R^2\\) est élevé, plus les instruments expliquent bien les résidus, donc plus il est suspect que les instruments soient corrélés à \\(u\\)."
  },
  {
    "objectID": "td7/td7.html#loi-asymptotique-et-hypothèses",
    "href": "td7/td7.html#loi-asymptotique-et-hypothèses",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "Sous les hypothèses suivantes :\n\ninstruments valides : \\(E[Z'u] = 0\\)\nhomoscédasticité des erreurs \\(u_i\\)\nspécification correcte du modèle (forme fonctionnelle, variables pertinentes, etc.)\n\nalors, sous l’hypothèse nulle \\(H_0\\) :\n\nTous les instruments sont exogènes\n\nla statistique de test \\(J\\) suit asymptotiquement une loi du chi-deux :\n\\[\nJ \\overset{a}{\\sim} \\chi^2_{L-K}\n\\]\n\nles degrés de liberté sont : \\(L - K\\) (nombre de restrictions sur-identifiantes)\n\n\\(L\\) : nombre d’instruments\n\\(K\\) : nombre de variables endogènes\n\n\nOn peut donc calculer une p-value à partir de cette loi \\(\\chi^2_{L-K}\\)."
  },
  {
    "objectID": "td7/td7.html#formulation-du-test",
    "href": "td7/td7.html#formulation-du-test",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "Hypothèse nulle \\(H_0\\) : Tous les instruments sont valides (exogènes)\n\\(E[Z'u] = 0\\)\nHypothèse alternative \\(H_1\\) : Au moins un instrument est invalide\n⟶ instruments corrélés au terme d’erreur, ou mauvaise spécification globale."
  },
  {
    "objectID": "td7/td7.html#interprétation-pratique",
    "href": "td7/td7.html#interprétation-pratique",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "On calcule la p-value associée à \\(J\\) sous la loi \\(\\chi^2_{L-K}\\) :\n\nSi la p-value est élevée (par ex. &gt; 5 %) :\n\non ne rejette pas \\(H_0\\) ;\non ne trouve pas de preuve statistique contre la validité globale des instruments ;\nattention : cela ne prouve pas que les instruments sont parfaits, seulement qu’on ne détecte pas de violation.\n\nSi la p-value est faible (par ex. &lt; 5 %) :\n\non rejette \\(H_0\\) ;\nil est probable qu’au moins un (ou plusieurs) instrument(s) soit(ent) corrélé(s) au terme d’erreur ;\ncela peut aussi refléter une mauvaise spécification du modèle (variables omises, non-linéarités, etc.).\n\n\nImportant : le test ne dit pas quel instrument est problématique. Il teste seulement la validité conjointe de tous les instruments."
  },
  {
    "objectID": "td7/td7.html#sargan-vs-hansen-j-test-robuste",
    "href": "td7/td7.html#sargan-vs-hansen-j-test-robuste",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "Le test de Sargan repose sur l’hypothèse d’homoscédasticité.\nEn présence d’hétéroscédasticité, la loi de \\(J = nR^2\\) n’est plus une bonne approximation.\nDans le cadre plus général du GMM (Generalized Method of Moments), on peut construire un test de sur-identification robuste à l’hétéroscédasticité :\n\nTest de Hansen J (ou Sargan–Hansen) :\n\nmême hypothèse nulle : validité globale des instruments ;\nmême loi asymptotique : \\(\\chi^2_{L-K}\\) ;\nmais la statistique est calculée à partir d’une matrice de pondération robuste (type “sandwich”).\n\n\nEn pratique :\n\nSargan : adapté si l’on suppose l’homoscédasticité.\nHansen J : à privilégier lorsque l’on utilise des estimateurs GMM ou des variances robustes."
  },
  {
    "objectID": "td7/td7.html#exemple-stylisé-1-endogène-2-instruments",
    "href": "td7/td7.html#exemple-stylisé-1-endogène-2-instruments",
    "title": "Économétrie — TD 7",
    "section": "",
    "text": "Considérons le modèle :\n\\[\ny_i = \\beta x_i + \\gamma' w_i + u_i\n\\]\n\n\\(x_i\\) est endogène\n\\(w_i\\) est exogène et inclus dans le modèle\non dispose de deux instruments \\(z_{1i}, z_{2i}\\) pour \\(x_i\\)\n\nOn a :\n\n\\(K = 1\\) (une variable endogène à instrumenter)\n\\(L = 2\\) (deux instruments)\n\n⟶ Le modèle est sur-identifié avec \\(L - K = 1\\) restriction sur-identifiante.\nÉtapes :\n\nEstimer le modèle par 2SLS en utilisant \\(z_{1i}, z_{2i}\\) (et \\(w_i\\)) comme instruments.\nRécupérer les résidus \\(\\hat{u}_i\\).\nRégresser \\(\\hat{u}_i\\) sur \\(z_{1i}, z_{2i}\\) (et \\(w_i\\)), récupérer le \\(R^2\\).\nCalculer \\(J = nR^2\\) et comparer à la loi \\(\\chi^2\\) à 1 ddl."
  },
  {
    "objectID": "td8/td8-slides.html#test-de-jarquebera-jb",
    "href": "td8/td8-slides.html#test-de-jarquebera-jb",
    "title": "Économétrie — TD 8",
    "section": "1.1 Test de Jarque–Bera (JB)",
    "text": "1.1 Test de Jarque–Bera (JB)\nStatistique : \\(JB = N\\left(\\frac{\\eta^2}{6} + \\frac{(\\nu-3)^2}{24}\\right) \\sim \\chi^2(2)\\)\n\n\\(\\eta\\) : skewness (asymétrie, doit être 0 sous normalité)\n\\(\\nu\\) : kurtosis (aplatissement, doit être 3 sous normalité)\n\nHypothèses :\n\n\\(H_0\\) : distribution normale des résidus\n\\(H_1\\) : non-normalité\n\nDécision : rejeter \\(H_0\\) si \\(JB &gt; \\chi^2_{2;5\\%}\\approx 6\\)."
  },
  {
    "objectID": "td8/td8-slides.html#modèle-à-estimer-3-cas",
    "href": "td8/td8-slides.html#modèle-à-estimer-3-cas",
    "title": "Économétrie — TD 8",
    "section": "2.1 Modèle à estimer (3 cas)",
    "text": "2.1 Modèle à estimer (3 cas)\n\\(\\text{TUO89} = c + a,\\text{PNBH} + b,\\log(\\text{SUPER}) + d,\\text{TEP} + e,\\text{TXPNBH} + f,\\text{JEUNE} + \\varepsilon\\)\nÀ estimer par MCO : 1) Sous-échantillon ( \\(\\text{PNBH} &lt; 1290\\) )\n2) Sous-échantillon ( \\(\\text{PNBH} \\ge 1290\\) )\n3) Échantillon total\nPuis, pour chaque estimation, appliquer le test de normalité JB."
  },
  {
    "objectID": "td9/td9-slides.html#origines-de-la-méthode-de-monte-carlo",
    "href": "td9/td9-slides.html#origines-de-la-méthode-de-monte-carlo",
    "title": "Économétrie — TD 9",
    "section": "2.1 Origines de la méthode de Monte Carlo",
    "text": "2.1 Origines de la méthode de Monte Carlo\n\n« The Monte Carlo method … is an invention of statistical sampling for the solution of mathematical problems for which direct methods are not feasible. » Metropolis and Ulam (1949);.\n\n\nLe nom vient du casino de Monte-Carlo, en référence au hasard des jeux de dés.\nPremière application systématique : années 1940, projet Manhattan (physique nucléaire).\nObjectif initial : estimer des intégrales complexes ou des probabilités impossibles à calculer analytiquement.\n\nMetropolis & Ulam, 1949 — texte intégral (JASA)"
  },
  {
    "objectID": "td9/td9-slides.html#principe-et-rôle-en-économétrie",
    "href": "td9/td9-slides.html#principe-et-rôle-en-économétrie",
    "title": "Économétrie — TD 9",
    "section": "2.2 Principe et rôle en économétrie",
    "text": "2.2 Principe et rôle en économétrie\n\nDéfinir un modèle théorique connu (ex. : régression linéaire avec erreurs d’une loi choisie).\nSimuler de très nombreux échantillons à partir de ce processus générateur.\nEstimer sur chaque échantillon la même statistique ou le même estimateur que l’on souhaite étudier.\n\nBut :\n\nObserver la distribution empirique des estimateurs (biais, variance, forme).\nÉvaluer la robustesse des tests (risque réel d’erreur de première espèce, puissance).\nÉtudier l’impact de la taille d’échantillon ou de la forme de la loi des erreurs.\n\n\n\n\n\n\n\nTip\n\n\nEn pratique, la simulation de Monte Carlo est un laboratoire virtuel :\nelle permet de vérifier ou illustrer les propriétés théoriques quand la démonstration analytique est difficile ou quand on veut comprendre le comportement « en conditions réelles »."
  },
  {
    "objectID": "annexes/tables.html",
    "href": "annexes/tables.html",
    "title": "Annexes — Tables statistiques",
    "section": "",
    "text": "Student (t) : choisissez un seuil (ex. 5%) et les degrés de liberté (ddl = N − p).\nComparez |t| à la valeur critique : si |t| ≥ t_critique ⇒ rejet de H0.\n\nFisher (F) : choisissez un seuil, les ddl du numérateur (q = nb de restrictions) et du dénominateur (N − p).\nSi F ≥ F_critique ⇒ rejet de H0.\n\n\nPar convention ici : tests bilatéraux pour Student (α = 10%, 5%, 1%) et tests unilatéraux pour Fisher aux mêmes seuils.\n\n\n\n\n\n\n\nTable 1: Valeurs critiques de Student (bilatéral)\n\n\n\n    ddl t(α=10%) t(α=5%) t(α=1%)\n1     1    6.314  12.706  63.657\n2     2    2.920   4.303   9.925\n3     3    2.353   3.182   5.841\n4     4    2.132   2.776   4.604\n5     5    2.015   2.571   4.032\n6     6    1.943   2.447   3.707\n7     7    1.895   2.365   3.499\n8     8    1.860   2.306   3.355\n9     9    1.833   2.262   3.250\n10   10    1.812   2.228   3.169\n11   11    1.796   2.201   3.106\n12   12    1.782   2.179   3.055\n13   13    1.771   2.160   3.012\n14   14    1.761   2.145   2.977\n15   15    1.753   2.131   2.947\n16   16    1.746   2.120   2.921\n17   17    1.740   2.110   2.898\n18   18    1.734   2.101   2.878\n19   19    1.729   2.093   2.861\n20   20    1.725   2.086   2.845\n21   21    1.721   2.080   2.831\n22   22    1.717   2.074   2.819\n23   23    1.714   2.069   2.807\n24   24    1.711   2.064   2.797\n25   25    1.708   2.060   2.787\n26   26    1.706   2.056   2.779\n27   27    1.703   2.052   2.771\n28   28    1.701   2.048   2.763\n29   29    1.699   2.045   2.756\n30   30    1.697   2.042   2.750\n31   40    1.684   2.021   2.704\n32   50    1.676   2.009   2.678\n33   60    1.671   2.000   2.660\n34   70    1.667   1.994   2.648\n35   80    1.664   1.990   2.639\n36   90    1.662   1.987   2.632\n37  100    1.660   1.984   2.626\n38  110    1.659   1.982   2.621\n39  120    1.658   1.980   2.617\n40  150    1.655   1.976   2.609\n41  200    1.653   1.972   2.601\n42  500    1.648   1.965   2.586\n43 1000    1.646   1.962   2.581\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Valeurs critiques de Fisher (unilatéral)\n\n\n\n$`F(α = 10%)`\n  ddl denom. df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 3.285 2.924 2.728 2.605 2.522 2.461 2.414 2.377 2.347  2.323\n2         15 3.073 2.695 2.490 2.361 2.273 2.208 2.158 2.119 2.086  2.059\n3         20 2.975 2.589 2.380 2.249 2.158 2.091 2.040 1.999 1.965  1.937\n4         30 2.881 2.489 2.276 2.142 2.049 1.980 1.927 1.884 1.849  1.819\n5         40 2.835 2.440 2.226 2.091 1.997 1.927 1.873 1.829 1.793  1.763\n6         60 2.791 2.393 2.177 2.041 1.946 1.875 1.819 1.775 1.738  1.707\n7        120 2.748 2.347 2.130 1.992 1.896 1.824 1.767 1.722 1.684  1.652\n8        500 2.716 2.313 2.095 1.956 1.859 1.786 1.729 1.683 1.644  1.612\n9       1000 2.711 2.308 2.089 1.950 1.853 1.780 1.723 1.676 1.638  1.605\n  df1=12 df1=15 df1=20\n1  2.284  2.244  2.201\n2  2.017  1.972  1.924\n3  1.892  1.845  1.794\n4  1.773  1.722  1.667\n5  1.715  1.662  1.605\n6  1.657  1.603  1.543\n7  1.601  1.545  1.482\n8  1.559  1.501  1.435\n9  1.552  1.494  1.428\n\n$`F(α = 5%)`\n  ddl denom. df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 4.965 4.103 3.708 3.478 3.326 3.217 3.135 3.072 3.020  2.978\n2         15 4.543 3.682 3.287 3.056 2.901 2.790 2.707 2.641 2.588  2.544\n3         20 4.351 3.493 3.098 2.866 2.711 2.599 2.514 2.447 2.393  2.348\n4         30 4.171 3.316 2.922 2.690 2.534 2.421 2.334 2.266 2.211  2.165\n5         40 4.085 3.232 2.839 2.606 2.449 2.336 2.249 2.180 2.124  2.077\n6         60 4.001 3.150 2.758 2.525 2.368 2.254 2.167 2.097 2.040  1.993\n7        120 3.920 3.072 2.680 2.447 2.290 2.175 2.087 2.016 1.959  1.910\n8        500 3.860 3.014 2.623 2.390 2.232 2.117 2.028 1.957 1.899  1.850\n9       1000 3.851 3.005 2.614 2.381 2.223 2.108 2.019 1.948 1.889  1.840\n  df1=12 df1=15 df1=20\n1  2.913  2.845  2.774\n2  2.475  2.403  2.328\n3  2.278  2.203  2.124\n4  2.092  2.015  1.932\n5  2.003  1.924  1.839\n6  1.917  1.836  1.748\n7  1.834  1.750  1.659\n8  1.772  1.686  1.592\n9  1.762  1.676  1.581\n\n$`F(α = 1%)`\n  ddl denom.  df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 10.044 7.559 6.552 5.994 5.636 5.386 5.200 5.057 4.942  4.849\n2         15  8.683 6.359 5.417 4.893 4.556 4.318 4.142 4.004 3.895  3.805\n3         20  8.096 5.849 4.938 4.431 4.103 3.871 3.699 3.564 3.457  3.368\n4         30  7.562 5.390 4.510 4.018 3.699 3.473 3.304 3.173 3.067  2.979\n5         40  7.314 5.179 4.313 3.828 3.514 3.291 3.124 2.993 2.888  2.801\n6         60  7.077 4.977 4.126 3.649 3.339 3.119 2.953 2.823 2.718  2.632\n7        120  6.851 4.787 3.949 3.480 3.174 2.956 2.792 2.663 2.559  2.472\n8        500  6.686 4.648 3.821 3.357 3.054 2.838 2.675 2.547 2.443  2.356\n9       1000  6.660 4.626 3.801 3.338 3.036 2.820 2.657 2.529 2.425  2.339\n  df1=12 df1=15 df1=20\n1  4.706  4.558  4.405\n2  3.666  3.522  3.372\n3  3.231  3.088  2.938\n4  2.843  2.700  2.549\n5  2.665  2.522  2.369\n6  2.496  2.352  2.198\n7  2.336  2.192  2.035\n8  2.220  2.075  1.915\n9  2.203  2.056  1.897\n\n\n\n\n\n\n\n\n\nPour Student, si vos ddl n’apparaissent pas, prenez la valeur la plus proche par défaut par le bas (conservateur).\n\nPour Fisher, si vos ddl sont hors table, utilisez directement qf() dans R ou élargissez la grille."
  },
  {
    "objectID": "annexes/tables.html#table-de-student-bilatéral",
    "href": "annexes/tables.html#table-de-student-bilatéral",
    "title": "Annexes — Tables statistiques",
    "section": "",
    "text": "Table 1: Valeurs critiques de Student (bilatéral)\n\n\n\n    ddl t(α=10%) t(α=5%) t(α=1%)\n1     1    6.314  12.706  63.657\n2     2    2.920   4.303   9.925\n3     3    2.353   3.182   5.841\n4     4    2.132   2.776   4.604\n5     5    2.015   2.571   4.032\n6     6    1.943   2.447   3.707\n7     7    1.895   2.365   3.499\n8     8    1.860   2.306   3.355\n9     9    1.833   2.262   3.250\n10   10    1.812   2.228   3.169\n11   11    1.796   2.201   3.106\n12   12    1.782   2.179   3.055\n13   13    1.771   2.160   3.012\n14   14    1.761   2.145   2.977\n15   15    1.753   2.131   2.947\n16   16    1.746   2.120   2.921\n17   17    1.740   2.110   2.898\n18   18    1.734   2.101   2.878\n19   19    1.729   2.093   2.861\n20   20    1.725   2.086   2.845\n21   21    1.721   2.080   2.831\n22   22    1.717   2.074   2.819\n23   23    1.714   2.069   2.807\n24   24    1.711   2.064   2.797\n25   25    1.708   2.060   2.787\n26   26    1.706   2.056   2.779\n27   27    1.703   2.052   2.771\n28   28    1.701   2.048   2.763\n29   29    1.699   2.045   2.756\n30   30    1.697   2.042   2.750\n31   40    1.684   2.021   2.704\n32   50    1.676   2.009   2.678\n33   60    1.671   2.000   2.660\n34   70    1.667   1.994   2.648\n35   80    1.664   1.990   2.639\n36   90    1.662   1.987   2.632\n37  100    1.660   1.984   2.626\n38  110    1.659   1.982   2.621\n39  120    1.658   1.980   2.617\n40  150    1.655   1.976   2.609\n41  200    1.653   1.972   2.601\n42  500    1.648   1.965   2.586\n43 1000    1.646   1.962   2.581"
  },
  {
    "objectID": "annexes/tables.html#table-de-fisher-unilatéral",
    "href": "annexes/tables.html#table-de-fisher-unilatéral",
    "title": "Annexes — Tables statistiques",
    "section": "",
    "text": "Table 2: Valeurs critiques de Fisher (unilatéral)\n\n\n\n$`F(α = 10%)`\n  ddl denom. df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 3.285 2.924 2.728 2.605 2.522 2.461 2.414 2.377 2.347  2.323\n2         15 3.073 2.695 2.490 2.361 2.273 2.208 2.158 2.119 2.086  2.059\n3         20 2.975 2.589 2.380 2.249 2.158 2.091 2.040 1.999 1.965  1.937\n4         30 2.881 2.489 2.276 2.142 2.049 1.980 1.927 1.884 1.849  1.819\n5         40 2.835 2.440 2.226 2.091 1.997 1.927 1.873 1.829 1.793  1.763\n6         60 2.791 2.393 2.177 2.041 1.946 1.875 1.819 1.775 1.738  1.707\n7        120 2.748 2.347 2.130 1.992 1.896 1.824 1.767 1.722 1.684  1.652\n8        500 2.716 2.313 2.095 1.956 1.859 1.786 1.729 1.683 1.644  1.612\n9       1000 2.711 2.308 2.089 1.950 1.853 1.780 1.723 1.676 1.638  1.605\n  df1=12 df1=15 df1=20\n1  2.284  2.244  2.201\n2  2.017  1.972  1.924\n3  1.892  1.845  1.794\n4  1.773  1.722  1.667\n5  1.715  1.662  1.605\n6  1.657  1.603  1.543\n7  1.601  1.545  1.482\n8  1.559  1.501  1.435\n9  1.552  1.494  1.428\n\n$`F(α = 5%)`\n  ddl denom. df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 4.965 4.103 3.708 3.478 3.326 3.217 3.135 3.072 3.020  2.978\n2         15 4.543 3.682 3.287 3.056 2.901 2.790 2.707 2.641 2.588  2.544\n3         20 4.351 3.493 3.098 2.866 2.711 2.599 2.514 2.447 2.393  2.348\n4         30 4.171 3.316 2.922 2.690 2.534 2.421 2.334 2.266 2.211  2.165\n5         40 4.085 3.232 2.839 2.606 2.449 2.336 2.249 2.180 2.124  2.077\n6         60 4.001 3.150 2.758 2.525 2.368 2.254 2.167 2.097 2.040  1.993\n7        120 3.920 3.072 2.680 2.447 2.290 2.175 2.087 2.016 1.959  1.910\n8        500 3.860 3.014 2.623 2.390 2.232 2.117 2.028 1.957 1.899  1.850\n9       1000 3.851 3.005 2.614 2.381 2.223 2.108 2.019 1.948 1.889  1.840\n  df1=12 df1=15 df1=20\n1  2.913  2.845  2.774\n2  2.475  2.403  2.328\n3  2.278  2.203  2.124\n4  2.092  2.015  1.932\n5  2.003  1.924  1.839\n6  1.917  1.836  1.748\n7  1.834  1.750  1.659\n8  1.772  1.686  1.592\n9  1.762  1.676  1.581\n\n$`F(α = 1%)`\n  ddl denom.  df1=1 df1=2 df1=3 df1=4 df1=5 df1=6 df1=7 df1=8 df1=9 df1=10\n1         10 10.044 7.559 6.552 5.994 5.636 5.386 5.200 5.057 4.942  4.849\n2         15  8.683 6.359 5.417 4.893 4.556 4.318 4.142 4.004 3.895  3.805\n3         20  8.096 5.849 4.938 4.431 4.103 3.871 3.699 3.564 3.457  3.368\n4         30  7.562 5.390 4.510 4.018 3.699 3.473 3.304 3.173 3.067  2.979\n5         40  7.314 5.179 4.313 3.828 3.514 3.291 3.124 2.993 2.888  2.801\n6         60  7.077 4.977 4.126 3.649 3.339 3.119 2.953 2.823 2.718  2.632\n7        120  6.851 4.787 3.949 3.480 3.174 2.956 2.792 2.663 2.559  2.472\n8        500  6.686 4.648 3.821 3.357 3.054 2.838 2.675 2.547 2.443  2.356\n9       1000  6.660 4.626 3.801 3.338 3.036 2.820 2.657 2.529 2.425  2.339\n  df1=12 df1=15 df1=20\n1  4.706  4.558  4.405\n2  3.666  3.522  3.372\n3  3.231  3.088  2.938\n4  2.843  2.700  2.549\n5  2.665  2.522  2.369\n6  2.496  2.352  2.198\n7  2.336  2.192  2.035\n8  2.220  2.075  1.915\n9  2.203  2.056  1.897"
  },
  {
    "objectID": "annexes/tables.html#remarques",
    "href": "annexes/tables.html#remarques",
    "title": "Annexes — Tables statistiques",
    "section": "",
    "text": "Pour Student, si vos ddl n’apparaissent pas, prenez la valeur la plus proche par défaut par le bas (conservateur).\n\nPour Fisher, si vos ddl sont hors table, utilisez directement qf() dans R ou élargissez la grille."
  },
  {
    "objectID": "cheat-sheet.html",
    "href": "cheat-sheet.html",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "",
    "text": "But : Aide-mémoire compact (formules + procédures) couvrant les TD 1→8 : MCO, diagnostics (normalité, hétéroscédasticité, autocorrélation, stabilité), spécification (RESET), sélection de modèle (AIC/SC/HQC), endogénéité & variables instrumentales, tests associés, et un rappel Monte Carlo."
  },
  {
    "objectID": "cheat-sheet.html#hypothèses-blue",
    "href": "cheat-sheet.html#hypothèses-blue",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "1.1 Hypothèses (BLUE)",
    "text": "1.1 Hypothèses (BLUE)\n\nLinéarité en paramètres ; échantillonnage i.i.d.\nExogénéité : \\(\\mathrm{Cov}(X,\\varepsilon)=0\\).\nHomoscedasticité : \\(\\mathrm{Var}(\\varepsilon_i)=\\sigma^2\\).\nIndépendance sérielle : \\(\\mathrm{Cov}(\\varepsilon_i,\\varepsilon_j)=0\\) (séries \\(t\\)).\nNormalité (utile surtout en petit \\(N\\) pour l’inférence exacte t/F).\n\nConséquences\nSans normalité, OLS reste sans biais & convergent (sous exogénéité), mais t/F peuvent être mal calibrés (risque de 1ʳᵉ espèce ↑/↓)."
  },
  {
    "objectID": "cheat-sheet.html#interprétations-usuelles",
    "href": "cheat-sheet.html#interprétations-usuelles",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "1.2 Interprétations usuelles",
    "text": "1.2 Interprétations usuelles\n\n\\(y\\) en log, \\(x\\) en niveau : \\(\\beta_k \\approx 100 \\times \\Delta\\%\\, y\\) pour +1 unité de \\(x_k\\) (si \\(|\\beta_k|\\) petit).\nMuette \\(D\\) : effet % \\(\\approx 100\\times(\\exp(\\beta_D)-1)\\)."
  },
  {
    "objectID": "cheat-sheet.html#breuschpagan-bp",
    "href": "cheat-sheet.html#breuschpagan-bp",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "3.1 Breusch–Pagan (BP)",
    "text": "3.1 Breusch–Pagan (BP)\nRégression auxiliaire : \\(\\hat\\varepsilon_i^2 = \\theta_0 + \\theta'Z_i + \\omega_i\\).\nStatistique : \\(BP = N \\times R^2 \\sim \\chi^2(K_z)\\) (où \\(K_z\\) = nb de \\(Z\\)).\nDécision : Rejeter \\(H_0\\) (variance constante) si \\(BP\\) &gt; seuil."
  },
  {
    "objectID": "cheat-sheet.html#white-générique",
    "href": "cheat-sheet.html#white-générique",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "3.2 White (générique)",
    "text": "3.2 White (générique)\nInclure \\(Z\\), interactions et carrés (\\(Z, Z^2, Z_iZ_j\\)).\nStatistique : \\(W = N \\times R^2 \\sim \\chi^2(K-1)\\).\nVersion petits échantillons : F-test sur la régression auxiliaire.\nEViews : View → Residual Diagnostics → Heteroskedasticity Tests → BP/White.\nCorrection : Estimate → Options → Coefficient covariance = White (ou HAC)."
  },
  {
    "objectID": "cheat-sheet.html#durbinwatson-dw",
    "href": "cheat-sheet.html#durbinwatson-dw",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "4.1 Durbin–Watson (DW)",
    "text": "4.1 Durbin–Watson (DW)\n\\(DW=\\sum_{t=2}^T(\\hat\\varepsilon_t-\\hat\\varepsilon_{t-1})^2\\big/\\sum_{t=1}^T\\hat\\varepsilon_t^2 \\approx 2(1-\\hat\\rho)\\).\nTableaux \\(D_L, D_U\\) → zones : rejet (+), incertitude, acceptation, rejet (−).\nLimites : constante requise, pas de \\(y_{t-1}\\) comme régresseur, AR(1) seulement."
  },
  {
    "objectID": "cheat-sheet.html#breuschgodfrey-bg",
    "href": "cheat-sheet.html#breuschgodfrey-bg",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "4.2 Breusch–Godfrey (BG)",
    "text": "4.2 Breusch–Godfrey (BG)\nRégression : \\(\\hat\\varepsilon_t=\\rho_1\\hat\\varepsilon_{t-1}+\\cdots+\\rho_p\\hat\\varepsilon_{t-p}+Z_t'\\theta+\\omega_t\\).\nStatistique : \\(BG = T\\times R^2 \\sim \\chi^2(p)\\).\nEViews : View → Residual Diagnostics → Serial Correlation LM test.\nCorrection : HAC (Newey–West) ou modéliser ARMA des erreurs / Cochrane–Orcutt."
  },
  {
    "objectID": "cheat-sheet.html#chow-point-de-rupture-connu",
    "href": "cheat-sheet.html#chow-point-de-rupture-connu",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "5.1 Chow (point de rupture connu)",
    "text": "5.1 Chow (point de rupture connu)\nTrois régressions (avant, après, complet).\nStatistique : \\(CH=\\dfrac{SCR_t-(SCR_1+SCR_2)}{SCR_1+SCR_2}\\times\\dfrac{N-2K}{K}\\ \\leadsto F(K,N-2K)\\).\nAttention : hypothèse d’homoscedasticité."
  },
  {
    "objectID": "cheat-sheet.html#quandtandrews-point-inconnu",
    "href": "cheat-sheet.html#quandtandrews-point-inconnu",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "5.2 Quandt–Andrews (point inconnu)",
    "text": "5.2 Quandt–Andrews (point inconnu)\nCalculer le test de Chow pour toutes ruptures admissibles, retenir la plus défavorable (QLR/sup‑Wald).\nEViews : View → Stability Diagnostics → Quandt-Andrews Breakpoint Test.\nPratique : trier les données selon la variable “candidate rupture” avant test.\nSolutions si instabilité : sous‑échantillons ; muettes + interactions ; exclusion outliers (avec prudence)."
  },
  {
    "objectID": "cheat-sheet.html#sources-dendogénéité",
    "href": "cheat-sheet.html#sources-dendogénéité",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "8.1 Sources d’endogénéité",
    "text": "8.1 Sources d’endogénéité\n\nVariable omise corrélée à \\(X\\)\nCausalité inverse (\\(Y \\leftrightarrow X\\))\nErreur de mesure sur \\(X\\) (biais d’atténuation)"
  },
  {
    "objectID": "cheat-sheet.html#sls-dmc-principe",
    "href": "cheat-sheet.html#sls-dmc-principe",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "8.2 2SLS / DMC (principe)",
    "text": "8.2 2SLS / DMC (principe)\n1ʳᵉ étape : \\(X = \\pi_0+\\pi_1 Z + W'\\pi + v \\Rightarrow \\hat X\\).\n2ᵉ étape : \\(Y=\\beta_0+\\beta_1\\hat X + W'\\gamma + u\\) (SE adaptés 2SLS).\nConditions pour \\(Z\\) :\n\nPertinence (\\(\\mathrm{Cov}(Z,X)\\neq 0\\)) → F‑stat 1ʳᵉ étape &gt; 10 (règle pratique).\nExogénéité exclue (\\(\\mathrm{Cov}(Z,u)=0\\)).\n\nEViews : Estimate → Method: TSLS/IV ; lister endogènes & instruments."
  },
  {
    "objectID": "cheat-sheet.html#tests-associés",
    "href": "cheat-sheet.html#tests-associés",
    "title": "Économétrie L3 — Cheat Sheet (TD1→TD8)",
    "section": "8.3 Tests associés",
    "text": "8.3 Tests associés\n\nFaiblesse des instruments : F 1ʳᵉ étape (règle &gt;10).\nSur‑identification (si \\(q&gt;p\\)) : Sargan (homo) / Hansen‑J (robuste) \\(\\sim \\chi^2(q-p)\\).\nNécessité d’instrumenter : Durbin–Wu–Hausman (DWH) :\n\\(H_0\\) : OLS non biaisé (\\(\\beta^{OLS}\\approx\\beta^{IV}\\)).\n\nEViews : View → IV Diagnostics and Tests → Weak/Orthogonality/Endogeneity."
  }
]